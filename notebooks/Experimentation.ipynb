{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Initial Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6250)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 62,790\n",
      "Trainable params: 62,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 14s 343ms/step - loss: 206.4199 - accuracy: 0.1375 - val_loss: 61.2814 - val_accuracy: 0.1950\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 12s 295ms/step - loss: 25.8079 - accuracy: 0.3070 - val_loss: 25.6535 - val_accuracy: 0.2300\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 13s 331ms/step - loss: 9.2154 - accuracy: 0.4875 - val_loss: 24.1452 - val_accuracy: 0.2300\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 13s 328ms/step - loss: 5.7722 - accuracy: 0.6305 - val_loss: 24.4043 - val_accuracy: 0.2550\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 3.1833 - accuracy: 0.7484 - val_loss: 23.5417 - val_accuracy: 0.2450\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 2.6024 - accuracy: 0.8050 - val_loss: 22.6050 - val_accuracy: 0.2700\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 1.8781 - accuracy: 0.8391 - val_loss: 22.8495 - val_accuracy: 0.2950\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 13s 313ms/step - loss: 1.4264 - accuracy: 0.8805 - val_loss: 21.5290 - val_accuracy: 0.2750\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 14s 353ms/step - loss: 1.4600 - accuracy: 0.8797 - val_loss: 22.5392 - val_accuracy: 0.2950\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 14s 352ms/step - loss: 1.6695 - accuracy: 0.8656 - val_loss: 24.2101 - val_accuracy: 0.2700\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 24s 594ms/step - loss: 1.1783 - accuracy: 0.9055 - val_loss: 23.7482 - val_accuracy: 0.2750\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 20s 510ms/step - loss: 1.2082 - accuracy: 0.9086 - val_loss: 22.7660 - val_accuracy: 0.3200\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.8945 - accuracy: 0.9230 - val_loss: 24.3732 - val_accuracy: 0.3100\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 18s 439ms/step - loss: 0.7411 - accuracy: 0.9266 - val_loss: 22.9944 - val_accuracy: 0.3100\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.6260 - accuracy: 0.9410 - val_loss: 22.1744 - val_accuracy: 0.3100\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 0.4950 - accuracy: 0.9484 - val_loss: 23.5396 - val_accuracy: 0.3050\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 13s 330ms/step - loss: 0.6568 - accuracy: 0.9312 - val_loss: 22.1723 - val_accuracy: 0.3150\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 13s 327ms/step - loss: 0.5126 - accuracy: 0.9453 - val_loss: 20.7959 - val_accuracy: 0.3200\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 0.4686 - accuracy: 0.9555 - val_loss: 22.1873 - val_accuracy: 0.3150\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 12s 309ms/step - loss: 0.7931 - accuracy: 0.9367 - val_loss: 20.5646 - val_accuracy: 0.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cc9634588>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfit on the training data, did not generalize to the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - Increase Kernel Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=5, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 252, 252, 10)      760       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6250)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 63,270\n",
      "Trainable params: 63,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 14s 358ms/step - loss: 91.8692 - accuracy: 0.1266 - val_loss: 10.7892 - val_accuracy: 0.1200\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 13s 329ms/step - loss: 5.1260 - accuracy: 0.1937 - val_loss: 6.1438 - val_accuracy: 0.1200\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 13s 323ms/step - loss: 3.0122 - accuracy: 0.2820 - val_loss: 5.3370 - val_accuracy: 0.1150\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 2.2932 - accuracy: 0.3602 - val_loss: 5.0220 - val_accuracy: 0.0950\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 1.8092 - accuracy: 0.4742 - val_loss: 4.7914 - val_accuracy: 0.1100\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 1.3916 - accuracy: 0.5734 - val_loss: 4.9906 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 1.1837 - accuracy: 0.6445 - val_loss: 5.1580 - val_accuracy: 0.1400\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.8349 - accuracy: 0.7297 - val_loss: 5.5516 - val_accuracy: 0.1500\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.7210 - accuracy: 0.7844 - val_loss: 5.6833 - val_accuracy: 0.1750\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 0.5843 - accuracy: 0.8200 - val_loss: 5.9044 - val_accuracy: 0.1700\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.4832 - accuracy: 0.8461 - val_loss: 6.1850 - val_accuracy: 0.1800\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 0.5311 - accuracy: 0.8445 - val_loss: 6.5411 - val_accuracy: 0.1650\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 11s 279ms/step - loss: 0.4465 - accuracy: 0.8742 - val_loss: 6.2271 - val_accuracy: 0.1900\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 11s 269ms/step - loss: 0.4272 - accuracy: 0.8664 - val_loss: 6.9730 - val_accuracy: 0.1600\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.2873 - accuracy: 0.9086 - val_loss: 6.9802 - val_accuracy: 0.1650\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 11s 270ms/step - loss: 0.3226 - accuracy: 0.9172 - val_loss: 7.1365 - val_accuracy: 0.1750\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 10s 252ms/step - loss: 0.3055 - accuracy: 0.9203 - val_loss: 6.3069 - val_accuracy: 0.1900\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 11s 276ms/step - loss: 0.3261 - accuracy: 0.9055 - val_loss: 6.5375 - val_accuracy: 0.2050\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 10s 252ms/step - loss: 0.1863 - accuracy: 0.9422 - val_loss: 7.1709 - val_accuracy: 0.1750\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 10s 251ms/step - loss: 0.2363 - accuracy: 0.9328 - val_loss: 6.5620 - val_accuracy: 0.1850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ce9557c88>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger kernel performed worse. Let's try a smaller kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - Decrease Kernel Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=2, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 255, 255, 10)      130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6250)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 62,640\n",
      "Trainable params: 62,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 11s 269ms/step - loss: 189.8808 - accuracy: 0.1531 - val_loss: 73.4405 - val_accuracy: 0.1400\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 10s 248ms/step - loss: 25.9073 - accuracy: 0.3313 - val_loss: 26.9899 - val_accuracy: 0.1800\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 10.4909 - accuracy: 0.4836 - val_loss: 27.0480 - val_accuracy: 0.2450\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 8.1029 - accuracy: 0.6031 - val_loss: 26.4237 - val_accuracy: 0.2300\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 4.3869 - accuracy: 0.7258 - val_loss: 26.1492 - val_accuracy: 0.2600\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 10s 248ms/step - loss: 2.2677 - accuracy: 0.8141 - val_loss: 25.8212 - val_accuracy: 0.2650\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 2.2636 - accuracy: 0.8297 - val_loss: 27.1669 - val_accuracy: 0.2750\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 2.2134 - accuracy: 0.8469 - val_loss: 24.9422 - val_accuracy: 0.2650\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 10s 252ms/step - loss: 2.0985 - accuracy: 0.8477 - val_loss: 26.3898 - val_accuracy: 0.3100\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 10s 251ms/step - loss: 2.5562 - accuracy: 0.8188 - val_loss: 25.5685 - val_accuracy: 0.2950\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 10s 255ms/step - loss: 1.3884 - accuracy: 0.8844 - val_loss: 26.1829 - val_accuracy: 0.2800\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 1.4396 - accuracy: 0.8898 - val_loss: 27.5017 - val_accuracy: 0.2750\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 11s 273ms/step - loss: 1.1201 - accuracy: 0.9156 - val_loss: 23.6535 - val_accuracy: 0.2700\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 10s 254ms/step - loss: 0.6220 - accuracy: 0.9422 - val_loss: 24.0806 - val_accuracy: 0.3100\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.7690 - accuracy: 0.9297 - val_loss: 26.7089 - val_accuracy: 0.3250\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 0.5950 - accuracy: 0.9305 - val_loss: 25.4855 - val_accuracy: 0.2650\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 0.7042 - accuracy: 0.9445 - val_loss: 27.1789 - val_accuracy: 0.3050\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 0.5646 - accuracy: 0.9469 - val_loss: 25.0143 - val_accuracy: 0.3100\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.7158 - accuracy: 0.9383 - val_loss: 26.1621 - val_accuracy: 0.2900\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.7334 - accuracy: 0.9336 - val_loss: 25.7695 - val_accuracy: 0.2950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cc4fe1408>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel_size=3 performed best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - Add Dropout Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 254, 254, 10)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6250)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 62,790\n",
      "Trainable params: 62,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 49.5038 - accuracy: 0.1656 - val_loss: 17.6243 - val_accuracy: 0.1500\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 10.2765 - accuracy: 0.3523 - val_loss: 12.6249 - val_accuracy: 0.2800\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 9s 231ms/step - loss: 4.7453 - accuracy: 0.5672 - val_loss: 12.1243 - val_accuracy: 0.2750\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 2.6323 - accuracy: 0.7195 - val_loss: 12.2602 - val_accuracy: 0.3050\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 1.7278 - accuracy: 0.7859 - val_loss: 12.7241 - val_accuracy: 0.3000\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 1.1139 - accuracy: 0.8492 - val_loss: 12.9153 - val_accuracy: 0.3100\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.9632 - accuracy: 0.8672 - val_loss: 12.8161 - val_accuracy: 0.3200\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.6719 - accuracy: 0.9008 - val_loss: 12.8051 - val_accuracy: 0.3350\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.6634 - accuracy: 0.9094 - val_loss: 12.8353 - val_accuracy: 0.3300\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.6006 - accuracy: 0.9117 - val_loss: 12.4846 - val_accuracy: 0.3150\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 0.6188 - accuracy: 0.8984 - val_loss: 14.1582 - val_accuracy: 0.3200\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 9s 234ms/step - loss: 0.4189 - accuracy: 0.9344 - val_loss: 12.7194 - val_accuracy: 0.2850\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 0.4242 - accuracy: 0.9320 - val_loss: 13.9278 - val_accuracy: 0.3400\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 9s 228ms/step - loss: 0.5113 - accuracy: 0.9297 - val_loss: 13.4699 - val_accuracy: 0.3050\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 0.4268 - accuracy: 0.9281 - val_loss: 13.9890 - val_accuracy: 0.3150\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.2866 - accuracy: 0.9484 - val_loss: 14.0509 - val_accuracy: 0.3250\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.3531 - accuracy: 0.9516 - val_loss: 12.2735 - val_accuracy: 0.3350\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 0.3690 - accuracy: 0.9500 - val_loss: 14.3479 - val_accuracy: 0.3250\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 9s 234ms/step - loss: 0.2772 - accuracy: 0.9563 - val_loss: 12.5733 - val_accuracy: 0.3650\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 0.2768 - accuracy: 0.9609 - val_loss: 14.1566 - val_accuracy: 0.3350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cc59a4208>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5 - Remove MaxPooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 254, 254, 10)      0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 645160)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                6451610   \n",
      "=================================================================\n",
      "Total params: 6,451,890\n",
      "Trainable params: 6,451,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 11464.7284 - accuracy: 0.1328 - val_loss: 1047.1991 - val_accuracy: 0.1400\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 10s 258ms/step - loss: 326.8999 - accuracy: 0.4602 - val_loss: 142.2167 - val_accuracy: 0.3550\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 18.1810 - accuracy: 0.8375 - val_loss: 116.1318 - val_accuracy: 0.3450\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 6.6618 - accuracy: 0.9039 - val_loss: 124.9605 - val_accuracy: 0.3200\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 8.2324 - accuracy: 0.9000 - val_loss: 137.4872 - val_accuracy: 0.3300\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 9s 231ms/step - loss: 5.2438 - accuracy: 0.9266 - val_loss: 119.1479 - val_accuracy: 0.3150\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 4.4293 - accuracy: 0.9367 - val_loss: 142.5738 - val_accuracy: 0.2600\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 4.7065 - accuracy: 0.9312 - val_loss: 138.9247 - val_accuracy: 0.3100\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 3.9598 - accuracy: 0.9445 - val_loss: 134.5392 - val_accuracy: 0.3300\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 9s 223ms/step - loss: 3.3397 - accuracy: 0.9492 - val_loss: 130.6685 - val_accuracy: 0.3000\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 2.8844 - accuracy: 0.9563 - val_loss: 142.2470 - val_accuracy: 0.2900\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 3.9037 - accuracy: 0.9695 - val_loss: 139.7449 - val_accuracy: 0.2900\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 2.3135 - accuracy: 0.9500 - val_loss: 144.4836 - val_accuracy: 0.2900\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 9s 231ms/step - loss: 4.9724 - accuracy: 0.9547 - val_loss: 161.3033 - val_accuracy: 0.3050\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 3.8931 - accuracy: 0.9516 - val_loss: 141.5282 - val_accuracy: 0.3050\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 2.0290 - accuracy: 0.9711 - val_loss: 148.4748 - val_accuracy: 0.3250\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 3.4899 - accuracy: 0.9680 - val_loss: 141.8416 - val_accuracy: 0.3150\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 1.3716 - accuracy: 0.9805 - val_loss: 147.0416 - val_accuracy: 0.2950\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 1.2350 - accuracy: 0.9844 - val_loss: 153.2559 - val_accuracy: 0.2850\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 1.3026 - accuracy: 0.9812 - val_loss: 157.2209 - val_accuracy: 0.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cc65fc708>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the same with way more parameters. Still overfitting like crazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6 - Replace Dropout with BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 254, 254, 10)      40        \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 645160)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                6451610   \n",
      "=================================================================\n",
      "Total params: 6,451,930\n",
      "Trainable params: 6,451,910\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 42.8838 - accuracy: 0.3375 - val_loss: 26.2029 - val_accuracy: 0.2200\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 7.1125 - accuracy: 0.6984 - val_loss: 31.2764 - val_accuracy: 0.2950\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 3.9108 - accuracy: 0.8336 - val_loss: 26.1086 - val_accuracy: 0.3000\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 2.4493 - accuracy: 0.9000 - val_loss: 33.3006 - val_accuracy: 0.3200\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 2.6187 - accuracy: 0.8969 - val_loss: 33.1035 - val_accuracy: 0.2350\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.9513 - accuracy: 0.9211 - val_loss: 38.5788 - val_accuracy: 0.3400\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 2.0216 - accuracy: 0.9180 - val_loss: 57.0341 - val_accuracy: 0.3200\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 9s 223ms/step - loss: 2.1917 - accuracy: 0.9180 - val_loss: 35.0713 - val_accuracy: 0.2900\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 1.2304 - accuracy: 0.9414 - val_loss: 50.2434 - val_accuracy: 0.3300\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 9s 223ms/step - loss: 1.8036 - accuracy: 0.9375 - val_loss: 39.2733 - val_accuracy: 0.3350\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 223ms/step - loss: 1.1293 - accuracy: 0.9523 - val_loss: 40.2244 - val_accuracy: 0.2900\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 0.9864 - accuracy: 0.9531 - val_loss: 62.5346 - val_accuracy: 0.2600\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.7189 - accuracy: 0.9656 - val_loss: 49.5669 - val_accuracy: 0.3400\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 9s 223ms/step - loss: 0.4423 - accuracy: 0.9766 - val_loss: 42.2173 - val_accuracy: 0.3250\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 0.9381 - accuracy: 0.9656 - val_loss: 53.1661 - val_accuracy: 0.2400\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 223ms/step - loss: 1.0653 - accuracy: 0.9641 - val_loss: 65.6195 - val_accuracy: 0.2250\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 228ms/step - loss: 1.2043 - accuracy: 0.9633 - val_loss: 55.6972 - val_accuracy: 0.3200\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 1.7356 - accuracy: 0.9602 - val_loss: 65.0281 - val_accuracy: 0.3150\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 1.3094 - accuracy: 0.9555 - val_loss: 60.9734 - val_accuracy: 0.3150\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 1.2854 - accuracy: 0.9602 - val_loss: 47.2757 - val_accuracy: 0.3200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cca23bf08>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7 - Bring back dropout, add a second convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 254, 254, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 252, 252, 10)      910       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 252, 252, 10)      0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 635040)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                6350410   \n",
      "=================================================================\n",
      "Total params: 6,351,600\n",
      "Trainable params: 6,351,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 3991.8533 - accuracy: 0.1289 - val_loss: 51.7726 - val_accuracy: 0.1400\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 27.9060 - accuracy: 0.3680 - val_loss: 6.1529 - val_accuracy: 0.1800\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 9s 234ms/step - loss: 2.3160 - accuracy: 0.6305 - val_loss: 4.7680 - val_accuracy: 0.1900\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.2600 - accuracy: 0.7414 - val_loss: 4.1564 - val_accuracy: 0.2100\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.9547 - accuracy: 0.7719 - val_loss: 4.1388 - val_accuracy: 0.1850\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.7604 - accuracy: 0.8219 - val_loss: 4.0299 - val_accuracy: 0.1800\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 0.5663 - accuracy: 0.8516 - val_loss: 4.1448 - val_accuracy: 0.1700\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.5987 - accuracy: 0.8516 - val_loss: 4.1777 - val_accuracy: 0.2000\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 9s 228ms/step - loss: 0.4676 - accuracy: 0.8836 - val_loss: 4.3252 - val_accuracy: 0.2100\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 0.4310 - accuracy: 0.9031 - val_loss: 4.3552 - val_accuracy: 0.2150\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 0.3685 - accuracy: 0.9070 - val_loss: 4.4339 - val_accuracy: 0.2100\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 0.3379 - accuracy: 0.9164 - val_loss: 4.4466 - val_accuracy: 0.1900\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.3219 - accuracy: 0.9104 - val_loss: 4.5055 - val_accuracy: 0.2050\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 0.3052 - accuracy: 0.9227 - val_loss: 4.7609 - val_accuracy: 0.2000\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 9s 234ms/step - loss: 0.2976 - accuracy: 0.9273 - val_loss: 4.7062 - val_accuracy: 0.1850\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 0.2713 - accuracy: 0.9344 - val_loss: 4.8985 - val_accuracy: 0.1850\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 0.2644 - accuracy: 0.9344 - val_loss: 4.8986 - val_accuracy: 0.2050\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 0.2615 - accuracy: 0.9391 - val_loss: 5.0358 - val_accuracy: 0.1850\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.2135 - accuracy: 0.9484 - val_loss: 5.1725 - val_accuracy: 0.2200\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 10s 255ms/step - loss: 0.2066 - accuracy: 0.9484 - val_loss: 5.3007 - val_accuracy: 0.2050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cd019b148>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8 - Increase number of nodes in first convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(25, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 254, 254, 25)      700       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 254, 254, 25)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 252, 252, 10)      2260      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 252, 252, 10)      0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 635040)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                6350410   \n",
      "=================================================================\n",
      "Total params: 6,353,370\n",
      "Trainable params: 6,353,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 585.7035 - accuracy: 0.1375 - val_loss: 2.3104 - val_accuracy: 0.1250\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 2.3322 - accuracy: 0.1703 - val_loss: 2.3022 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 2.2763 - accuracy: 0.1680 - val_loss: 2.3076 - val_accuracy: 0.1100\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 2.1862 - accuracy: 0.2258 - val_loss: 2.3655 - val_accuracy: 0.0900\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 1.9212 - accuracy: 0.3539 - val_loss: 2.6162 - val_accuracy: 0.0800\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 1.6729 - accuracy: 0.4672 - val_loss: 2.7381 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 1.3183 - accuracy: 0.5813 - val_loss: 3.4139 - val_accuracy: 0.1150\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 1.0740 - accuracy: 0.6641 - val_loss: 3.0923 - val_accuracy: 0.1200\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 0.8550 - accuracy: 0.7469 - val_loss: 3.4390 - val_accuracy: 0.1400\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.8281 - accuracy: 0.7602 - val_loss: 3.6947 - val_accuracy: 0.1300\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 231ms/step - loss: 0.7016 - accuracy: 0.7891 - val_loss: 3.8116 - val_accuracy: 0.1200\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 0.6124 - accuracy: 0.8148 - val_loss: 4.1876 - val_accuracy: 0.1250\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 0.5713 - accuracy: 0.8305 - val_loss: 4.2015 - val_accuracy: 0.1400\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 0.5067 - accuracy: 0.8508 - val_loss: 4.2071 - val_accuracy: 0.1700\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 0.4999 - accuracy: 0.8531 - val_loss: 4.7920 - val_accuracy: 0.1300\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 0.4081 - accuracy: 0.8859 - val_loss: 4.3717 - val_accuracy: 0.1050\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.3667 - accuracy: 0.8938 - val_loss: 4.8806 - val_accuracy: 0.1300\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 0.4519 - accuracy: 0.8734 - val_loss: 5.0455 - val_accuracy: 0.1250\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 0.4256 - accuracy: 0.8945 - val_loss: 5.1498 - val_accuracy: 0.0850\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 10s 255ms/step - loss: 0.3814 - accuracy: 0.9023 - val_loss: 4.7313 - val_accuracy: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ccbd06b48>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 9 - Add more Conv, Dense, Pooling, and Dropout Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(25, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 252, 252, 10)      910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 23, 23, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 21, 21, 10)        910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 4,295\n",
      "Trainable params: 4,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 10s 253ms/step - loss: 10.0287 - accuracy: 0.1063 - val_loss: 2.4930 - val_accuracy: 0.1100\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 2.3948 - accuracy: 0.1156 - val_loss: 2.3390 - val_accuracy: 0.0950\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 2.3280 - accuracy: 0.1086 - val_loss: 2.3230 - val_accuracy: 0.1050\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 9s 230ms/step - loss: 2.3073 - accuracy: 0.1234 - val_loss: 2.3341 - val_accuracy: 0.1350\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 2.3051 - accuracy: 0.1250 - val_loss: 2.3159 - val_accuracy: 0.1150\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 9s 231ms/step - loss: 2.3021 - accuracy: 0.1055 - val_loss: 2.3016 - val_accuracy: 0.1400\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 2.2964 - accuracy: 0.1227 - val_loss: 2.2956 - val_accuracy: 0.1300\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 2.3003 - accuracy: 0.1164 - val_loss: 2.2908 - val_accuracy: 0.1250\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 9s 230ms/step - loss: 2.2903 - accuracy: 0.1406 - val_loss: 2.3041 - val_accuracy: 0.1050\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 9s 228ms/step - loss: 2.2885 - accuracy: 0.1344 - val_loss: 2.3184 - val_accuracy: 0.1100\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 2.2850 - accuracy: 0.1547 - val_loss: 2.3026 - val_accuracy: 0.1150\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 9s 226ms/step - loss: 2.2852 - accuracy: 0.1219 - val_loss: 2.3074 - val_accuracy: 0.1250\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 2.2655 - accuracy: 0.1635 - val_loss: 2.3117 - val_accuracy: 0.1250\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 2.2755 - accuracy: 0.1336 - val_loss: 2.3374 - val_accuracy: 0.1050\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 2.2650 - accuracy: 0.1500 - val_loss: 2.3170 - val_accuracy: 0.1200\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 2.2375 - accuracy: 0.1695 - val_loss: 2.3314 - val_accuracy: 0.1200\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 2.2357 - accuracy: 0.1508 - val_loss: 2.3590 - val_accuracy: 0.1250\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 2.2355 - accuracy: 0.1750 - val_loss: 2.2984 - val_accuracy: 0.1300\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 2.2239 - accuracy: 0.1672 - val_loss: 2.3338 - val_accuracy: 0.1200\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 2.2118 - accuracy: 0.1813 - val_loss: 2.2950 - val_accuracy: 0.1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ccea8d288>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 10 - AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weight Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                              mode='max', \\\n",
    "                              monitor='val_accuracy', \\\n",
    "                              save_best_only=True)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '../data/raw/imgs/train'\n",
    "testpath = '../data/raw/imgs/testlabeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "testdatagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory(trainpath, \\\n",
    "                                    target_size=(227, 227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory(testpath, \\\n",
    "                                   target_size=(227, 227))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(99, \\\n",
    "                 kernel_size=11, \\\n",
    "                 strides=4, \\\n",
    "                 padding='valid', \\\n",
    "                 activation='relu', \\\n",
    "                 input_shape=(227, 227, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(3, \\\n",
    "                    strides=2, \\\n",
    "                    padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(256, \\\n",
    "                 kernel_size=5, \\\n",
    "                 strides=1, \\\n",
    "                 padding='same', \\\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(3, \\\n",
    "                    strides=2, \\\n",
    "                    padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(384, \\\n",
    "                 kernel_size=3, \\\n",
    "                 strides=1, \\\n",
    "                 padding='same', \\\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(384, \\\n",
    "                 kernel_size=3, \\\n",
    "                 strides=1, \\\n",
    "                 padding='same', \\\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(256, \\\n",
    "                 kernel_size=3, \\\n",
    "                 strides=1, \\\n",
    "                 padding='same', \\\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 99)        36036     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 99)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       633856    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               4326500   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 8,105,102\n",
      "Trainable params: 8,105,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 15s 376ms/step - loss: 17.6337 - accuracy: 0.1242 - val_loss: 2.2994 - val_accuracy: 0.1850\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 14s 342ms/step - loss: 2.0946 - accuracy: 0.2516 - val_loss: 1.9108 - val_accuracy: 0.2900\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 14s 353ms/step - loss: 1.6135 - accuracy: 0.4195 - val_loss: 1.7132 - val_accuracy: 0.3800\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 14s 352ms/step - loss: 1.2855 - accuracy: 0.5508 - val_loss: 1.5437 - val_accuracy: 0.4200\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 13s 331ms/step - loss: 1.0813 - accuracy: 0.6305 - val_loss: 1.6753 - val_accuracy: 0.4450\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 13s 321ms/step - loss: 0.8291 - accuracy: 0.7414 - val_loss: 2.1762 - val_accuracy: 0.4050\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.7403 - accuracy: 0.7477 - val_loss: 2.0163 - val_accuracy: 0.4350\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.7120 - accuracy: 0.7781 - val_loss: 2.2034 - val_accuracy: 0.4450\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 12s 309ms/step - loss: 0.6040 - accuracy: 0.8047 - val_loss: 1.8845 - val_accuracy: 0.4600\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 0.4701 - accuracy: 0.8586 - val_loss: 2.1310 - val_accuracy: 0.4300\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 11s 287ms/step - loss: 0.4339 - accuracy: 0.8578 - val_loss: 2.3119 - val_accuracy: 0.4400\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.4230 - accuracy: 0.8664 - val_loss: 2.2655 - val_accuracy: 0.4300\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 13s 314ms/step - loss: 0.3583 - accuracy: 0.8867 - val_loss: 2.3098 - val_accuracy: 0.4750\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.3389 - accuracy: 0.9008 - val_loss: 1.9401 - val_accuracy: 0.4700\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.3396 - accuracy: 0.8945 - val_loss: 2.0313 - val_accuracy: 0.4800\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.3143 - accuracy: 0.9086 - val_loss: 1.9798 - val_accuracy: 0.4950\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 17s 413ms/step - loss: 0.3145 - accuracy: 0.9070 - val_loss: 2.2312 - val_accuracy: 0.4850\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.2738 - accuracy: 0.9242 - val_loss: 2.3627 - val_accuracy: 0.4550\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 13s 326ms/step - loss: 0.2813 - accuracy: 0.9070 - val_loss: 2.1976 - val_accuracy: 0.4600\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 0.2751 - accuracy: 0.9203 - val_loss: 2.1338 - val_accuracy: 0.4550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2353b187808>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, \\\n",
    "          epochs=20, \\\n",
    "          steps_per_epoch=40, \\\n",
    "          validation_data=test, \\\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely better, but it's only hitting ~0.46 validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

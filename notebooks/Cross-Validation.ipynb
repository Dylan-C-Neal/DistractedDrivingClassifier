{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selectively Loading Data with Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('driver_imgs_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the dataframe to make a column that generates the filepathway from this parent folder ot each individual file. Then create a function that will generate the crossvalidation train/test splits, with each iteration pulling out one specific subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw/imgs/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = numpy.empty([5,2])\n",
    "checkpoint = ModelCheckpoint('weights.hdf5', \\\n",
    "                             mode='max', \\\n",
    "                             monitor='val_accuracy', \\\n",
    "                             save_best_only=True)\n",
    "callbacks_list=[checkpoint]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15702 images belonging to 10 classes.\n",
      "Found 6722 images belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 20 steps\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 29s 1s/step - loss: 184.2983 - accuracy: 0.1031 - val_loss: 108.1223 - val_accuracy: 0.1328\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 32s 2s/step - loss: 55.8650 - accuracy: 0.1312 - val_loss: 27.2335 - val_accuracy: 0.1984\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 22s 1s/step - loss: 18.8952 - accuracy: 0.2156 - val_loss: 13.3917 - val_accuracy: 0.2609\n",
      "Found 15702 images belonging to 10 classes.\n",
      "Found 6722 images belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 20 steps\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 25s 1s/step - loss: 145.4389 - accuracy: 0.1016 - val_loss: 73.0403 - val_accuracy: 0.1375\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 21s 1s/step - loss: 41.4412 - accuracy: 0.1672 - val_loss: 25.4188 - val_accuracy: 0.1984\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 21s 1s/step - loss: 18.8068 - accuracy: 0.2672 - val_loss: 16.9706 - val_accuracy: 0.2203\n",
      "Found 15702 images belonging to 10 classes.\n",
      "Found 6722 images belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 20 steps\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 25s 1s/step - loss: 107.0873 - accuracy: 0.1344 - val_loss: 48.6456 - val_accuracy: 0.1578\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 19s 952ms/step - loss: 28.6194 - accuracy: 0.1891 - val_loss: 20.6139 - val_accuracy: 0.2016\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 18s 915ms/step - loss: 14.5201 - accuracy: 0.2688 - val_loss: 13.1339 - val_accuracy: 0.2484\n",
      "Found 15702 images belonging to 10 classes.\n",
      "Found 6722 images belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 20 steps\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 22s 1s/step - loss: 99.9368 - accuracy: 0.1484 - val_loss: 36.6659 - val_accuracy: 0.1672\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 18s 894ms/step - loss: 23.3865 - accuracy: 0.1762 - val_loss: 13.0480 - val_accuracy: 0.2375\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 18s 890ms/step - loss: 9.1367 - accuracy: 0.2984 - val_loss: 7.1966 - val_accuracy: 0.2984\n",
      "Found 15702 images belonging to 10 classes.\n",
      "Found 6722 images belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 20 steps\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 23s 1s/step - loss: 152.4586 - accuracy: 0.1063 - val_loss: 76.8022 - val_accuracy: 0.1391\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 18s 895ms/step - loss: 53.7283 - accuracy: 0.1688 - val_loss: 28.8321 - val_accuracy: 0.2156\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 18s 910ms/step - loss: 22.6963 - accuracy: 0.2188 - val_loss: 14.8237 - val_accuracy: 0.2875\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(480, 640, 3)))\n",
    "    model.add(MaxPool2D(30))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    datagen = keras.preprocessing.image.ImageDataGenerator(validation_split=0.3)\n",
    "    \n",
    "    train = datagen.flow_from_directory(path, \\\n",
    "                                   target_size=(480, 640), \\\n",
    "                                   subset='training')\n",
    "    \n",
    "    val = datagen.flow_from_directory(path, \\\n",
    "                                   target_size=(480, 640), \\\n",
    "                                   subset='validation')\n",
    "    \n",
    "    model.fit(train, \\\n",
    "              epochs=3, \\\n",
    "              steps_per_epoch=20, \\\n",
    "              validation_data=val, \\\n",
    "              validation_steps=20, \\\n",
    "              callbacks=callbacks_list)\n",
    "    \n",
    "    #print('Evaluating')\n",
    "    #history = model.evaluate(val)\n",
    "    #scores[i,0] = history[0]\n",
    "    #scores[i,1] = history[1]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

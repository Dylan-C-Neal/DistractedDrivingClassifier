{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from functions import cvmodeleval,samplecv, trainsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training filename dataframe\n",
    "df = pd.read_csv('data/processed/driver_image_list_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeled and unlabeled test filename dataframes\n",
    "df_test_labeled = pd.read_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/processed/labeled_test_df.csv')\n",
    "df_test = pd.read_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/test_filenames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to over/undersample classes occurance by subject so dataset is completely balanced.\n",
    "df = trainsampling(df, samples=80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path variables for data\n",
    "train_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/train'\n",
    "labeled_test_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/testlabeled'\n",
    "unlabeled_test_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 subjects were chosen from the training data to be used for validation during model training. These subjects represent one woman and man with dark skin and one woman and man with light skin. This is to help balance any potential racial bias in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of validation subjects\n",
    "val_subjects = ['p056', 'p050', 'p041', 'p016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects)]\n",
    "df_val = df[df['subject'].isin(val_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing and Data-Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataGenerators for training and test/validation data. Generators include randomized preprocessing for \n",
    "# called out parameters. Test_dgen will be used for both validation data and test data.\n",
    "\n",
    "train_dgen = ImageDataGenerator(samplewise_center=True,\n",
    "                                rescale=1./255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                channel_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_dgen = ImageDataGenerator(samplewise_center=True,\n",
    "                               rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 validated image filenames belonging to 10 classes.\n",
      "Found 3200 validated image filenames belonging to 10 classes.\n",
      "Found 200 validated image filenames belonging to 10 classes.\n",
      "Found 79726 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)\n",
    "\n",
    "test_labeled = test_dgen.flow_from_dataframe(df_test_labeled,\n",
    "                                             x_col='filename',\n",
    "                                             y_col='classname',\n",
    "                                             target_size=(227,227),\n",
    "                                             shuffle=False)\n",
    "\n",
    "test = test_dgen.flow_from_dataframe(df_test,\n",
    "                                     x_col='filename',\n",
    "                                     y_col='class',\n",
    "                                     target_size=(227,227),\n",
    "                                     shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1 - AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture below is based off of AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for initializing model\n",
    "def alexNet_arch(opt):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(99,\n",
    "                  kernel_size=11,\n",
    "                  strides=4,\n",
    "                  padding='valid',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                        strides=2,\n",
    "                        padding='valid'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer variable\n",
    "opt = RMSprop(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model_1\n",
    "model_1 = alexNet_arch(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model1_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 37s 323ms/step - loss: 6.9370 - accuracy: 0.0918 - val_loss: 2.4704 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 36s 326ms/step - loss: 2.7232 - accuracy: 0.0996 - val_loss: 2.3143 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 35s 320ms/step - loss: 2.4712 - accuracy: 0.1074 - val_loss: 2.3308 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 35s 319ms/step - loss: 2.4106 - accuracy: 0.1175 - val_loss: 2.3382 - val_accuracy: 0.0819\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 34s 312ms/step - loss: 2.3365 - accuracy: 0.1322 - val_loss: 2.2670 - val_accuracy: 0.1278\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 2.2182 - accuracy: 0.1680 - val_loss: 2.1761 - val_accuracy: 0.1900\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 2.1847 - accuracy: 0.1627 - val_loss: 2.0818 - val_accuracy: 0.2309\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 35s 320ms/step - loss: 2.1023 - accuracy: 0.1848 - val_loss: 1.9907 - val_accuracy: 0.2228\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 34s 307ms/step - loss: 2.0495 - accuracy: 0.2408 - val_loss: 1.8269 - val_accuracy: 0.3141\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 1.9844 - accuracy: 0.2580 - val_loss: 1.8713 - val_accuracy: 0.2309\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 1.9225 - accuracy: 0.2545 - val_loss: 2.1298 - val_accuracy: 0.3403\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.8979 - accuracy: 0.2744 - val_loss: 1.8953 - val_accuracy: 0.2503\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.8064 - accuracy: 0.2888 - val_loss: 1.8129 - val_accuracy: 0.4009\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.7552 - accuracy: 0.3207 - val_loss: 2.0009 - val_accuracy: 0.3169\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 1.6673 - accuracy: 0.3460 - val_loss: 2.1884 - val_accuracy: 0.3591\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 1.6882 - accuracy: 0.3380 - val_loss: 1.5826 - val_accuracy: 0.3728\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.6024 - accuracy: 0.3839 - val_loss: 1.7211 - val_accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.6260 - accuracy: 0.3626 - val_loss: 1.6332 - val_accuracy: 0.4556\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 33s 305ms/step - loss: 1.4911 - accuracy: 0.4248 - val_loss: 1.4591 - val_accuracy: 0.4403\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 33s 298ms/step - loss: 1.5116 - accuracy: 0.4450 - val_loss: 1.6147 - val_accuracy: 0.4241\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 1.4967 - accuracy: 0.4111 - val_loss: 2.6076 - val_accuracy: 0.3853\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.5100 - accuracy: 0.4253 - val_loss: 1.6006 - val_accuracy: 0.4572\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 1.3689 - accuracy: 0.4725 - val_loss: 1.5605 - val_accuracy: 0.3922\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 33s 303ms/step - loss: 1.4382 - accuracy: 0.4313 - val_loss: 2.1730 - val_accuracy: 0.4162\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.3154 - accuracy: 0.4958 - val_loss: 1.3790 - val_accuracy: 0.4725\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.2592 - accuracy: 0.5069 - val_loss: 2.0544 - val_accuracy: 0.4209\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 34s 305ms/step - loss: 1.2776 - accuracy: 0.4922 - val_loss: 1.3580 - val_accuracy: 0.5391\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 1.2141 - accuracy: 0.5467 - val_loss: 2.7274 - val_accuracy: 0.4297\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.2181 - accuracy: 0.5566 - val_loss: 1.7309 - val_accuracy: 0.4519\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.1889 - accuracy: 0.5543 - val_loss: 1.9721 - val_accuracy: 0.4659\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 33s 304ms/step - loss: 1.1153 - accuracy: 0.5788 - val_loss: 2.2953 - val_accuracy: 0.5484\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.1607 - accuracy: 0.5432 - val_loss: 2.1510 - val_accuracy: 0.4722\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.0466 - accuracy: 0.6067 - val_loss: 2.1928 - val_accuracy: 0.5200\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.0721 - accuracy: 0.6115 - val_loss: 3.5886 - val_accuracy: 0.4822\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.0939 - accuracy: 0.6083 - val_loss: 1.2664 - val_accuracy: 0.5797\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 1.0112 - accuracy: 0.6376 - val_loss: 3.8568 - val_accuracy: 0.34030111 - ac\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.9635 - accuracy: 0.6643 - val_loss: 1.8653 - val_accuracy: 0.5362- loss: - ETA: 0s - loss: 0.9634 - accuracy: 0.\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.9672 - accuracy: 0.6250 - val_loss: 4.3620 - val_accuracy: 0.5213\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.9016 - accuracy: 0.6907 - val_loss: 1.5191 - val_accuracy: 0.5622\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.9299 - accuracy: 0.6766 - val_loss: 1.8797 - val_accuracy: 0.5406\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.9072 - accuracy: 0.6725 - val_loss: 1.5550 - val_accuracy: 0.5744\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.8576 - accuracy: 0.7003 - val_loss: 1.2470 - val_accuracy: 0.5897\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.7888 - accuracy: 0.7128 - val_loss: 1.7872 - val_accuracy: 0.6278\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.8785 - accuracy: 0.7049 - val_loss: 1.6290 - val_accuracy: 0.6516\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.8114 - accuracy: 0.7252 - val_loss: 1.3758 - val_accuracy: 0.6003\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.8449 - accuracy: 0.7165 - val_loss: 3.1881 - val_accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 32s 286ms/step - loss: 0.7990 - accuracy: 0.7181 - val_loss: 1.2954 - val_accuracy: 0.6356\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7620 - accuracy: 0.7261 - val_loss: 1.0843 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7879 - accuracy: 0.7454 - val_loss: 2.5816 - val_accuracy: 0.6044\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.6449 - accuracy: 0.7890 - val_loss: 2.4861 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7814 - accuracy: 0.7390 - val_loss: 3.0154 - val_accuracy: 0.4925\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7237 - accuracy: 0.7633 - val_loss: 1.8533 - val_accuracy: 0.6072\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.6905 - accuracy: 0.7591 - val_loss: 1.3254 - val_accuracy: 0.6137\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.7218 - accuracy: 0.7610 - val_loss: 3.5828 - val_accuracy: 0.5547\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.7115 - accuracy: 0.7712 - val_loss: 2.0833 - val_accuracy: 0.5666\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6871 - accuracy: 0.7649 - val_loss: 3.9417 - val_accuracy: 0.5825\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.7307 - accuracy: 0.7818 - val_loss: 1.1655 - val_accuracy: 0.6803\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.6096 - accuracy: 0.7805 - val_loss: 1.3496 - val_accuracy: 0.5738\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.6752 - accuracy: 0.7550 - val_loss: 2.7699 - val_accuracy: 0.6125\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 32s 292ms/step - loss: 0.6621 - accuracy: 0.7665 - val_loss: 0.9719 - val_accuracy: 0.6928\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6555 - accuracy: 0.7714 - val_loss: 1.6889 - val_accuracy: 0.6097: 0.6557 - accuracy: 0.\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6568 - accuracy: 0.7847 - val_loss: 1.0797 - val_accuracy: 0.6553\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 32s 292ms/step - loss: 0.5286 - accuracy: 0.8196 - val_loss: 3.4980 - val_accuracy: 0.5675\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5640 - accuracy: 0.8030 - val_loss: 2.0961 - val_accuracy: 0.6269\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 32s 290ms/step - loss: 0.5747 - accuracy: 0.8205 - val_loss: 1.9404 - val_accuracy: 0.6381\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.6131 - accuracy: 0.8072 - val_loss: 1.0244 - val_accuracy: 0.7038\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 0.6409 - accuracy: 0.8094 - val_loss: 1.2645 - val_accuracy: 0.7022\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 32s 291ms/step - loss: 0.5321 - accuracy: 0.8291 - val_loss: 1.0098 - val_accuracy: 0.7075\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 0.5949 - accuracy: 0.8158 - val_loss: 1.5364 - val_accuracy: 0.6219\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 33s 296ms/step - loss: 0.5694 - accuracy: 0.8236 - val_loss: 1.2908 - val_accuracy: 0.6587\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5534 - accuracy: 0.8104 - val_loss: 1.5745 - val_accuracy: 0.6662\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.4999 - accuracy: 0.8354 - val_loss: 6.3533 - val_accuracy: 0.5203\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.5988 - accuracy: 0.8055 - val_loss: 1.9124 - val_accuracy: 0.6078\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 0.6210 - accuracy: 0.7965 - val_loss: 1.0781 - val_accuracy: 0.6884\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 32s 291ms/step - loss: 0.5594 - accuracy: 0.8237 - val_loss: 1.2082 - val_accuracy: 0.6325\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.4701 - accuracy: 0.8397 - val_loss: 2.0178 - val_accuracy: 0.6169\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 0.5477 - accuracy: 0.8369 - val_loss: 2.1251 - val_accuracy: 0.6300\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.6061 - accuracy: 0.8016 - val_loss: 2.4876 - val_accuracy: 0.6166\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.5179 - accuracy: 0.8301 - val_loss: 1.1209 - val_accuracy: 0.7175\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.5503 - accuracy: 0.8343 - val_loss: 1.2862 - val_accuracy: 0.6447\n",
      "Wall time: 44min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ed51c4400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train model_1\n",
    "model_1.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_1.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to a dataframe with original labeles\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_1_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 10s 105ms/step - loss: 0.9719 - accuracy: 0.6928\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_1_val_metrics = model_1.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_1_val_metrics[0]], \n",
    "                                    'Accuracy':[model_1_val_metrics[1]]})\n",
    "model_1_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_1_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971922</td>\n",
       "      <td>0.692813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0            0.971922  0.692813"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9719 cross-entropy loss and 0.6928 accuracy are not a bad start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Xception Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a method desribed at this url (https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/), I loaded a pre-trained Xception model through keras with weights optimized for imagenet. I made all of the existing layers non-trainable and then added a few trainable layers which will be fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 227, 227, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 113, 113, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 113, 113, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 113, 113, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 111, 111, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 111, 111, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 111, 111, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 111, 111, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 111, 111, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 111, 111, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 111, 111, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 111, 111, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 56, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 56, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 56, 56, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 56, 56, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 56, 56, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 56, 56, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          51380736    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 72,247,346\n",
      "Trainable params: 51,385,866\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_2 = tf.keras.applications.Xception(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_2.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_2 = tf.keras.models.Model(base_model_2.input, x)\n",
    "model_2.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model2_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 71s 647ms/step - loss: 2.8249 - accuracy: 0.1415 - val_loss: 2.1583 - val_accuracy: 0.2169\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 60s 549ms/step - loss: 2.3187 - accuracy: 0.1727 - val_loss: 2.2208 - val_accuracy: 0.2288\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 62s 560ms/step - loss: 2.1792 - accuracy: 0.2364 - val_loss: 2.4904 - val_accuracy: 0.1937\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 60s 548ms/step - loss: 2.1252 - accuracy: 0.2557 - val_loss: 2.3664 - val_accuracy: 0.2147\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 2.0460 - accuracy: 0.3051 - val_loss: 2.4786 - val_accuracy: 0.2256\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 1.9675 - accuracy: 0.3210 - val_loss: 2.5725 - val_accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.9526 - accuracy: 0.3301 - val_loss: 2.5295 - val_accuracy: 0.2122\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.8587 - accuracy: 0.3682 - val_loss: 2.5472 - val_accuracy: 0.2769\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 1.8533 - accuracy: 0.3812 - val_loss: 2.8614 - val_accuracy: 0.2166\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 1.7944 - accuracy: 0.4011 - val_loss: 2.6684 - val_accuracy: 0.2356\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.8344 - accuracy: 0.3812 - val_loss: 3.1513 - val_accuracy: 0.1700\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.7937 - accuracy: 0.3932 - val_loss: 2.8103 - val_accuracy: 0.2384\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.7601 - accuracy: 0.4131 - val_loss: 3.1716 - val_accuracy: 0.2109\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.6830 - accuracy: 0.4295 - val_loss: 3.0304 - val_accuracy: 0.2269\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 1.6815 - accuracy: 0.4347 - val_loss: 3.2372 - val_accuracy: 0.2266\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.6595 - accuracy: 0.4472 - val_loss: 3.4794 - val_accuracy: 0.2262\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 1.6560 - accuracy: 0.4392 - val_loss: 3.7069 - val_accuracy: 0.2525\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.6152 - accuracy: 0.4466 - val_loss: 3.3362 - val_accuracy: 0.2156\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.5994 - accuracy: 0.4517 - val_loss: 3.3340 - val_accuracy: 0.2119\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 1.5447 - accuracy: 0.4710 - val_loss: 4.2985 - val_accuracy: 0.1969\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.6734 - accuracy: 0.4443 - val_loss: 4.0363 - val_accuracy: 0.2087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ba027de48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_2.predict(val)\n",
    "\n",
    "# Convert to a dataframe with original labels\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_2_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 2.1583 - accuracy: 0.2169\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_2_val_metrics = model_2.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_2_val_metrics[0]], \n",
    "                                    'Accuracy':[model_2_val_metrics[1]]})\n",
    "model_2_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_2_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.15828</td>\n",
       "      <td>0.216875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0             2.15828  0.216875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - VGG16 Transfer-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_3 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_3.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_3 = tf.keras.models.Model(base_model_3.input, x)\n",
    "model_3.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 63s 569ms/step - loss: 2.5059 - accuracy: 0.1324 - val_loss: 2.1846 - val_accuracy: 0.1606\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 59s 541ms/step - loss: 2.2511 - accuracy: 0.1653 - val_loss: 2.0830 - val_accuracy: 0.2734\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 59s 538ms/step - loss: 2.1532 - accuracy: 0.2284 - val_loss: 1.9477 - val_accuracy: 0.2266\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 2.1002 - accuracy: 0.2295 - val_loss: 1.8449 - val_accuracy: 0.3663\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 59s 537ms/step - loss: 1.9959 - accuracy: 0.2886 - val_loss: 1.6320 - val_accuracy: 0.5341\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 1.9342 - accuracy: 0.3034 - val_loss: 1.5335 - val_accuracy: 0.6256\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.8685 - accuracy: 0.3528 - val_loss: 1.5222 - val_accuracy: 0.5369\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 58s 525ms/step - loss: 1.7947 - accuracy: 0.3693 - val_loss: 1.3815 - val_accuracy: 0.6181\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.6574 - accuracy: 0.4341 - val_loss: 1.3276 - val_accuracy: 0.6159\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 1.6994 - accuracy: 0.4136 - val_loss: 1.2882 - val_accuracy: 0.6109\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 1.6211 - accuracy: 0.4517 - val_loss: 1.2407 - val_accuracy: 0.5769\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.5630 - accuracy: 0.4597 - val_loss: 1.1015 - val_accuracy: 0.7384\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 1.5050 - accuracy: 0.4801 - val_loss: 1.1019 - val_accuracy: 0.6950\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 1.4783 - accuracy: 0.4892 - val_loss: 1.2250 - val_accuracy: 0.5638\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.4343 - accuracy: 0.5261 - val_loss: 1.0464 - val_accuracy: 0.6612\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 1.4105 - accuracy: 0.5102 - val_loss: 0.9985 - val_accuracy: 0.7241\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.3692 - accuracy: 0.5278 - val_loss: 1.0238 - val_accuracy: 0.6775\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 56s 513ms/step - loss: 1.3585 - accuracy: 0.5330 - val_loss: 0.9533 - val_accuracy: 0.7362\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.3233 - accuracy: 0.5449 - val_loss: 1.0242 - val_accuracy: 0.6547\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 1.2883 - accuracy: 0.5665 - val_loss: 0.9397 - val_accuracy: 0.7272\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 1.2685 - accuracy: 0.5767 - val_loss: 0.9362 - val_accuracy: 0.7056\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 1.2557 - accuracy: 0.5705 - val_loss: 0.8747 - val_accuracy: 0.7334\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 55s 498ms/step - loss: 1.2587 - accuracy: 0.5744 - val_loss: 0.9221 - val_accuracy: 0.7116\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 55s 500ms/step - loss: 1.2557 - accuracy: 0.5778 - val_loss: 0.9435 - val_accuracy: 0.7075\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 55s 502ms/step - loss: 1.1779 - accuracy: 0.6017 - val_loss: 1.0846 - val_accuracy: 0.6075\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.1667 - accuracy: 0.6028 - val_loss: 0.9744 - val_accuracy: 0.6831\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.1335 - accuracy: 0.6187 - val_loss: 0.9020 - val_accuracy: 0.7016\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 1.1551 - accuracy: 0.6034 - val_loss: 0.9316 - val_accuracy: 0.6975\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 63s 570ms/step - loss: 1.1354 - accuracy: 0.6193 - val_loss: 0.8170 - val_accuracy: 0.7541\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 58s 530ms/step - loss: 1.0773 - accuracy: 0.6386 - val_loss: 0.7890 - val_accuracy: 0.7556\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0984 - accuracy: 0.6187 - val_loss: 1.0447 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 1.0777 - accuracy: 0.6403 - val_loss: 0.9368 - val_accuracy: 0.7003\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 58s 523ms/step - loss: 1.0628 - accuracy: 0.6494 - val_loss: 0.8261 - val_accuracy: 0.7578\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 60s 545ms/step - loss: 1.0540 - accuracy: 0.6415 - val_loss: 1.0391 - val_accuracy: 0.6538\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 1.0416 - accuracy: 0.6608 - val_loss: 0.9632 - val_accuracy: 0.6944\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.9996 - accuracy: 0.6591 - val_loss: 0.8432 - val_accuracy: 0.7303\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0333 - accuracy: 0.6602 - val_loss: 0.8632 - val_accuracy: 0.7194\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0168 - accuracy: 0.6597 - val_loss: 0.9146 - val_accuracy: 0.6700\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.9422 - accuracy: 0.6801 - val_loss: 0.9312 - val_accuracy: 0.6928\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.9547 - accuracy: 0.6824 - val_loss: 0.8237 - val_accuracy: 0.7566\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.9504 - accuracy: 0.6801 - val_loss: 0.8506 - val_accuracy: 0.7231\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9649 - accuracy: 0.6722 - val_loss: 0.9130 - val_accuracy: 0.6844\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9749 - accuracy: 0.6756 - val_loss: 0.8606 - val_accuracy: 0.7175\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.9777 - accuracy: 0.6727 - val_loss: 0.8787 - val_accuracy: 0.7169\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 59s 539ms/step - loss: 0.9161 - accuracy: 0.6926 - val_loss: 0.7318 - val_accuracy: 0.7569\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.9721 - accuracy: 0.6699 - val_loss: 0.8721 - val_accuracy: 0.6997\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.9386 - accuracy: 0.6812 - val_loss: 0.8388 - val_accuracy: 0.7153\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9135 - accuracy: 0.6960 - val_loss: 0.8732 - val_accuracy: 0.6919\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.8933 - accuracy: 0.7006 - val_loss: 0.8399 - val_accuracy: 0.7178\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.9312 - accuracy: 0.6960 - val_loss: 0.8972 - val_accuracy: 0.6975\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.9067 - accuracy: 0.7006 - val_loss: 0.8612 - val_accuracy: 0.7234\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.9091 - accuracy: 0.6898 - val_loss: 0.8654 - val_accuracy: 0.7147\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.8836 - accuracy: 0.6926 - val_loss: 1.0139 - val_accuracy: 0.6822\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.9084 - accuracy: 0.6994 - val_loss: 0.8808 - val_accuracy: 0.6988\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.8851 - accuracy: 0.7000 - val_loss: 0.8380 - val_accuracy: 0.7188\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 0.8359 - accuracy: 0.7199 - val_loss: 0.9066 - val_accuracy: 0.6913\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 60s 544ms/step - loss: 0.8708 - accuracy: 0.7142 - val_loss: 0.8984 - val_accuracy: 0.6897\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 59s 539ms/step - loss: 0.8583 - accuracy: 0.7125 - val_loss: 0.8167 - val_accuracy: 0.7334\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 0.8788 - accuracy: 0.7142 - val_loss: 0.8421 - val_accuracy: 0.7034\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 60s 547ms/step - loss: 0.8753 - accuracy: 0.7028 - val_loss: 0.8929 - val_accuracy: 0.6784\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 0.8081 - accuracy: 0.7312 - val_loss: 0.9423 - val_accuracy: 0.6841\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 0.8400 - accuracy: 0.7193 - val_loss: 0.8140 - val_accuracy: 0.7406\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.8432 - accuracy: 0.7159 - val_loss: 0.7726 - val_accuracy: 0.7328\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.8556 - accuracy: 0.7182 - val_loss: 0.8617 - val_accuracy: 0.6963\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.8331 - accuracy: 0.7295 - val_loss: 0.9490 - val_accuracy: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x204e7f42d08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I renamed the weight file for this first run to model3_weights_first_run.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from first run\n",
    "model_3.load_weights('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights_first_run.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_3.predict(val)\n",
    "\n",
    "# Convert to a dataframe with original labels\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_3_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 15s 150ms/step - loss: 0.7258 - accuracy: 0.7607\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_3_val_metrics = model_3.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_3_val_metrics[0]], \n",
    "                                    'Accuracy':[model_3_val_metrics[1]]})\n",
    "model_3_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_3_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7318361401557922, 0.7568749785423279]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to cross-validate, the same pre-trained VGG16 Model will be trained on 4 additional CV-folds. The predictions from all 4 models will be ensembled together to ideally improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation subjects for upcoming CV-folds.\n",
    "val_subjects_cv2 = ['p002', 'p014', 'p022', 'p042']\n",
    "val_subjects_cv3 = ['p012', 'p015', 'p045', 'p049']\n",
    "val_subjects_cv4 = ['p075', 'p066', 'p064', 'p051']\n",
    "val_subjects_cv5 = ['p052', 'p047', 'p061', 'p035']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd CV Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects_cv2)]\n",
    "df_val = df[df['subject'].isin(val_subjects_cv2)]\n",
    "\n",
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 validated image filenames belonging to 10 classes.\n",
      "Found 3200 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_cv2 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_cv2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_cv2.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_cv2 = tf.keras.models.Model(base_model_cv2.input, x)\n",
    "model_cv2.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_cv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model_cv2_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 41s 339ms/step - loss: 2.7870 - accuracy: 0.1189 - val_loss: 2.1574 - val_accuracy: 0.2506\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 37s 335ms/step - loss: 2.2966 - accuracy: 0.1594 - val_loss: 2.0629 - val_accuracy: 0.3734\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 37s 337ms/step - loss: 2.2214 - accuracy: 0.1985 - val_loss: 1.9174 - val_accuracy: 0.3703\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 37s 337ms/step - loss: 2.1209 - accuracy: 0.2446 - val_loss: 1.7821 - val_accuracy: 0.4206\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 37s 339ms/step - loss: 2.0485 - accuracy: 0.2555 - val_loss: 1.6020 - val_accuracy: 0.5603\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 37s 341ms/step - loss: 1.9052 - accuracy: 0.3346 - val_loss: 1.5451 - val_accuracy: 0.5891\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 37s 339ms/step - loss: 1.8237 - accuracy: 0.3529 - val_loss: 1.4881 - val_accuracy: 0.5144\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 37s 341ms/step - loss: 1.8318 - accuracy: 0.3681 - val_loss: 1.4077 - val_accuracy: 0.5741\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 38s 342ms/step - loss: 1.7120 - accuracy: 0.3976 - val_loss: 1.4422 - val_accuracy: 0.4772\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 38s 348ms/step - loss: 1.6617 - accuracy: 0.4244 - val_loss: 1.3330 - val_accuracy: 0.5356\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 38s 350ms/step - loss: 1.6094 - accuracy: 0.4442 - val_loss: 1.2842 - val_accuracy: 0.5709\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 39s 353ms/step - loss: 1.5753 - accuracy: 0.4508 - val_loss: 1.3536 - val_accuracy: 0.5094\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 40s 361ms/step - loss: 1.5644 - accuracy: 0.4638 - val_loss: 1.2529 - val_accuracy: 0.5178\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 40s 360ms/step - loss: 1.5040 - accuracy: 0.4855 - val_loss: 1.3046 - val_accuracy: 0.4856\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 40s 366ms/step - loss: 1.4688 - accuracy: 0.5015 - val_loss: 1.1857 - val_accuracy: 0.5697\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 41s 372ms/step - loss: 1.4640 - accuracy: 0.5230 - val_loss: 1.1872 - val_accuracy: 0.5966\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 42s 382ms/step - loss: 1.3686 - accuracy: 0.5378 - val_loss: 1.1751 - val_accuracy: 0.6087\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 42s 381ms/step - loss: 1.3496 - accuracy: 0.5537 - val_loss: 1.1278 - val_accuracy: 0.5984\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 42s 383ms/step - loss: 1.3379 - accuracy: 0.5637 - val_loss: 1.1204 - val_accuracy: 0.5850\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 43s 394ms/step - loss: 1.2361 - accuracy: 0.5943 - val_loss: 1.1527 - val_accuracy: 0.6031\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 43s 389ms/step - loss: 1.2685 - accuracy: 0.5811 - val_loss: 1.0866 - val_accuracy: 0.6078\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 43s 394ms/step - loss: 1.2573 - accuracy: 0.5886 - val_loss: 1.0600 - val_accuracy: 0.6178\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 43s 394ms/step - loss: 1.2271 - accuracy: 0.5827 - val_loss: 1.2925 - val_accuracy: 0.5428\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 43s 389ms/step - loss: 1.2222 - accuracy: 0.5975 - val_loss: 1.0813 - val_accuracy: 0.6137\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 43s 391ms/step - loss: 1.2210 - accuracy: 0.5923 - val_loss: 1.0348 - val_accuracy: 0.6369\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 44s 399ms/step - loss: 1.1594 - accuracy: 0.5984 - val_loss: 1.0591 - val_accuracy: 0.6322\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 44s 402ms/step - loss: 1.1353 - accuracy: 0.6366 - val_loss: 1.0079 - val_accuracy: 0.6241\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 45s 407ms/step - loss: 1.0976 - accuracy: 0.6322 - val_loss: 1.1824 - val_accuracy: 0.5556\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 50s 452ms/step - loss: 1.0437 - accuracy: 0.6472 - val_loss: 1.0129 - val_accuracy: 0.6406\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 44s 403ms/step - loss: 1.1246 - accuracy: 0.6216 - val_loss: 1.0833 - val_accuracy: 0.5931\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 45s 406ms/step - loss: 1.0908 - accuracy: 0.6327 - val_loss: 1.1441 - val_accuracy: 0.6034\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 45s 411ms/step - loss: 1.0207 - accuracy: 0.6572 - val_loss: 1.0967 - val_accuracy: 0.6031\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 46s 420ms/step - loss: 1.0906 - accuracy: 0.6245 - val_loss: 1.0346 - val_accuracy: 0.6431\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 46s 415ms/step - loss: 1.1077 - accuracy: 0.6274 - val_loss: 1.3433 - val_accuracy: 0.5631\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 46s 420ms/step - loss: 1.0646 - accuracy: 0.6538 - val_loss: 1.1306 - val_accuracy: 0.6103\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 46s 416ms/step - loss: 1.0956 - accuracy: 0.6040 - val_loss: 1.1567 - val_accuracy: 0.5806\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 48s 436ms/step - loss: 0.9899 - accuracy: 0.6723 - val_loss: 1.1147 - val_accuracy: 0.6044\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 47s 426ms/step - loss: 0.9954 - accuracy: 0.6703 - val_loss: 1.0033 - val_accuracy: 0.6559\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 47s 427ms/step - loss: 0.9475 - accuracy: 0.6924 - val_loss: 1.0039 - val_accuracy: 0.6488\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 47s 429ms/step - loss: 0.9804 - accuracy: 0.6600 - val_loss: 1.0279 - val_accuracy: 0.6409\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 48s 436ms/step - loss: 1.0131 - accuracy: 0.6776 - val_loss: 1.1676 - val_accuracy: 0.6134\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 48s 441ms/step - loss: 0.9517 - accuracy: 0.6661 - val_loss: 1.1688 - val_accuracy: 0.5888\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 48s 434ms/step - loss: 0.9105 - accuracy: 0.6889 - val_loss: 1.1578 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 49s 447ms/step - loss: 0.9682 - accuracy: 0.6709 - val_loss: 1.0645 - val_accuracy: 0.6528\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 49s 442ms/step - loss: 0.9690 - accuracy: 0.6750 - val_loss: 1.2074 - val_accuracy: 0.5987\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 49s 447ms/step - loss: 0.9403 - accuracy: 0.6961 - val_loss: 1.2219 - val_accuracy: 0.5678\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 49s 447ms/step - loss: 0.9214 - accuracy: 0.6922 - val_loss: 1.1874 - val_accuracy: 0.6009\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 49s 448ms/step - loss: 0.9285 - accuracy: 0.6890 - val_loss: 1.2752 - val_accuracy: 0.5750\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 50s 452ms/step - loss: 0.8775 - accuracy: 0.7036 - val_loss: 1.1239 - val_accuracy: 0.6216\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 50s 453ms/step - loss: 0.8714 - accuracy: 0.7048 - val_loss: 1.3033 - val_accuracy: 0.5784\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 51s 463ms/step - loss: 0.9388 - accuracy: 0.6836 - val_loss: 1.2484 - val_accuracy: 0.5956\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 51s 461ms/step - loss: 0.9202 - accuracy: 0.7001 - val_loss: 1.1808 - val_accuracy: 0.5941\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 51s 464ms/step - loss: 0.8974 - accuracy: 0.7061 - val_loss: 1.1170 - val_accuracy: 0.5928\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 51s 466ms/step - loss: 0.8150 - accuracy: 0.7339 - val_loss: 1.1749 - val_accuracy: 0.6291\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 53s 481ms/step - loss: 0.8321 - accuracy: 0.7294 - val_loss: 1.1497 - val_accuracy: 0.6513\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 52s 471ms/step - loss: 0.7870 - accuracy: 0.7224 - val_loss: 1.0259 - val_accuracy: 0.6659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.8335 - accuracy: 0.7247 - val_loss: 1.1995 - val_accuracy: 0.6187\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 0.8526 - accuracy: 0.7134 - val_loss: 1.1082 - val_accuracy: 0.6319\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.8914 - accuracy: 0.7178 - val_loss: 1.0534 - val_accuracy: 0.6459\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 54s 489ms/step - loss: 0.8394 - accuracy: 0.7077 - val_loss: 1.1749 - val_accuracy: 0.6094\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 55s 501ms/step - loss: 0.8446 - accuracy: 0.7246 - val_loss: 1.3130 - val_accuracy: 0.6087\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 0.8154 - accuracy: 0.7322 - val_loss: 1.1643 - val_accuracy: 0.6263\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 55s 501ms/step - loss: 0.8065 - accuracy: 0.7292 - val_loss: 1.3561 - val_accuracy: 0.5809\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 55s 503ms/step - loss: 0.8382 - accuracy: 0.7276 - val_loss: 1.0915 - val_accuracy: 0.6494\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 56s 514ms/step - loss: 0.8097 - accuracy: 0.7211 - val_loss: 1.1217 - val_accuracy: 0.6522\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.8424 - accuracy: 0.7273 - val_loss: 1.1361 - val_accuracy: 0.6497\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.8622 - accuracy: 0.7228 - val_loss: 1.1432 - val_accuracy: 0.6200\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.8951 - accuracy: 0.7119 - val_loss: 1.1471 - val_accuracy: 0.6284\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 56s 512ms/step - loss: 0.8529 - accuracy: 0.7212 - val_loss: 1.3529 - val_accuracy: 0.5906\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.8356 - accuracy: 0.7327 - val_loss: 1.4269 - val_accuracy: 0.5700\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 0.7711 - accuracy: 0.7417 - val_loss: 1.2338 - val_accuracy: 0.6162\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 59s 540ms/step - loss: 0.8701 - accuracy: 0.7047 - val_loss: 1.3473 - val_accuracy: 0.6019\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 60s 546ms/step - loss: 0.8021 - accuracy: 0.7190 - val_loss: 1.2531 - val_accuracy: 0.6091\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 59s 538ms/step - loss: 0.8021 - accuracy: 0.7280 - val_loss: 1.2103 - val_accuracy: 0.6203\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 0.7899 - accuracy: 0.7280 - val_loss: 1.2647 - val_accuracy: 0.6009\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 61s 553ms/step - loss: 0.8472 - accuracy: 0.7215 - val_loss: 1.1491 - val_accuracy: 0.6187\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 61s 552ms/step - loss: 0.7378 - accuracy: 0.7524 - val_loss: 1.3323 - val_accuracy: 0.6075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19785b79160>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv2.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd CV Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects_cv3)]\n",
    "df_val = df[df['subject'].isin(val_subjects_cv3)]\n",
    "\n",
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 validated image filenames belonging to 10 classes.\n",
      "Found 3200 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_cv3 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_cv3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_cv3.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_cv3 = tf.keras.models.Model(base_model_cv3.input, x)\n",
    "model_cv3.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_cv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model_cv3_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 47s 392ms/step - loss: 2.7424 - accuracy: 0.1260 - val_loss: 2.1902 - val_accuracy: 0.2503\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 44s 403ms/step - loss: 2.2875 - accuracy: 0.1674 - val_loss: 2.0469 - val_accuracy: 0.2606\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 39s 359ms/step - loss: 2.1808 - accuracy: 0.2044 - val_loss: 1.9034 - val_accuracy: 0.2828\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 39s 351ms/step - loss: 2.0851 - accuracy: 0.2625 - val_loss: 1.8203 - val_accuracy: 0.2703\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 37s 334ms/step - loss: 2.0092 - accuracy: 0.2835 - val_loss: 1.5902 - val_accuracy: 0.6275\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 41s 369ms/step - loss: 1.8904 - accuracy: 0.3277 - val_loss: 1.5494 - val_accuracy: 0.5044\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 37s 333ms/step - loss: 1.8185 - accuracy: 0.3682 - val_loss: 1.4213 - val_accuracy: 0.5922\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 36s 332ms/step - loss: 1.7808 - accuracy: 0.3786 - val_loss: 1.3834 - val_accuracy: 0.5519\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 37s 333ms/step - loss: 1.7483 - accuracy: 0.4066 - val_loss: 1.2389 - val_accuracy: 0.7019\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 37s 333ms/step - loss: 1.6779 - accuracy: 0.4144 - val_loss: 1.2249 - val_accuracy: 0.6097\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 37s 336ms/step - loss: 1.5734 - accuracy: 0.4669 - val_loss: 1.0901 - val_accuracy: 0.7056\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 37s 335ms/step - loss: 1.5565 - accuracy: 0.4645 - val_loss: 1.0833 - val_accuracy: 0.7053\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 37s 339ms/step - loss: 1.5027 - accuracy: 0.4904 - val_loss: 1.0770 - val_accuracy: 0.6819\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 37s 339ms/step - loss: 1.4728 - accuracy: 0.4792 - val_loss: 1.1048 - val_accuracy: 0.6275\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 37s 339ms/step - loss: 1.4040 - accuracy: 0.5094 - val_loss: 1.0503 - val_accuracy: 0.6556\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 38s 342ms/step - loss: 1.3868 - accuracy: 0.5142 - val_loss: 0.9751 - val_accuracy: 0.7022\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 38s 345ms/step - loss: 1.3054 - accuracy: 0.5651 - val_loss: 1.0243 - val_accuracy: 0.6444\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 38s 347ms/step - loss: 1.3524 - accuracy: 0.5353 - val_loss: 1.0019 - val_accuracy: 0.6591\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 39s 353ms/step - loss: 1.2856 - accuracy: 0.5563 - val_loss: 0.9595 - val_accuracy: 0.6919\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 39s 357ms/step - loss: 1.3061 - accuracy: 0.5718 - val_loss: 0.8685 - val_accuracy: 0.7131\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 40s 361ms/step - loss: 1.2295 - accuracy: 0.5706 - val_loss: 0.8921 - val_accuracy: 0.6994\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 40s 364ms/step - loss: 1.2838 - accuracy: 0.5693 - val_loss: 0.9173 - val_accuracy: 0.6712\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 40s 365ms/step - loss: 1.2139 - accuracy: 0.5812 - val_loss: 0.8151 - val_accuracy: 0.7184\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 40s 366ms/step - loss: 1.2021 - accuracy: 0.5906 - val_loss: 0.9006 - val_accuracy: 0.6791\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 41s 370ms/step - loss: 1.1439 - accuracy: 0.6195 - val_loss: 0.9485 - val_accuracy: 0.6609\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 42s 385ms/step - loss: 1.1959 - accuracy: 0.5815 - val_loss: 0.8741 - val_accuracy: 0.6825\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 41s 369ms/step - loss: 1.1181 - accuracy: 0.6452 - val_loss: 0.8907 - val_accuracy: 0.6831\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 41s 373ms/step - loss: 1.1748 - accuracy: 0.6100 - val_loss: 0.8790 - val_accuracy: 0.7134\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 41s 374ms/step - loss: 1.0787 - accuracy: 0.6302 - val_loss: 0.8541 - val_accuracy: 0.7088\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 41s 376ms/step - loss: 1.0563 - accuracy: 0.6449 - val_loss: 0.8164 - val_accuracy: 0.7081\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 42s 378ms/step - loss: 1.0448 - accuracy: 0.6596 - val_loss: 0.7839 - val_accuracy: 0.7334\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 42s 380ms/step - loss: 1.0521 - accuracy: 0.6442 - val_loss: 0.8248 - val_accuracy: 0.7009\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 43s 389ms/step - loss: 1.0362 - accuracy: 0.6678 - val_loss: 0.8497 - val_accuracy: 0.6831\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 42s 381ms/step - loss: 1.0618 - accuracy: 0.6327 - val_loss: 1.0196 - val_accuracy: 0.6316\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 42s 384ms/step - loss: 1.0542 - accuracy: 0.6429 - val_loss: 0.7747 - val_accuracy: 0.7306\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 43s 389ms/step - loss: 1.0364 - accuracy: 0.6647 - val_loss: 0.8428 - val_accuracy: 0.7044\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 42s 385ms/step - loss: 0.9909 - accuracy: 0.6640 - val_loss: 0.7519 - val_accuracy: 0.7409\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 45s 413ms/step - loss: 1.0599 - accuracy: 0.6521 - val_loss: 0.8176 - val_accuracy: 0.7138\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 43s 392ms/step - loss: 1.0347 - accuracy: 0.6527 - val_loss: 0.8531 - val_accuracy: 0.6969\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 43s 393ms/step - loss: 1.0244 - accuracy: 0.6609 - val_loss: 0.8513 - val_accuracy: 0.7041\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 44s 404ms/step - loss: 0.9389 - accuracy: 0.6819 - val_loss: 0.8300 - val_accuracy: 0.7034\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 44s 401ms/step - loss: 0.9281 - accuracy: 0.6843 - val_loss: 0.7131 - val_accuracy: 0.7613\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 45s 406ms/step - loss: 0.9405 - accuracy: 0.6816 - val_loss: 0.7511 - val_accuracy: 0.7400\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 45s 408ms/step - loss: 0.9209 - accuracy: 0.6860 - val_loss: 0.7790 - val_accuracy: 0.7322\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 45s 411ms/step - loss: 0.8863 - accuracy: 0.6890 - val_loss: 0.8107 - val_accuracy: 0.7141\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 45s 412ms/step - loss: 0.9171 - accuracy: 0.6926 - val_loss: 0.9022 - val_accuracy: 0.6913\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 47s 424ms/step - loss: 0.9019 - accuracy: 0.6878 - val_loss: 0.7578 - val_accuracy: 0.7322\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 46s 419ms/step - loss: 0.9548 - accuracy: 0.6835 - val_loss: 0.6809 - val_accuracy: 0.7706\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 47s 425ms/step - loss: 0.9116 - accuracy: 0.6838 - val_loss: 0.6887 - val_accuracy: 0.7594\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 46s 421ms/step - loss: 0.8839 - accuracy: 0.7001 - val_loss: 0.8160 - val_accuracy: 0.7128\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 47s 430ms/step - loss: 0.9416 - accuracy: 0.6955 - val_loss: 0.8358 - val_accuracy: 0.7034\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 48s 439ms/step - loss: 0.9144 - accuracy: 0.7044 - val_loss: 0.6867 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 48s 438ms/step - loss: 0.8814 - accuracy: 0.6945 - val_loss: 0.7005 - val_accuracy: 0.7550\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 49s 445ms/step - loss: 0.8540 - accuracy: 0.7196 - val_loss: 0.7444 - val_accuracy: 0.7409\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 48s 437ms/step - loss: 0.9517 - accuracy: 0.6916 - val_loss: 0.6748 - val_accuracy: 0.7584\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 48s 436ms/step - loss: 0.8685 - accuracy: 0.7105 - val_loss: 0.8528 - val_accuracy: 0.7106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "110/110 [==============================] - 49s 445ms/step - loss: 0.7982 - accuracy: 0.7274 - val_loss: 0.6788 - val_accuracy: 0.7487\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 51s 468ms/step - loss: 0.8453 - accuracy: 0.7117 - val_loss: 0.7735 - val_accuracy: 0.7166\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 52s 474ms/step - loss: 0.8337 - accuracy: 0.7278 - val_loss: 0.7113 - val_accuracy: 0.7397\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 50s 458ms/step - loss: 0.8714 - accuracy: 0.7237 - val_loss: 0.7467 - val_accuracy: 0.7425\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 52s 474ms/step - loss: 0.8897 - accuracy: 0.6924 - val_loss: 0.6816 - val_accuracy: 0.7694\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 51s 467ms/step - loss: 0.8193 - accuracy: 0.7173 - val_loss: 0.9177 - val_accuracy: 0.6747\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 52s 469ms/step - loss: 0.7908 - accuracy: 0.7470 - val_loss: 0.7168 - val_accuracy: 0.7362\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 54s 496ms/step - loss: 0.8504 - accuracy: 0.7119 - val_loss: 0.6851 - val_accuracy: 0.7622\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 53s 483ms/step - loss: 0.8191 - accuracy: 0.7352 - val_loss: 0.8887 - val_accuracy: 0.6841\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 53s 484ms/step - loss: 0.8134 - accuracy: 0.7285 - val_loss: 0.7582 - val_accuracy: 0.7303\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 54s 489ms/step - loss: 0.7701 - accuracy: 0.7331 - val_loss: 0.8275 - val_accuracy: 0.7059\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 0.7844 - accuracy: 0.7482 - val_loss: 0.7191 - val_accuracy: 0.7419\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 55s 497ms/step - loss: 0.8655 - accuracy: 0.7045 - val_loss: 0.7631 - val_accuracy: 0.7241\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.8048 - accuracy: 0.7464 - val_loss: 0.6327 - val_accuracy: 0.7759\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.7647 - accuracy: 0.7535 - val_loss: 0.6590 - val_accuracy: 0.7647\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 55s 504ms/step - loss: 0.7850 - accuracy: 0.7342 - val_loss: 0.7221 - val_accuracy: 0.7362\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.8326 - accuracy: 0.7395 - val_loss: 0.7763 - val_accuracy: 0.7334\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 0.7471 - accuracy: 0.7537 - val_loss: 0.6592 - val_accuracy: 0.7647\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.8475 - accuracy: 0.7219 - val_loss: 0.7184 - val_accuracy: 0.7412\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 57s 517ms/step - loss: 0.8175 - accuracy: 0.7332 - val_loss: 0.6292 - val_accuracy: 0.7819\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.8160 - accuracy: 0.7366 - val_loss: 0.7652 - val_accuracy: 0.7319\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 58s 530ms/step - loss: 0.7979 - accuracy: 0.7420 - val_loss: 0.7588 - val_accuracy: 0.7300\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.7686 - accuracy: 0.7498 - val_loss: 0.7111 - val_accuracy: 0.7387\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 59s 540ms/step - loss: 0.7499 - accuracy: 0.7496 - val_loss: 0.7194 - val_accuracy: 0.7506\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 0.7889 - accuracy: 0.7265 - val_loss: 0.7618 - val_accuracy: 0.7303\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 60s 545ms/step - loss: 0.6979 - accuracy: 0.7733 - val_loss: 0.7218 - val_accuracy: 0.7528\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 60s 547ms/step - loss: 0.8037 - accuracy: 0.7392 - val_loss: 0.7009 - val_accuracy: 0.7625\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 0.7265 - accuracy: 0.7798 - val_loss: 0.7244 - val_accuracy: 0.7456\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 61s 560ms/step - loss: 0.7850 - accuracy: 0.7351 - val_loss: 0.7377 - val_accuracy: 0.7525\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 61s 552ms/step - loss: 0.7998 - accuracy: 0.7239 - val_loss: 0.6795 - val_accuracy: 0.7659\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 61s 554ms/step - loss: 0.7883 - accuracy: 0.7488 - val_loss: 0.7709 - val_accuracy: 0.7356\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 63s 572ms/step - loss: 0.7635 - accuracy: 0.7529 - val_loss: 0.7172 - val_accuracy: 0.7566\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 62s 560ms/step - loss: 0.7239 - accuracy: 0.7625 - val_loss: 0.7233 - val_accuracy: 0.7578\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 64s 579ms/step - loss: 0.8018 - accuracy: 0.7496 - val_loss: 0.7130 - val_accuracy: 0.7647\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 0.7254 - accuracy: 0.7639 - val_loss: 0.8080 - val_accuracy: 0.7397\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 65s 593ms/step - loss: 0.7315 - accuracy: 0.7544 - val_loss: 0.7335 - val_accuracy: 0.7509\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 65s 588ms/step - loss: 0.7293 - accuracy: 0.7616 - val_loss: 0.7174 - val_accuracy: 0.7550\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 67s 614ms/step - loss: 0.7327 - accuracy: 0.7600 - val_loss: 0.7112 - val_accuracy: 0.7566\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 66s 599ms/step - loss: 0.7551 - accuracy: 0.7549 - val_loss: 0.8989 - val_accuracy: 0.7212\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 66s 605ms/step - loss: 0.7428 - accuracy: 0.7478 - val_loss: 0.6796 - val_accuracy: 0.7531\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 66s 603ms/step - loss: 0.7620 - accuracy: 0.7405 - val_loss: 0.7409 - val_accuracy: 0.7572\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 66s 600ms/step - loss: 0.7150 - accuracy: 0.7602 - val_loss: 0.6965 - val_accuracy: 0.7666\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7611"
     ]
    }
   ],
   "source": [
    "model_cv3.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th CV Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects_cv4)]\n",
    "df_val = df[df['subject'].isin(val_subjects_cv4)]\n",
    "\n",
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model_cv4 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_cv4.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_cv4.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_cv4 = tf.keras.models.Model(base_model_cv4.input, x)\n",
    "model_cv4.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_cv4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model_cv4_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv4.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th CV Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects_cv5)]\n",
    "df_val = df[df['subject'].isin(val_subjects_cv5)]\n",
    "\n",
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model_cv5 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_cv5.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_cv5.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_cv5 = tf.keras.models.Model(base_model_cv5.input, x)\n",
    "model_cv5.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_cv5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model_cv5_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv5.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_output = model_3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df = pd.DataFrame(test_nn_output, \n",
    "                              columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_filenames = os.listdir('D:\\\\Users\\\\Dylan\\\\Documents\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\imgs\\\\test\\\\test')\n",
    "test_filenames = pd.DataFrame({'filename':test_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.851118</td>\n",
       "      <td>0.080587</td>\n",
       "      <td>2.725571e-03</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.003962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.988080</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>4.734514e-05</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.442520</td>\n",
       "      <td>0.191491</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>8.597373e-02</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.227242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>4.882125e-05</td>\n",
       "      <td>0.964899</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.912742</td>\n",
       "      <td>0.070103</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>1.139908e-05</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.038359</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>8.648908e-01</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.035290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.020845</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.960031</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>8.723551e-06</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.955001</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>9.573871e-07</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.303719</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.448532</td>\n",
       "      <td>2.306005e-01</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.874217</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>3.652179e-05</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img        c0        c1        c2        c3        c4  \\\n",
       "0           img_1.jpg  0.001619  0.004821  0.011293  0.027774  0.004447   \n",
       "1          img_10.jpg  0.009783  0.000062  0.000048  0.001064  0.000109   \n",
       "2         img_100.jpg  0.442520  0.191491  0.027255  0.000582  0.000186   \n",
       "3        img_1000.jpg  0.000202  0.000092  0.032745  0.000010  0.000036   \n",
       "4      img_100000.jpg  0.013909  0.000152  0.000098  0.912742  0.070103   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "79721   img_99994.jpg  0.000934  0.038359  0.027704  0.000053  0.000013   \n",
       "79722   img_99995.jpg  0.020845  0.015850  0.000383  0.960031  0.000601   \n",
       "79723   img_99996.jpg  0.000387  0.019609  0.000071  0.955001  0.022456   \n",
       "79724   img_99998.jpg  0.000054  0.005063  0.303719  0.000002  0.000006   \n",
       "79725   img_99999.jpg  0.121082  0.000519  0.000056  0.000894  0.000026   \n",
       "\n",
       "             c5        c6            c7        c8        c9  \n",
       "0      0.851118  0.080587  2.725571e-03  0.011653  0.003962  \n",
       "1      0.988080  0.000144  4.734514e-05  0.000493  0.000171  \n",
       "2      0.003014  0.009266  8.597373e-02  0.012470  0.227242  \n",
       "3      0.000366  0.000595  4.882125e-05  0.964899  0.001007  \n",
       "4      0.000915  0.000669  1.139908e-05  0.001219  0.000180  \n",
       "...         ...       ...           ...       ...       ...  \n",
       "79721  0.004159  0.006234  8.648908e-01  0.022365  0.035290  \n",
       "79722  0.000080  0.000600  8.723551e-06  0.000224  0.001378  \n",
       "79723  0.000004  0.002145  9.573871e-07  0.000252  0.000074  \n",
       "79724  0.000013  0.448532  2.306005e-01  0.011783  0.000227  \n",
       "79725  0.874217  0.000096  3.652179e-05  0.002041  0.001033  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_df = test_filenames.join(test_predictions)\n",
    "test_predictions_df.rename(columns={'filename':'img'}, inplace=True)\n",
    "test_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df.to_csv('D:\\\\Users\\\\Dylan\\\\Documents\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\test_predictions(VGG16_Transfer_Learning_2).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from functions import cvmodeleval,samplecv, trainsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Set memory limit on GPU to keep it from freezing up when fitting TensorFlow models later\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 3 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], \\\n",
    "                                                                [tf.config.experimental.\\\n",
    "                                                                 VirtualDeviceConfiguration\\\n",
    "                                                                 (memory_limit=1024 * 4)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training filename dataframe\n",
    "df = pd.read_csv('data/processed/driver_image_list_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeled and unlabeled test filename dataframes\n",
    "df_test_labeled = pd.read_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/processed/labeled_test_df.csv')\n",
    "df_test = pd.read_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/test_filenames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to over/undersample classes occurance by subject so dataset is completely balanced.\n",
    "df = trainsampling(df, samples=80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path variables for data\n",
    "train_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/train'\n",
    "labeled_test_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/testlabeled'\n",
    "unlabeled_test_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 subjects were chosen from the training data to be used for validation during model training. These subjects represent one woman and man with dark skin and one woman and man with light skin. This is to help balance any potential racial bias in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of validation subjects\n",
    "val_subjects = ['p056', 'p050', 'p041', 'p016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects)]\n",
    "df_val = df[df['subject'].isin(val_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing and Data-Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataGenerators for training and test/validation data. Generators include randomized preprocessing for \n",
    "# called out parameters. Test_dgen will be used for both validation data and test data.\n",
    "\n",
    "train_dgen = ImageDataGenerator(samplewise_center=True,\n",
    "                                rescale=1./255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                channel_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_dgen = ImageDataGenerator(samplewise_center=True,\n",
    "                               rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 validated image filenames belonging to 10 classes.\n",
      "Found 3200 validated image filenames belonging to 10 classes.\n",
      "Found 200 validated image filenames belonging to 10 classes.\n",
      "Found 79726 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)\n",
    "\n",
    "test_labeled = test_dgen.flow_from_dataframe(df_test_labeled,\n",
    "                                             x_col='filename',\n",
    "                                             y_col='classname',\n",
    "                                             target_size=(227,227),\n",
    "                                             shuffle=False)\n",
    "\n",
    "test = test_dgen.flow_from_dataframe(df_test,\n",
    "                                     x_col='filename',\n",
    "                                     y_col='class',\n",
    "                                     target_size=(227,227),\n",
    "                                     shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1 - AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture below is based off of AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for initializing model\n",
    "def alexNet_arch(opt):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(99,\n",
    "                  kernel_size=11,\n",
    "                  strides=4,\n",
    "                  padding='valid',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                        strides=2,\n",
    "                        padding='valid'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer variable\n",
    "opt = RMSprop(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model_1\n",
    "model_1 = alexNet_arch(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model1_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 37s 323ms/step - loss: 6.9370 - accuracy: 0.0918 - val_loss: 2.4704 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 36s 326ms/step - loss: 2.7232 - accuracy: 0.0996 - val_loss: 2.3143 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 35s 320ms/step - loss: 2.4712 - accuracy: 0.1074 - val_loss: 2.3308 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 35s 319ms/step - loss: 2.4106 - accuracy: 0.1175 - val_loss: 2.3382 - val_accuracy: 0.0819\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 34s 312ms/step - loss: 2.3365 - accuracy: 0.1322 - val_loss: 2.2670 - val_accuracy: 0.1278\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 2.2182 - accuracy: 0.1680 - val_loss: 2.1761 - val_accuracy: 0.1900\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 2.1847 - accuracy: 0.1627 - val_loss: 2.0818 - val_accuracy: 0.2309\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 35s 320ms/step - loss: 2.1023 - accuracy: 0.1848 - val_loss: 1.9907 - val_accuracy: 0.2228\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 34s 307ms/step - loss: 2.0495 - accuracy: 0.2408 - val_loss: 1.8269 - val_accuracy: 0.3141\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 1.9844 - accuracy: 0.2580 - val_loss: 1.8713 - val_accuracy: 0.2309\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 1.9225 - accuracy: 0.2545 - val_loss: 2.1298 - val_accuracy: 0.3403\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.8979 - accuracy: 0.2744 - val_loss: 1.8953 - val_accuracy: 0.2503\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.8064 - accuracy: 0.2888 - val_loss: 1.8129 - val_accuracy: 0.4009\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.7552 - accuracy: 0.3207 - val_loss: 2.0009 - val_accuracy: 0.3169\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 1.6673 - accuracy: 0.3460 - val_loss: 2.1884 - val_accuracy: 0.3591\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 1.6882 - accuracy: 0.3380 - val_loss: 1.5826 - val_accuracy: 0.3728\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.6024 - accuracy: 0.3839 - val_loss: 1.7211 - val_accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.6260 - accuracy: 0.3626 - val_loss: 1.6332 - val_accuracy: 0.4556\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 33s 305ms/step - loss: 1.4911 - accuracy: 0.4248 - val_loss: 1.4591 - val_accuracy: 0.4403\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 33s 298ms/step - loss: 1.5116 - accuracy: 0.4450 - val_loss: 1.6147 - val_accuracy: 0.4241\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 1.4967 - accuracy: 0.4111 - val_loss: 2.6076 - val_accuracy: 0.3853\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.5100 - accuracy: 0.4253 - val_loss: 1.6006 - val_accuracy: 0.4572\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 1.3689 - accuracy: 0.4725 - val_loss: 1.5605 - val_accuracy: 0.3922\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 33s 303ms/step - loss: 1.4382 - accuracy: 0.4313 - val_loss: 2.1730 - val_accuracy: 0.4162\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.3154 - accuracy: 0.4958 - val_loss: 1.3790 - val_accuracy: 0.4725\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.2592 - accuracy: 0.5069 - val_loss: 2.0544 - val_accuracy: 0.4209\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 34s 305ms/step - loss: 1.2776 - accuracy: 0.4922 - val_loss: 1.3580 - val_accuracy: 0.5391\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 1.2141 - accuracy: 0.5467 - val_loss: 2.7274 - val_accuracy: 0.4297\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.2181 - accuracy: 0.5566 - val_loss: 1.7309 - val_accuracy: 0.4519\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.1889 - accuracy: 0.5543 - val_loss: 1.9721 - val_accuracy: 0.4659\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 33s 304ms/step - loss: 1.1153 - accuracy: 0.5788 - val_loss: 2.2953 - val_accuracy: 0.5484\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.1607 - accuracy: 0.5432 - val_loss: 2.1510 - val_accuracy: 0.4722\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.0466 - accuracy: 0.6067 - val_loss: 2.1928 - val_accuracy: 0.5200\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.0721 - accuracy: 0.6115 - val_loss: 3.5886 - val_accuracy: 0.4822\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.0939 - accuracy: 0.6083 - val_loss: 1.2664 - val_accuracy: 0.5797\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 1.0112 - accuracy: 0.6376 - val_loss: 3.8568 - val_accuracy: 0.34030111 - ac\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.9635 - accuracy: 0.6643 - val_loss: 1.8653 - val_accuracy: 0.5362- loss: - ETA: 0s - loss: 0.9634 - accuracy: 0.\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.9672 - accuracy: 0.6250 - val_loss: 4.3620 - val_accuracy: 0.5213\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.9016 - accuracy: 0.6907 - val_loss: 1.5191 - val_accuracy: 0.5622\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.9299 - accuracy: 0.6766 - val_loss: 1.8797 - val_accuracy: 0.5406\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.9072 - accuracy: 0.6725 - val_loss: 1.5550 - val_accuracy: 0.5744\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.8576 - accuracy: 0.7003 - val_loss: 1.2470 - val_accuracy: 0.5897\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.7888 - accuracy: 0.7128 - val_loss: 1.7872 - val_accuracy: 0.6278\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.8785 - accuracy: 0.7049 - val_loss: 1.6290 - val_accuracy: 0.6516\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.8114 - accuracy: 0.7252 - val_loss: 1.3758 - val_accuracy: 0.6003\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.8449 - accuracy: 0.7165 - val_loss: 3.1881 - val_accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 32s 286ms/step - loss: 0.7990 - accuracy: 0.7181 - val_loss: 1.2954 - val_accuracy: 0.6356\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7620 - accuracy: 0.7261 - val_loss: 1.0843 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7879 - accuracy: 0.7454 - val_loss: 2.5816 - val_accuracy: 0.6044\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.6449 - accuracy: 0.7890 - val_loss: 2.4861 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7814 - accuracy: 0.7390 - val_loss: 3.0154 - val_accuracy: 0.4925\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7237 - accuracy: 0.7633 - val_loss: 1.8533 - val_accuracy: 0.6072\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.6905 - accuracy: 0.7591 - val_loss: 1.3254 - val_accuracy: 0.6137\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.7218 - accuracy: 0.7610 - val_loss: 3.5828 - val_accuracy: 0.5547\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.7115 - accuracy: 0.7712 - val_loss: 2.0833 - val_accuracy: 0.5666\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6871 - accuracy: 0.7649 - val_loss: 3.9417 - val_accuracy: 0.5825\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.7307 - accuracy: 0.7818 - val_loss: 1.1655 - val_accuracy: 0.6803\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.6096 - accuracy: 0.7805 - val_loss: 1.3496 - val_accuracy: 0.5738\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.6752 - accuracy: 0.7550 - val_loss: 2.7699 - val_accuracy: 0.6125\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 32s 292ms/step - loss: 0.6621 - accuracy: 0.7665 - val_loss: 0.9719 - val_accuracy: 0.6928\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6555 - accuracy: 0.7714 - val_loss: 1.6889 - val_accuracy: 0.6097: 0.6557 - accuracy: 0.\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6568 - accuracy: 0.7847 - val_loss: 1.0797 - val_accuracy: 0.6553\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 32s 292ms/step - loss: 0.5286 - accuracy: 0.8196 - val_loss: 3.4980 - val_accuracy: 0.5675\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5640 - accuracy: 0.8030 - val_loss: 2.0961 - val_accuracy: 0.6269\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 32s 290ms/step - loss: 0.5747 - accuracy: 0.8205 - val_loss: 1.9404 - val_accuracy: 0.6381\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.6131 - accuracy: 0.8072 - val_loss: 1.0244 - val_accuracy: 0.7038\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 0.6409 - accuracy: 0.8094 - val_loss: 1.2645 - val_accuracy: 0.7022\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 32s 291ms/step - loss: 0.5321 - accuracy: 0.8291 - val_loss: 1.0098 - val_accuracy: 0.7075\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 0.5949 - accuracy: 0.8158 - val_loss: 1.5364 - val_accuracy: 0.6219\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 33s 296ms/step - loss: 0.5694 - accuracy: 0.8236 - val_loss: 1.2908 - val_accuracy: 0.6587\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5534 - accuracy: 0.8104 - val_loss: 1.5745 - val_accuracy: 0.6662\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.4999 - accuracy: 0.8354 - val_loss: 6.3533 - val_accuracy: 0.5203\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.5988 - accuracy: 0.8055 - val_loss: 1.9124 - val_accuracy: 0.6078\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 0.6210 - accuracy: 0.7965 - val_loss: 1.0781 - val_accuracy: 0.6884\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 32s 291ms/step - loss: 0.5594 - accuracy: 0.8237 - val_loss: 1.2082 - val_accuracy: 0.6325\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.4701 - accuracy: 0.8397 - val_loss: 2.0178 - val_accuracy: 0.6169\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 0.5477 - accuracy: 0.8369 - val_loss: 2.1251 - val_accuracy: 0.6300\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.6061 - accuracy: 0.8016 - val_loss: 2.4876 - val_accuracy: 0.6166\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.5179 - accuracy: 0.8301 - val_loss: 1.1209 - val_accuracy: 0.7175\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.5503 - accuracy: 0.8343 - val_loss: 1.2862 - val_accuracy: 0.6447\n",
      "Wall time: 44min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ed51c4400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train model_1\n",
    "model_1.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_1.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to a dataframe with original labeles\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_1_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 10s 105ms/step - loss: 0.9719 - accuracy: 0.6928\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_1_val_metrics = model_1.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_1_val_metrics[0]], \n",
    "                                    'Accuracy':[model_1_val_metrics[1]]})\n",
    "model_1_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_1_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971922</td>\n",
       "      <td>0.692813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0            0.971922  0.692813"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9719 cross-entropy loss and 0.6928 accuracy are not a bad start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Xception Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a method desribed at this url (https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/), I loaded a pre-trained Xception model through keras with weights optimized for imagenet. I made all of the existing layers non-trainable and then added a few trainable layers which will be fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 227, 227, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 113, 113, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 113, 113, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 113, 113, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 111, 111, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 111, 111, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 111, 111, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 111, 111, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 111, 111, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 111, 111, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 111, 111, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 111, 111, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 56, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 56, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 56, 56, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 56, 56, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 56, 56, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 56, 56, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          51380736    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 72,247,346\n",
      "Trainable params: 51,385,866\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_2 = tf.keras.applications.Xception(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_2.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_2 = tf.keras.models.Model(base_model_2.input, x)\n",
    "model_2.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model2_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 71s 647ms/step - loss: 2.8249 - accuracy: 0.1415 - val_loss: 2.1583 - val_accuracy: 0.2169\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 60s 549ms/step - loss: 2.3187 - accuracy: 0.1727 - val_loss: 2.2208 - val_accuracy: 0.2288\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 62s 560ms/step - loss: 2.1792 - accuracy: 0.2364 - val_loss: 2.4904 - val_accuracy: 0.1937\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 60s 548ms/step - loss: 2.1252 - accuracy: 0.2557 - val_loss: 2.3664 - val_accuracy: 0.2147\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 2.0460 - accuracy: 0.3051 - val_loss: 2.4786 - val_accuracy: 0.2256\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 1.9675 - accuracy: 0.3210 - val_loss: 2.5725 - val_accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.9526 - accuracy: 0.3301 - val_loss: 2.5295 - val_accuracy: 0.2122\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.8587 - accuracy: 0.3682 - val_loss: 2.5472 - val_accuracy: 0.2769\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 1.8533 - accuracy: 0.3812 - val_loss: 2.8614 - val_accuracy: 0.2166\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 1.7944 - accuracy: 0.4011 - val_loss: 2.6684 - val_accuracy: 0.2356\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.8344 - accuracy: 0.3812 - val_loss: 3.1513 - val_accuracy: 0.1700\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.7937 - accuracy: 0.3932 - val_loss: 2.8103 - val_accuracy: 0.2384\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.7601 - accuracy: 0.4131 - val_loss: 3.1716 - val_accuracy: 0.2109\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.6830 - accuracy: 0.4295 - val_loss: 3.0304 - val_accuracy: 0.2269\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 1.6815 - accuracy: 0.4347 - val_loss: 3.2372 - val_accuracy: 0.2266\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.6595 - accuracy: 0.4472 - val_loss: 3.4794 - val_accuracy: 0.2262\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 1.6560 - accuracy: 0.4392 - val_loss: 3.7069 - val_accuracy: 0.2525\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.6152 - accuracy: 0.4466 - val_loss: 3.3362 - val_accuracy: 0.2156\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.5994 - accuracy: 0.4517 - val_loss: 3.3340 - val_accuracy: 0.2119\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 1.5447 - accuracy: 0.4710 - val_loss: 4.2985 - val_accuracy: 0.1969\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.6734 - accuracy: 0.4443 - val_loss: 4.0363 - val_accuracy: 0.2087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ba027de48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_2.predict(val)\n",
    "\n",
    "# Convert to a dataframe with original labels\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_2_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 2.1583 - accuracy: 0.2169\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_2_val_metrics = model_2.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_2_val_metrics[0]], \n",
    "                                    'Accuracy':[model_2_val_metrics[1]]})\n",
    "model_2_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_2_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.15828</td>\n",
       "      <td>0.216875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0             2.15828  0.216875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - VGG16 Transfer-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_3 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_3.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_3 = tf.keras.models.Model(base_model_3.input, x)\n",
    "model_3.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 63s 569ms/step - loss: 2.5059 - accuracy: 0.1324 - val_loss: 2.1846 - val_accuracy: 0.1606\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 59s 541ms/step - loss: 2.2511 - accuracy: 0.1653 - val_loss: 2.0830 - val_accuracy: 0.2734\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 59s 538ms/step - loss: 2.1532 - accuracy: 0.2284 - val_loss: 1.9477 - val_accuracy: 0.2266\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 2.1002 - accuracy: 0.2295 - val_loss: 1.8449 - val_accuracy: 0.3663\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 59s 537ms/step - loss: 1.9959 - accuracy: 0.2886 - val_loss: 1.6320 - val_accuracy: 0.5341\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 1.9342 - accuracy: 0.3034 - val_loss: 1.5335 - val_accuracy: 0.6256\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.8685 - accuracy: 0.3528 - val_loss: 1.5222 - val_accuracy: 0.5369\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 58s 525ms/step - loss: 1.7947 - accuracy: 0.3693 - val_loss: 1.3815 - val_accuracy: 0.6181\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.6574 - accuracy: 0.4341 - val_loss: 1.3276 - val_accuracy: 0.6159\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 1.6994 - accuracy: 0.4136 - val_loss: 1.2882 - val_accuracy: 0.6109\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 1.6211 - accuracy: 0.4517 - val_loss: 1.2407 - val_accuracy: 0.5769\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.5630 - accuracy: 0.4597 - val_loss: 1.1015 - val_accuracy: 0.7384\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 1.5050 - accuracy: 0.4801 - val_loss: 1.1019 - val_accuracy: 0.6950\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 1.4783 - accuracy: 0.4892 - val_loss: 1.2250 - val_accuracy: 0.5638\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.4343 - accuracy: 0.5261 - val_loss: 1.0464 - val_accuracy: 0.6612\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 1.4105 - accuracy: 0.5102 - val_loss: 0.9985 - val_accuracy: 0.7241\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.3692 - accuracy: 0.5278 - val_loss: 1.0238 - val_accuracy: 0.6775\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 56s 513ms/step - loss: 1.3585 - accuracy: 0.5330 - val_loss: 0.9533 - val_accuracy: 0.7362\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.3233 - accuracy: 0.5449 - val_loss: 1.0242 - val_accuracy: 0.6547\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 1.2883 - accuracy: 0.5665 - val_loss: 0.9397 - val_accuracy: 0.7272\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 1.2685 - accuracy: 0.5767 - val_loss: 0.9362 - val_accuracy: 0.7056\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 1.2557 - accuracy: 0.5705 - val_loss: 0.8747 - val_accuracy: 0.7334\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 55s 498ms/step - loss: 1.2587 - accuracy: 0.5744 - val_loss: 0.9221 - val_accuracy: 0.7116\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 55s 500ms/step - loss: 1.2557 - accuracy: 0.5778 - val_loss: 0.9435 - val_accuracy: 0.7075\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 55s 502ms/step - loss: 1.1779 - accuracy: 0.6017 - val_loss: 1.0846 - val_accuracy: 0.6075\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.1667 - accuracy: 0.6028 - val_loss: 0.9744 - val_accuracy: 0.6831\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.1335 - accuracy: 0.6187 - val_loss: 0.9020 - val_accuracy: 0.7016\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 1.1551 - accuracy: 0.6034 - val_loss: 0.9316 - val_accuracy: 0.6975\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 63s 570ms/step - loss: 1.1354 - accuracy: 0.6193 - val_loss: 0.8170 - val_accuracy: 0.7541\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 58s 530ms/step - loss: 1.0773 - accuracy: 0.6386 - val_loss: 0.7890 - val_accuracy: 0.7556\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0984 - accuracy: 0.6187 - val_loss: 1.0447 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 1.0777 - accuracy: 0.6403 - val_loss: 0.9368 - val_accuracy: 0.7003\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 58s 523ms/step - loss: 1.0628 - accuracy: 0.6494 - val_loss: 0.8261 - val_accuracy: 0.7578\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 60s 545ms/step - loss: 1.0540 - accuracy: 0.6415 - val_loss: 1.0391 - val_accuracy: 0.6538\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 1.0416 - accuracy: 0.6608 - val_loss: 0.9632 - val_accuracy: 0.6944\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.9996 - accuracy: 0.6591 - val_loss: 0.8432 - val_accuracy: 0.7303\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0333 - accuracy: 0.6602 - val_loss: 0.8632 - val_accuracy: 0.7194\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0168 - accuracy: 0.6597 - val_loss: 0.9146 - val_accuracy: 0.6700\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.9422 - accuracy: 0.6801 - val_loss: 0.9312 - val_accuracy: 0.6928\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.9547 - accuracy: 0.6824 - val_loss: 0.8237 - val_accuracy: 0.7566\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.9504 - accuracy: 0.6801 - val_loss: 0.8506 - val_accuracy: 0.7231\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9649 - accuracy: 0.6722 - val_loss: 0.9130 - val_accuracy: 0.6844\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9749 - accuracy: 0.6756 - val_loss: 0.8606 - val_accuracy: 0.7175\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.9777 - accuracy: 0.6727 - val_loss: 0.8787 - val_accuracy: 0.7169\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 59s 539ms/step - loss: 0.9161 - accuracy: 0.6926 - val_loss: 0.7318 - val_accuracy: 0.7569\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.9721 - accuracy: 0.6699 - val_loss: 0.8721 - val_accuracy: 0.6997\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.9386 - accuracy: 0.6812 - val_loss: 0.8388 - val_accuracy: 0.7153\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9135 - accuracy: 0.6960 - val_loss: 0.8732 - val_accuracy: 0.6919\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.8933 - accuracy: 0.7006 - val_loss: 0.8399 - val_accuracy: 0.7178\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.9312 - accuracy: 0.6960 - val_loss: 0.8972 - val_accuracy: 0.6975\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.9067 - accuracy: 0.7006 - val_loss: 0.8612 - val_accuracy: 0.7234\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.9091 - accuracy: 0.6898 - val_loss: 0.8654 - val_accuracy: 0.7147\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.8836 - accuracy: 0.6926 - val_loss: 1.0139 - val_accuracy: 0.6822\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.9084 - accuracy: 0.6994 - val_loss: 0.8808 - val_accuracy: 0.6988\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.8851 - accuracy: 0.7000 - val_loss: 0.8380 - val_accuracy: 0.7188\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 0.8359 - accuracy: 0.7199 - val_loss: 0.9066 - val_accuracy: 0.6913\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 60s 544ms/step - loss: 0.8708 - accuracy: 0.7142 - val_loss: 0.8984 - val_accuracy: 0.6897\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 59s 539ms/step - loss: 0.8583 - accuracy: 0.7125 - val_loss: 0.8167 - val_accuracy: 0.7334\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 0.8788 - accuracy: 0.7142 - val_loss: 0.8421 - val_accuracy: 0.7034\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 60s 547ms/step - loss: 0.8753 - accuracy: 0.7028 - val_loss: 0.8929 - val_accuracy: 0.6784\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 0.8081 - accuracy: 0.7312 - val_loss: 0.9423 - val_accuracy: 0.6841\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 0.8400 - accuracy: 0.7193 - val_loss: 0.8140 - val_accuracy: 0.7406\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.8432 - accuracy: 0.7159 - val_loss: 0.7726 - val_accuracy: 0.7328\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.8556 - accuracy: 0.7182 - val_loss: 0.8617 - val_accuracy: 0.6963\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.8331 - accuracy: 0.7295 - val_loss: 0.9490 - val_accuracy: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x204e7f42d08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I renamed the weight file for this first run to model3_weights_first_run.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 59s 537ms/step - loss: 0.9516 - accuracy: 0.6835 - val_loss: 0.9357 - val_accuracy: 0.6862\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 59s 538ms/step - loss: 0.9273 - accuracy: 0.6972 - val_loss: 0.8685 - val_accuracy: 0.7056\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.9531 - accuracy: 0.7017 - val_loss: 0.9524 - val_accuracy: 0.6603\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 0.8974 - accuracy: 0.6977 - val_loss: 0.8452 - val_accuracy: 0.7459\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 56s 512ms/step - loss: 0.9220 - accuracy: 0.6932 - val_loss: 0.8573 - val_accuracy: 0.7159\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9031 - accuracy: 0.6949 - val_loss: 0.8959 - val_accuracy: 0.6862\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 59s 540ms/step - loss: 0.8845 - accuracy: 0.7091 - val_loss: 0.8056 - val_accuracy: 0.7175\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 61s 550ms/step - loss: 0.8904 - accuracy: 0.6972 - val_loss: 0.8229 - val_accuracy: 0.6991\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 61s 551ms/step - loss: 0.8907 - accuracy: 0.7080 - val_loss: 0.7741 - val_accuracy: 0.7234\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 60s 545ms/step - loss: 0.8696 - accuracy: 0.7051 - val_loss: 0.8858 - val_accuracy: 0.6859\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 61s 557ms/step - loss: 0.8589 - accuracy: 0.7091 - val_loss: 0.8691 - val_accuracy: 0.7103\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 60s 546ms/step - loss: 0.8406 - accuracy: 0.7227 - val_loss: 0.8444 - val_accuracy: 0.7128\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 61s 553ms/step - loss: 0.8355 - accuracy: 0.7119 - val_loss: 0.7885 - val_accuracy: 0.7306\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 60s 542ms/step - loss: 0.8347 - accuracy: 0.7159 - val_loss: 1.0079 - val_accuracy: 0.6809\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.8520 - accuracy: 0.7114 - val_loss: 0.9718 - val_accuracy: 0.6869\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 60s 545ms/step - loss: 0.8593 - accuracy: 0.7261 - val_loss: 0.8792 - val_accuracy: 0.6959\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 61s 559ms/step - loss: 0.8725 - accuracy: 0.7233 - val_loss: 0.8631 - val_accuracy: 0.7084\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 62s 560ms/step - loss: 0.8617 - accuracy: 0.7170 - val_loss: 0.9534 - val_accuracy: 0.6847\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.8130 - accuracy: 0.7381 - val_loss: 0.7799 - val_accuracy: 0.7350\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 57s 517ms/step - loss: 0.7994 - accuracy: 0.7375 - val_loss: 0.8648 - val_accuracy: 0.7269\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 0.8110 - accuracy: 0.7222 - val_loss: 0.8349 - val_accuracy: 0.7306\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.8328 - accuracy: 0.7347 - val_loss: 0.7877 - val_accuracy: 0.7462\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.7862 - accuracy: 0.7358 - val_loss: 0.9183 - val_accuracy: 0.6916\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.8043 - accuracy: 0.7472 - val_loss: 0.7926 - val_accuracy: 0.7297\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 58s 525ms/step - loss: 0.7775 - accuracy: 0.7420 - val_loss: 0.8631 - val_accuracy: 0.7222\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 61s 555ms/step - loss: 0.7521 - accuracy: 0.7432 - val_loss: 0.9266 - val_accuracy: 0.6906\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.7765 - accuracy: 0.7403 - val_loss: 1.1005 - val_accuracy: 0.6422\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 58s 523ms/step - loss: 0.8085 - accuracy: 0.7273 - val_loss: 0.8587 - val_accuracy: 0.7266\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 57s 517ms/step - loss: 0.8389 - accuracy: 0.7153 - val_loss: 0.8514 - val_accuracy: 0.7303\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 59s 540ms/step - loss: 0.7713 - accuracy: 0.7472 - val_loss: 0.9035 - val_accuracy: 0.7250\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 59s 532ms/step - loss: 0.7655 - accuracy: 0.7545 - val_loss: 0.8251 - val_accuracy: 0.7387\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 58s 523ms/step - loss: 0.7564 - accuracy: 0.7403 - val_loss: 0.8268 - val_accuracy: 0.7272\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.7947 - accuracy: 0.7295 - val_loss: 0.8555 - val_accuracy: 0.7303\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 0.7826 - accuracy: 0.7369 - val_loss: 0.8359 - val_accuracy: 0.7409\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.7410 - accuracy: 0.7523 - val_loss: 0.7400 - val_accuracy: 0.7578\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.7879 - accuracy: 0.7398 - val_loss: 0.7665 - val_accuracy: 0.7634\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.6996 - accuracy: 0.7551 - val_loss: 0.8283 - val_accuracy: 0.7631\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7735 - accuracy: 0.7477 - val_loss: 0.9233 - val_accuracy: 0.7181\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.7557 - accuracy: 0.7426 - val_loss: 0.9577 - val_accuracy: 0.7078\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 0.7578 - accuracy: 0.7511 - val_loss: 0.9948 - val_accuracy: 0.6731\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 0.7998 - accuracy: 0.7420 - val_loss: 0.8811 - val_accuracy: 0.7269\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 0.7234 - accuracy: 0.7705 - val_loss: 0.7672 - val_accuracy: 0.7484\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7505 - accuracy: 0.7557 - val_loss: 1.0125 - val_accuracy: 0.6716\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.7573 - accuracy: 0.7449 - val_loss: 1.1049 - val_accuracy: 0.6594\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7792 - accuracy: 0.7511 - val_loss: 0.9465 - val_accuracy: 0.7153\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.7180 - accuracy: 0.7688 - val_loss: 0.8894 - val_accuracy: 0.7088\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7405 - accuracy: 0.7563 - val_loss: 0.8344 - val_accuracy: 0.7416\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.6837 - accuracy: 0.7756 - val_loss: 0.7712 - val_accuracy: 0.7647\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7265 - accuracy: 0.7602 - val_loss: 0.7739 - val_accuracy: 0.7578\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7511 - accuracy: 0.7602 - val_loss: 0.8634 - val_accuracy: 0.7297\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7423 - accuracy: 0.7602 - val_loss: 0.9762 - val_accuracy: 0.6897\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7113 - accuracy: 0.7608 - val_loss: 0.9444 - val_accuracy: 0.7144\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7191 - accuracy: 0.7727 - val_loss: 0.8761 - val_accuracy: 0.7516\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7416 - accuracy: 0.7682 - val_loss: 0.8968 - val_accuracy: 0.7287\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7343 - accuracy: 0.7585 - val_loss: 0.8584 - val_accuracy: 0.7191\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 56s 512ms/step - loss: 0.7310 - accuracy: 0.7688 - val_loss: 0.8474 - val_accuracy: 0.7191\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.7133 - accuracy: 0.7727 - val_loss: 0.9263 - val_accuracy: 0.7231\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 56s 513ms/step - loss: 0.7189 - accuracy: 0.7597 - val_loss: 0.9608 - val_accuracy: 0.6919\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.7463 - accuracy: 0.7716 - val_loss: 0.9073 - val_accuracy: 0.7328\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 56s 512ms/step - loss: 0.7278 - accuracy: 0.7631 - val_loss: 0.9813 - val_accuracy: 0.7300\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 57s 517ms/step - loss: 0.6926 - accuracy: 0.7744 - val_loss: 0.9074 - val_accuracy: 0.7384\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.7225 - accuracy: 0.7648 - val_loss: 0.9086 - val_accuracy: 0.7312\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 56s 513ms/step - loss: 0.7372 - accuracy: 0.7693 - val_loss: 0.9009 - val_accuracy: 0.7309\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 0.7607 - accuracy: 0.7415 - val_loss: 0.9833 - val_accuracy: 0.7059\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 0.6980 - accuracy: 0.7648 - val_loss: 0.8970 - val_accuracy: 0.7116\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7546 - accuracy: 0.7500 - val_loss: 0.9046 - val_accuracy: 0.7375\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.7056 - accuracy: 0.7653 - val_loss: 0.9161 - val_accuracy: 0.7225\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.6911 - accuracy: 0.7648 - val_loss: 0.9705 - val_accuracy: 0.7169\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.7045 - accuracy: 0.7693 - val_loss: 0.9774 - val_accuracy: 0.7331\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 59s 540ms/step - loss: 0.7319 - accuracy: 0.7670 - val_loss: 1.0336 - val_accuracy: 0.7294\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7051 - accuracy: 0.7705 - val_loss: 1.0805 - val_accuracy: 0.7119\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 57s 517ms/step - loss: 0.6914 - accuracy: 0.7909 - val_loss: 0.9155 - val_accuracy: 0.7362\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.7393 - accuracy: 0.7597 - val_loss: 1.0520 - val_accuracy: 0.7166\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.6591 - accuracy: 0.7955 - val_loss: 0.9242 - val_accuracy: 0.7337\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.7104 - accuracy: 0.7636 - val_loss: 1.0277 - val_accuracy: 0.7084\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.7538 - accuracy: 0.7653 - val_loss: 0.9600 - val_accuracy: 0.7212\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 59s 532ms/step - loss: 0.7159 - accuracy: 0.7739 - val_loss: 0.9283 - val_accuracy: 0.7237\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 59s 537ms/step - loss: 0.6470 - accuracy: 0.7847 - val_loss: 0.9577 - val_accuracy: 0.7462\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 56s 513ms/step - loss: 0.6867 - accuracy: 0.7841 - val_loss: 0.8646 - val_accuracy: 0.7481\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 0.7237 - accuracy: 0.7795 - val_loss: 0.9388 - val_accuracy: 0.7434\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 56s 514ms/step - loss: 0.7373 - accuracy: 0.7676 - val_loss: 0.8691 - val_accuracy: 0.7528\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.6538 - accuracy: 0.7858 - val_loss: 1.0553 - val_accuracy: 0.7044\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.6830 - accuracy: 0.7744 - val_loss: 1.1170 - val_accuracy: 0.7216\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.7211 - accuracy: 0.7727 - val_loss: 1.0249 - val_accuracy: 0.7141\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.6730 - accuracy: 0.7977 - val_loss: 0.8986 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205a9fdb4c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model further and see if it improves\n",
    "model_3.fit(train,\n",
    "            epochs=200,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I renamed the weight file for this second run to model3_weights_second_run.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the learning rate from 0.0001 to 0.00001, reload the weights from the first run, and then see if it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change learning rate\n",
    "K.set_value(model_3.optimizer.learning_rate, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from first run\n",
    "model_3.load_weights('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights_first_run.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update callbacks_list. Remove earlystop. Have run for 600 epochs overnight.\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights_third_run.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/600\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.8752 - accuracy: 0.7142 - val_loss: 0.8257 - val_accuracy: 0.7159\n",
      "Epoch 2/600\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.8403 - accuracy: 0.7347 - val_loss: 0.8300 - val_accuracy: 0.7113\n",
      "Epoch 3/600\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.8288 - accuracy: 0.7284 - val_loss: 0.8105 - val_accuracy: 0.7116\n",
      "Epoch 4/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.8112 - accuracy: 0.7455 - val_loss: 0.8121 - val_accuracy: 0.7194\n",
      "Epoch 5/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.8394 - accuracy: 0.7239 - val_loss: 0.8258 - val_accuracy: 0.7078\n",
      "Epoch 6/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.8219 - accuracy: 0.7426 - val_loss: 0.8315 - val_accuracy: 0.7075\n",
      "Epoch 7/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.7716 - accuracy: 0.7517 - val_loss: 0.8428 - val_accuracy: 0.7038\n",
      "Epoch 8/600\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 0.8392 - accuracy: 0.7182 - val_loss: 0.8100 - val_accuracy: 0.7200\n",
      "Epoch 9/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.8517 - accuracy: 0.7290 - val_loss: 0.8270 - val_accuracy: 0.7169\n",
      "Epoch 10/600\n",
      "110/110 [==============================] - 60s 546ms/step - loss: 0.7863 - accuracy: 0.7398 - val_loss: 0.7977 - val_accuracy: 0.7222\n",
      "Epoch 11/600\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 0.7673 - accuracy: 0.7551 - val_loss: 0.7946 - val_accuracy: 0.7291\n",
      "Epoch 12/600\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.8544 - accuracy: 0.7250 - val_loss: 0.7875 - val_accuracy: 0.7306\n",
      "Epoch 13/600\n",
      "110/110 [==============================] - 55s 498ms/step - loss: 0.8419 - accuracy: 0.7449 - val_loss: 0.8224 - val_accuracy: 0.7109\n",
      "Epoch 14/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8498 - accuracy: 0.7278 - val_loss: 0.8433 - val_accuracy: 0.7059\n",
      "Epoch 15/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.8426 - accuracy: 0.7443 - val_loss: 0.8178 - val_accuracy: 0.7128\n",
      "Epoch 16/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8030 - accuracy: 0.7443 - val_loss: 0.7983 - val_accuracy: 0.7259\n",
      "Epoch 17/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8394 - accuracy: 0.7330 - val_loss: 0.8097 - val_accuracy: 0.7228\n",
      "Epoch 18/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7948 - accuracy: 0.7466 - val_loss: 0.8013 - val_accuracy: 0.7178\n",
      "Epoch 19/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7995 - accuracy: 0.7483 - val_loss: 0.8345 - val_accuracy: 0.7163\n",
      "Epoch 20/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8071 - accuracy: 0.7608 - val_loss: 0.8503 - val_accuracy: 0.7016\n",
      "Epoch 21/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.7602 - accuracy: 0.7614 - val_loss: 0.8029 - val_accuracy: 0.7241\n",
      "Epoch 22/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.8021 - accuracy: 0.7381 - val_loss: 0.8100 - val_accuracy: 0.7281\n",
      "Epoch 23/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7800 - accuracy: 0.7568 - val_loss: 0.8578 - val_accuracy: 0.7059\n",
      "Epoch 24/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7778 - accuracy: 0.7523 - val_loss: 0.8108 - val_accuracy: 0.7222\n",
      "Epoch 25/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.7814 - accuracy: 0.7489 - val_loss: 0.8269 - val_accuracy: 0.7150\n",
      "Epoch 26/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7861 - accuracy: 0.7437 - val_loss: 0.8012 - val_accuracy: 0.7287\n",
      "Epoch 27/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8230 - accuracy: 0.7341 - val_loss: 0.8311 - val_accuracy: 0.7159\n",
      "Epoch 28/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7534 - accuracy: 0.7614 - val_loss: 0.8246 - val_accuracy: 0.7122\n",
      "Epoch 29/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7735 - accuracy: 0.7517 - val_loss: 0.8104 - val_accuracy: 0.7297\n",
      "Epoch 30/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7583 - accuracy: 0.7591 - val_loss: 0.7978 - val_accuracy: 0.7278\n",
      "Epoch 31/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7771 - accuracy: 0.7551 - val_loss: 0.8197 - val_accuracy: 0.7147\n",
      "Epoch 32/600\n",
      "110/110 [==============================] - 55s 504ms/step - loss: 0.7683 - accuracy: 0.7472 - val_loss: 0.7847 - val_accuracy: 0.7306\n",
      "Epoch 33/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7671 - accuracy: 0.7534 - val_loss: 0.7959 - val_accuracy: 0.7269\n",
      "Epoch 34/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7699 - accuracy: 0.7420 - val_loss: 0.7978 - val_accuracy: 0.7222\n",
      "Epoch 35/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7782 - accuracy: 0.7523 - val_loss: 0.8072 - val_accuracy: 0.7241\n",
      "Epoch 36/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7493 - accuracy: 0.7619 - val_loss: 0.8095 - val_accuracy: 0.7250\n",
      "Epoch 37/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7416 - accuracy: 0.7716 - val_loss: 0.8140 - val_accuracy: 0.7222\n",
      "Epoch 38/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8107 - accuracy: 0.7358 - val_loss: 0.8104 - val_accuracy: 0.7197\n",
      "Epoch 39/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7799 - accuracy: 0.7551 - val_loss: 0.8227 - val_accuracy: 0.7122\n",
      "Epoch 40/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7430 - accuracy: 0.7665 - val_loss: 0.8084 - val_accuracy: 0.7303\n",
      "Epoch 41/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7403 - accuracy: 0.7545 - val_loss: 0.8246 - val_accuracy: 0.7237\n",
      "Epoch 42/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7915 - accuracy: 0.7500 - val_loss: 0.8182 - val_accuracy: 0.7200\n",
      "Epoch 43/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.8005 - accuracy: 0.7403 - val_loss: 0.8197 - val_accuracy: 0.7231\n",
      "Epoch 44/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7923 - accuracy: 0.7477 - val_loss: 0.7881 - val_accuracy: 0.7328\n",
      "Epoch 45/600\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.7697 - accuracy: 0.7568 - val_loss: 0.8289 - val_accuracy: 0.7150\n",
      "Epoch 46/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7518 - accuracy: 0.7619 - val_loss: 0.8140 - val_accuracy: 0.7209\n",
      "Epoch 47/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7403 - accuracy: 0.7534 - val_loss: 0.8382 - val_accuracy: 0.7063\n",
      "Epoch 48/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7683 - accuracy: 0.7551 - val_loss: 0.8262 - val_accuracy: 0.7178\n",
      "Epoch 49/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7983 - accuracy: 0.7523 - val_loss: 0.7904 - val_accuracy: 0.7303\n",
      "Epoch 50/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.7392 - accuracy: 0.7591 - val_loss: 0.8188 - val_accuracy: 0.7203\n",
      "Epoch 51/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7694 - accuracy: 0.7523 - val_loss: 0.8368 - val_accuracy: 0.7094\n",
      "Epoch 52/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7696 - accuracy: 0.7642 - val_loss: 0.8112 - val_accuracy: 0.7250\n",
      "Epoch 53/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7638 - accuracy: 0.7557 - val_loss: 0.8214 - val_accuracy: 0.7209\n",
      "Epoch 54/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7411 - accuracy: 0.7631 - val_loss: 0.8357 - val_accuracy: 0.7144\n",
      "Epoch 55/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7314 - accuracy: 0.7648 - val_loss: 0.8322 - val_accuracy: 0.7194\n",
      "Epoch 56/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7392 - accuracy: 0.7642 - val_loss: 0.8515 - val_accuracy: 0.7178\n",
      "Epoch 57/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7825 - accuracy: 0.7574 - val_loss: 0.8443 - val_accuracy: 0.7097\n",
      "Epoch 58/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7462 - accuracy: 0.7648 - val_loss: 0.8481 - val_accuracy: 0.7125\n",
      "Epoch 59/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7500 - accuracy: 0.7602 - val_loss: 0.8076 - val_accuracy: 0.7262\n",
      "Epoch 60/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7810 - accuracy: 0.7568 - val_loss: 0.8088 - val_accuracy: 0.7241\n",
      "Epoch 61/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7642 - accuracy: 0.7625 - val_loss: 0.7984 - val_accuracy: 0.7322\n",
      "Epoch 62/600\n",
      "110/110 [==============================] - 55s 502ms/step - loss: 0.7240 - accuracy: 0.7563 - val_loss: 0.7805 - val_accuracy: 0.7356\n",
      "Epoch 63/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7323 - accuracy: 0.7528 - val_loss: 0.8228 - val_accuracy: 0.7144\n",
      "Epoch 64/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.7382 - accuracy: 0.7739 - val_loss: 0.8011 - val_accuracy: 0.7259\n",
      "Epoch 65/600\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 0.7279 - accuracy: 0.7710 - val_loss: 0.8161 - val_accuracy: 0.7166\n",
      "Epoch 66/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7570 - accuracy: 0.7551 - val_loss: 0.8138 - val_accuracy: 0.7156\n",
      "Epoch 67/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7053 - accuracy: 0.7778 - val_loss: 0.7999 - val_accuracy: 0.7294\n",
      "Epoch 68/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7605 - accuracy: 0.7597 - val_loss: 0.8150 - val_accuracy: 0.7241\n",
      "Epoch 69/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7396 - accuracy: 0.7597 - val_loss: 0.8284 - val_accuracy: 0.7203\n",
      "Epoch 70/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.7366 - accuracy: 0.7614 - val_loss: 0.8280 - val_accuracy: 0.7212\n",
      "Epoch 71/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7913 - accuracy: 0.7574 - val_loss: 0.8008 - val_accuracy: 0.7259\n",
      "Epoch 72/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7536 - accuracy: 0.7602 - val_loss: 0.8112 - val_accuracy: 0.7175\n",
      "Epoch 73/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7327 - accuracy: 0.7716 - val_loss: 0.8091 - val_accuracy: 0.7259\n",
      "Epoch 74/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6695 - accuracy: 0.7881 - val_loss: 0.8596 - val_accuracy: 0.7038\n",
      "Epoch 75/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7401 - accuracy: 0.7699 - val_loss: 0.8180 - val_accuracy: 0.7259\n",
      "Epoch 76/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6730 - accuracy: 0.7892 - val_loss: 0.8014 - val_accuracy: 0.7219\n",
      "Epoch 77/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7156 - accuracy: 0.7750 - val_loss: 0.8512 - val_accuracy: 0.7041\n",
      "Epoch 78/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7308 - accuracy: 0.7642 - val_loss: 0.8268 - val_accuracy: 0.7169\n",
      "Epoch 79/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7572 - accuracy: 0.7631 - val_loss: 0.7902 - val_accuracy: 0.7287\n",
      "Epoch 80/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7234 - accuracy: 0.7801 - val_loss: 0.8089 - val_accuracy: 0.7206\n",
      "Epoch 81/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7256 - accuracy: 0.7699 - val_loss: 0.8151 - val_accuracy: 0.7203\n",
      "Epoch 82/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7455 - accuracy: 0.7619 - val_loss: 0.8173 - val_accuracy: 0.7297\n",
      "Epoch 83/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7188 - accuracy: 0.7642 - val_loss: 0.8068 - val_accuracy: 0.7241\n",
      "Epoch 84/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.7444 - accuracy: 0.7591 - val_loss: 0.8126 - val_accuracy: 0.7247\n",
      "Epoch 85/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7337 - accuracy: 0.7670 - val_loss: 0.8033 - val_accuracy: 0.7266\n",
      "Epoch 86/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7101 - accuracy: 0.7648 - val_loss: 0.8140 - val_accuracy: 0.7259\n",
      "Epoch 87/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7089 - accuracy: 0.7693 - val_loss: 0.8061 - val_accuracy: 0.7163\n",
      "Epoch 88/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7495 - accuracy: 0.7585 - val_loss: 0.7913 - val_accuracy: 0.7356\n",
      "Epoch 89/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7228 - accuracy: 0.7659 - val_loss: 0.8044 - val_accuracy: 0.7306\n",
      "Epoch 90/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7107 - accuracy: 0.7716 - val_loss: 0.7870 - val_accuracy: 0.7344\n",
      "Epoch 91/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7083 - accuracy: 0.7739 - val_loss: 0.8146 - val_accuracy: 0.7153\n",
      "Epoch 92/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7224 - accuracy: 0.7682 - val_loss: 0.8209 - val_accuracy: 0.7178\n",
      "Epoch 93/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7272 - accuracy: 0.7574 - val_loss: 0.8095 - val_accuracy: 0.7219\n",
      "Epoch 94/600\n",
      "110/110 [==============================] - 55s 500ms/step - loss: 0.7095 - accuracy: 0.7812 - val_loss: 0.8062 - val_accuracy: 0.7225\n",
      "Epoch 95/600\n",
      "110/110 [==============================] - 55s 503ms/step - loss: 0.7542 - accuracy: 0.7545 - val_loss: 0.7911 - val_accuracy: 0.7269\n",
      "Epoch 96/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7089 - accuracy: 0.7608 - val_loss: 0.8027 - val_accuracy: 0.7266\n",
      "Epoch 97/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7239 - accuracy: 0.7818 - val_loss: 0.7901 - val_accuracy: 0.7316\n",
      "Epoch 98/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7279 - accuracy: 0.7631 - val_loss: 0.7814 - val_accuracy: 0.7322\n",
      "Epoch 99/600\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 0.7408 - accuracy: 0.7665 - val_loss: 0.7643 - val_accuracy: 0.7450\n",
      "Epoch 100/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.7217 - accuracy: 0.7670 - val_loss: 0.8057 - val_accuracy: 0.7272\n",
      "Epoch 101/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7347 - accuracy: 0.7614 - val_loss: 0.8067 - val_accuracy: 0.7191\n",
      "Epoch 102/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7163 - accuracy: 0.7670 - val_loss: 0.7920 - val_accuracy: 0.7366\n",
      "Epoch 103/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7417 - accuracy: 0.7682 - val_loss: 0.7995 - val_accuracy: 0.7303\n",
      "Epoch 104/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6957 - accuracy: 0.7960 - val_loss: 0.7919 - val_accuracy: 0.7287\n",
      "Epoch 105/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7346 - accuracy: 0.7676 - val_loss: 0.8414 - val_accuracy: 0.7159\n",
      "Epoch 106/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7167 - accuracy: 0.7733 - val_loss: 0.8031 - val_accuracy: 0.7294\n",
      "Epoch 107/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6941 - accuracy: 0.7727 - val_loss: 0.7920 - val_accuracy: 0.7422\n",
      "Epoch 108/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7139 - accuracy: 0.7756 - val_loss: 0.8264 - val_accuracy: 0.7147\n",
      "Epoch 109/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7222 - accuracy: 0.7739 - val_loss: 0.7920 - val_accuracy: 0.7262\n",
      "Epoch 110/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6901 - accuracy: 0.7767 - val_loss: 0.8022 - val_accuracy: 0.7278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7095 - accuracy: 0.7807 - val_loss: 0.8174 - val_accuracy: 0.7206\n",
      "Epoch 112/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7250 - accuracy: 0.7756 - val_loss: 0.7958 - val_accuracy: 0.7222\n",
      "Epoch 113/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7079 - accuracy: 0.7744 - val_loss: 0.8190 - val_accuracy: 0.7191\n",
      "Epoch 114/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6723 - accuracy: 0.7841 - val_loss: 0.7886 - val_accuracy: 0.7275\n",
      "Epoch 115/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6801 - accuracy: 0.7886 - val_loss: 0.8203 - val_accuracy: 0.7184\n",
      "Epoch 116/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7666 - accuracy: 0.7642 - val_loss: 0.8088 - val_accuracy: 0.7209\n",
      "Epoch 117/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6867 - accuracy: 0.7858 - val_loss: 0.8033 - val_accuracy: 0.7291\n",
      "Epoch 118/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.7279 - accuracy: 0.7591 - val_loss: 0.8159 - val_accuracy: 0.7266\n",
      "Epoch 119/600\n",
      "110/110 [==============================] - 56s 510ms/step - loss: 0.6961 - accuracy: 0.7710 - val_loss: 0.8412 - val_accuracy: 0.7134\n",
      "Epoch 120/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6864 - accuracy: 0.7875 - val_loss: 0.8013 - val_accuracy: 0.7344\n",
      "Epoch 121/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6943 - accuracy: 0.7773 - val_loss: 0.7874 - val_accuracy: 0.7334\n",
      "Epoch 122/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6989 - accuracy: 0.7778 - val_loss: 0.7774 - val_accuracy: 0.7344\n",
      "Epoch 123/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7256 - accuracy: 0.7733 - val_loss: 0.8048 - val_accuracy: 0.7287\n",
      "Epoch 124/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7004 - accuracy: 0.7773 - val_loss: 0.8051 - val_accuracy: 0.7287\n",
      "Epoch 125/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.6641 - accuracy: 0.7983 - val_loss: 0.7937 - val_accuracy: 0.7297\n",
      "Epoch 126/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6760 - accuracy: 0.7937 - val_loss: 0.8462 - val_accuracy: 0.7122\n",
      "Epoch 127/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7098 - accuracy: 0.7744 - val_loss: 0.7950 - val_accuracy: 0.7269\n",
      "Epoch 128/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6672 - accuracy: 0.7915 - val_loss: 0.7697 - val_accuracy: 0.7434\n",
      "Epoch 129/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7446 - accuracy: 0.7636 - val_loss: 0.8022 - val_accuracy: 0.7241\n",
      "Epoch 130/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6677 - accuracy: 0.7881 - val_loss: 0.7957 - val_accuracy: 0.7309\n",
      "Epoch 131/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6746 - accuracy: 0.7784 - val_loss: 0.8030 - val_accuracy: 0.7244\n",
      "Epoch 132/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7331 - accuracy: 0.7659 - val_loss: 0.7937 - val_accuracy: 0.7262\n",
      "Epoch 133/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6965 - accuracy: 0.7744 - val_loss: 0.7813 - val_accuracy: 0.7316\n",
      "Epoch 134/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7112 - accuracy: 0.7727 - val_loss: 0.7759 - val_accuracy: 0.7391\n",
      "Epoch 135/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6577 - accuracy: 0.8017 - val_loss: 0.7651 - val_accuracy: 0.7462\n",
      "Epoch 136/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6810 - accuracy: 0.7847 - val_loss: 0.7785 - val_accuracy: 0.7347\n",
      "Epoch 137/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7020 - accuracy: 0.7653 - val_loss: 0.7871 - val_accuracy: 0.7334\n",
      "Epoch 138/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7027 - accuracy: 0.7790 - val_loss: 0.7901 - val_accuracy: 0.7237\n",
      "Epoch 139/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.7344 - accuracy: 0.7619 - val_loss: 0.8146 - val_accuracy: 0.7194\n",
      "Epoch 140/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7089 - accuracy: 0.7750 - val_loss: 0.7963 - val_accuracy: 0.7328\n",
      "Epoch 141/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6745 - accuracy: 0.7841 - val_loss: 0.7722 - val_accuracy: 0.7459\n",
      "Epoch 142/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6639 - accuracy: 0.7920 - val_loss: 0.7878 - val_accuracy: 0.7341\n",
      "Epoch 143/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7258 - accuracy: 0.7665 - val_loss: 0.8104 - val_accuracy: 0.7297\n",
      "Epoch 144/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6785 - accuracy: 0.7875 - val_loss: 0.7996 - val_accuracy: 0.7403\n",
      "Epoch 145/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6774 - accuracy: 0.7841 - val_loss: 0.8081 - val_accuracy: 0.7234\n",
      "Epoch 146/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.7427 - accuracy: 0.7665 - val_loss: 0.8221 - val_accuracy: 0.7119\n",
      "Epoch 147/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6965 - accuracy: 0.7756 - val_loss: 0.7891 - val_accuracy: 0.7344\n",
      "Epoch 148/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6443 - accuracy: 0.7909 - val_loss: 0.8002 - val_accuracy: 0.7253\n",
      "Epoch 149/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6820 - accuracy: 0.7784 - val_loss: 0.7990 - val_accuracy: 0.7312\n",
      "Epoch 150/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6301 - accuracy: 0.8034 - val_loss: 0.7873 - val_accuracy: 0.7375\n",
      "Epoch 151/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.6619 - accuracy: 0.7852 - val_loss: 0.8042 - val_accuracy: 0.7275\n",
      "Epoch 152/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.6602 - accuracy: 0.7892 - val_loss: 0.7811 - val_accuracy: 0.7400\n",
      "Epoch 153/600\n",
      "110/110 [==============================] - 55s 503ms/step - loss: 0.6078 - accuracy: 0.8045 - val_loss: 0.7582 - val_accuracy: 0.7450\n",
      "Epoch 154/600\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.6955 - accuracy: 0.7784 - val_loss: 0.8067 - val_accuracy: 0.7303\n",
      "Epoch 155/600\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.6625 - accuracy: 0.8017 - val_loss: 0.7950 - val_accuracy: 0.7300\n",
      "Epoch 156/600\n",
      "110/110 [==============================] - 58s 532ms/step - loss: 0.6644 - accuracy: 0.7977 - val_loss: 0.7825 - val_accuracy: 0.7322\n",
      "Epoch 157/600\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.6945 - accuracy: 0.7795 - val_loss: 0.8065 - val_accuracy: 0.7291\n",
      "Epoch 158/600\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.6937 - accuracy: 0.7818 - val_loss: 0.7920 - val_accuracy: 0.7353\n",
      "Epoch 159/600\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.6595 - accuracy: 0.7886 - val_loss: 0.7950 - val_accuracy: 0.7378\n",
      "Epoch 160/600\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.6771 - accuracy: 0.7852 - val_loss: 0.8098 - val_accuracy: 0.7266\n",
      "Epoch 161/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6922 - accuracy: 0.7864 - val_loss: 0.7956 - val_accuracy: 0.7266\n",
      "Epoch 162/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.6356 - accuracy: 0.8080 - val_loss: 0.7880 - val_accuracy: 0.7291\n",
      "Epoch 163/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.6540 - accuracy: 0.7835 - val_loss: 0.8111 - val_accuracy: 0.7334\n",
      "Epoch 164/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6773 - accuracy: 0.7909 - val_loss: 0.8002 - val_accuracy: 0.7291\n",
      "Epoch 165/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6957 - accuracy: 0.7841 - val_loss: 0.8137 - val_accuracy: 0.7153\n",
      "Epoch 166/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6853 - accuracy: 0.7937 - val_loss: 0.7840 - val_accuracy: 0.7409\n",
      "Epoch 167/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6658 - accuracy: 0.7932 - val_loss: 0.7805 - val_accuracy: 0.7378\n",
      "Epoch 168/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7131 - accuracy: 0.7784 - val_loss: 0.8156 - val_accuracy: 0.7244\n",
      "Epoch 169/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6795 - accuracy: 0.7898 - val_loss: 0.7900 - val_accuracy: 0.7325\n",
      "Epoch 170/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.7066 - accuracy: 0.7710 - val_loss: 0.7786 - val_accuracy: 0.7303\n",
      "Epoch 171/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6709 - accuracy: 0.7920 - val_loss: 0.7920 - val_accuracy: 0.7291\n",
      "Epoch 172/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6770 - accuracy: 0.7835 - val_loss: 0.7872 - val_accuracy: 0.7425\n",
      "Epoch 173/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6936 - accuracy: 0.7812 - val_loss: 0.7831 - val_accuracy: 0.7406\n",
      "Epoch 174/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6801 - accuracy: 0.7790 - val_loss: 0.8072 - val_accuracy: 0.7341\n",
      "Epoch 175/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6689 - accuracy: 0.7989 - val_loss: 0.7988 - val_accuracy: 0.7341\n",
      "Epoch 176/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6808 - accuracy: 0.7847 - val_loss: 0.8007 - val_accuracy: 0.7331\n",
      "Epoch 177/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6800 - accuracy: 0.7767 - val_loss: 0.7977 - val_accuracy: 0.7375\n",
      "Epoch 178/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6317 - accuracy: 0.8034 - val_loss: 0.8261 - val_accuracy: 0.7237\n",
      "Epoch 179/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6822 - accuracy: 0.7733 - val_loss: 0.8156 - val_accuracy: 0.7375\n",
      "Epoch 180/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6486 - accuracy: 0.8023 - val_loss: 0.8205 - val_accuracy: 0.7278\n",
      "Epoch 181/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6402 - accuracy: 0.7966 - val_loss: 0.8046 - val_accuracy: 0.7334\n",
      "Epoch 182/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6651 - accuracy: 0.7949 - val_loss: 0.8027 - val_accuracy: 0.7409\n",
      "Epoch 183/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6844 - accuracy: 0.7926 - val_loss: 0.8239 - val_accuracy: 0.7359\n",
      "Epoch 184/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6453 - accuracy: 0.7932 - val_loss: 0.8367 - val_accuracy: 0.7244\n",
      "Epoch 185/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6705 - accuracy: 0.7767 - val_loss: 0.8076 - val_accuracy: 0.7219\n",
      "Epoch 186/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6308 - accuracy: 0.8074 - val_loss: 0.8208 - val_accuracy: 0.7241\n",
      "Epoch 187/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6333 - accuracy: 0.7898 - val_loss: 0.8150 - val_accuracy: 0.7228\n",
      "Epoch 188/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6365 - accuracy: 0.7909 - val_loss: 0.8471 - val_accuracy: 0.7200\n",
      "Epoch 189/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6634 - accuracy: 0.7869 - val_loss: 0.8291 - val_accuracy: 0.7281\n",
      "Epoch 190/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6754 - accuracy: 0.7926 - val_loss: 0.8248 - val_accuracy: 0.7197\n",
      "Epoch 191/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6373 - accuracy: 0.7852 - val_loss: 0.8033 - val_accuracy: 0.7287\n",
      "Epoch 192/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6719 - accuracy: 0.7881 - val_loss: 0.8002 - val_accuracy: 0.7287\n",
      "Epoch 193/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6610 - accuracy: 0.8017 - val_loss: 0.7889 - val_accuracy: 0.7331\n",
      "Epoch 194/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6178 - accuracy: 0.8108 - val_loss: 0.8612 - val_accuracy: 0.7125\n",
      "Epoch 195/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6894 - accuracy: 0.7761 - val_loss: 0.8003 - val_accuracy: 0.7306\n",
      "Epoch 196/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6478 - accuracy: 0.8000 - val_loss: 0.7814 - val_accuracy: 0.7409\n",
      "Epoch 197/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6550 - accuracy: 0.7875 - val_loss: 0.8182 - val_accuracy: 0.7228\n",
      "Epoch 198/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6566 - accuracy: 0.8057 - val_loss: 0.8046 - val_accuracy: 0.7362\n",
      "Epoch 199/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6373 - accuracy: 0.7989 - val_loss: 0.8337 - val_accuracy: 0.7191\n",
      "Epoch 200/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6556 - accuracy: 0.7966 - val_loss: 0.7812 - val_accuracy: 0.7400\n",
      "Epoch 201/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5956 - accuracy: 0.8131 - val_loss: 0.7939 - val_accuracy: 0.7322\n",
      "Epoch 202/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6416 - accuracy: 0.8074 - val_loss: 0.7983 - val_accuracy: 0.7369\n",
      "Epoch 203/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6571 - accuracy: 0.7858 - val_loss: 0.8014 - val_accuracy: 0.7294\n",
      "Epoch 204/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6496 - accuracy: 0.7983 - val_loss: 0.8045 - val_accuracy: 0.7309\n",
      "Epoch 205/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6588 - accuracy: 0.8011 - val_loss: 0.7631 - val_accuracy: 0.7491\n",
      "Epoch 206/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6518 - accuracy: 0.7920 - val_loss: 0.7897 - val_accuracy: 0.7381\n",
      "Epoch 207/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5625 - accuracy: 0.8182 - val_loss: 0.8343 - val_accuracy: 0.7163\n",
      "Epoch 208/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.6644 - accuracy: 0.7949 - val_loss: 0.8171 - val_accuracy: 0.7244\n",
      "Epoch 209/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6859 - accuracy: 0.7892 - val_loss: 0.8164 - val_accuracy: 0.7344\n",
      "Epoch 210/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6270 - accuracy: 0.8074 - val_loss: 0.8312 - val_accuracy: 0.7178\n",
      "Epoch 211/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6171 - accuracy: 0.7943 - val_loss: 0.8030 - val_accuracy: 0.7344\n",
      "Epoch 212/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6288 - accuracy: 0.8000 - val_loss: 0.8597 - val_accuracy: 0.7166\n",
      "Epoch 213/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6498 - accuracy: 0.7915 - val_loss: 0.8056 - val_accuracy: 0.7281\n",
      "Epoch 214/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6364 - accuracy: 0.8108 - val_loss: 0.8080 - val_accuracy: 0.7300\n",
      "Epoch 215/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6684 - accuracy: 0.7898 - val_loss: 0.8330 - val_accuracy: 0.7209\n",
      "Epoch 216/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6770 - accuracy: 0.7898 - val_loss: 0.7965 - val_accuracy: 0.7328\n",
      "Epoch 217/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6545 - accuracy: 0.8006 - val_loss: 0.8159 - val_accuracy: 0.7300\n",
      "Epoch 218/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6780 - accuracy: 0.7949 - val_loss: 0.8147 - val_accuracy: 0.7216\n",
      "Epoch 219/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6234 - accuracy: 0.8091 - val_loss: 0.8419 - val_accuracy: 0.7166\n",
      "Epoch 220/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6423 - accuracy: 0.8085 - val_loss: 0.8086 - val_accuracy: 0.7244\n",
      "Epoch 221/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6659 - accuracy: 0.7886 - val_loss: 0.7947 - val_accuracy: 0.7359\n",
      "Epoch 222/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6369 - accuracy: 0.8017 - val_loss: 0.8056 - val_accuracy: 0.7344\n",
      "Epoch 223/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6326 - accuracy: 0.7955 - val_loss: 0.7923 - val_accuracy: 0.7394\n",
      "Epoch 224/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6275 - accuracy: 0.8125 - val_loss: 0.8263 - val_accuracy: 0.7206\n",
      "Epoch 225/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6803 - accuracy: 0.7841 - val_loss: 0.8391 - val_accuracy: 0.7194\n",
      "Epoch 226/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6135 - accuracy: 0.8097 - val_loss: 0.8825 - val_accuracy: 0.7103\n",
      "Epoch 227/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6435 - accuracy: 0.8017 - val_loss: 0.8357 - val_accuracy: 0.7181\n",
      "Epoch 228/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6113 - accuracy: 0.8114 - val_loss: 0.8092 - val_accuracy: 0.7331\n",
      "Epoch 229/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6573 - accuracy: 0.7920 - val_loss: 0.8385 - val_accuracy: 0.7222\n",
      "Epoch 230/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6456 - accuracy: 0.7937 - val_loss: 0.7989 - val_accuracy: 0.7241\n",
      "Epoch 231/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6119 - accuracy: 0.8045 - val_loss: 0.8127 - val_accuracy: 0.7241\n",
      "Epoch 232/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6344 - accuracy: 0.7955 - val_loss: 0.8090 - val_accuracy: 0.7234\n",
      "Epoch 233/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6235 - accuracy: 0.7977 - val_loss: 0.8076 - val_accuracy: 0.7300\n",
      "Epoch 234/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6508 - accuracy: 0.8017 - val_loss: 0.8139 - val_accuracy: 0.7253\n",
      "Epoch 235/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6359 - accuracy: 0.7960 - val_loss: 0.8287 - val_accuracy: 0.7219\n",
      "Epoch 236/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6337 - accuracy: 0.8000 - val_loss: 0.8007 - val_accuracy: 0.7387\n",
      "Epoch 237/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6382 - accuracy: 0.8011 - val_loss: 0.7758 - val_accuracy: 0.7397\n",
      "Epoch 238/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5889 - accuracy: 0.8091 - val_loss: 0.8331 - val_accuracy: 0.7316\n",
      "Epoch 239/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6542 - accuracy: 0.7864 - val_loss: 0.8036 - val_accuracy: 0.7272\n",
      "Epoch 240/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6071 - accuracy: 0.8125 - val_loss: 0.8034 - val_accuracy: 0.7234\n",
      "Epoch 241/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.6657 - accuracy: 0.7909 - val_loss: 0.8072 - val_accuracy: 0.7259\n",
      "Epoch 242/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6414 - accuracy: 0.7926 - val_loss: 0.7905 - val_accuracy: 0.7362\n",
      "Epoch 243/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6354 - accuracy: 0.8023 - val_loss: 0.8015 - val_accuracy: 0.7291\n",
      "Epoch 244/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6374 - accuracy: 0.8068 - val_loss: 0.8166 - val_accuracy: 0.7237\n",
      "Epoch 245/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6168 - accuracy: 0.7977 - val_loss: 0.8155 - val_accuracy: 0.7216\n",
      "Epoch 246/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5897 - accuracy: 0.8222 - val_loss: 0.7939 - val_accuracy: 0.7394\n",
      "Epoch 247/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6239 - accuracy: 0.8114 - val_loss: 0.7940 - val_accuracy: 0.7353\n",
      "Epoch 248/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6356 - accuracy: 0.8040 - val_loss: 0.7982 - val_accuracy: 0.7284\n",
      "Epoch 249/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6345 - accuracy: 0.8006 - val_loss: 0.8449 - val_accuracy: 0.7188\n",
      "Epoch 250/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6333 - accuracy: 0.7909 - val_loss: 0.8559 - val_accuracy: 0.7134\n",
      "Epoch 251/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5978 - accuracy: 0.8250 - val_loss: 0.7969 - val_accuracy: 0.7381\n",
      "Epoch 252/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6102 - accuracy: 0.8057 - val_loss: 0.8263 - val_accuracy: 0.7269\n",
      "Epoch 253/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6378 - accuracy: 0.8040 - val_loss: 0.8038 - val_accuracy: 0.7341\n",
      "Epoch 254/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6214 - accuracy: 0.8023 - val_loss: 0.8167 - val_accuracy: 0.7300\n",
      "Epoch 255/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6048 - accuracy: 0.8057 - val_loss: 0.8290 - val_accuracy: 0.7278\n",
      "Epoch 256/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6202 - accuracy: 0.7909 - val_loss: 0.7992 - val_accuracy: 0.7391\n",
      "Epoch 257/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5784 - accuracy: 0.8108 - val_loss: 0.8485 - val_accuracy: 0.7225\n",
      "Epoch 258/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6420 - accuracy: 0.8011 - val_loss: 0.8085 - val_accuracy: 0.7253\n",
      "Epoch 259/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5774 - accuracy: 0.8227 - val_loss: 0.8073 - val_accuracy: 0.7291\n",
      "Epoch 260/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6374 - accuracy: 0.7943 - val_loss: 0.7993 - val_accuracy: 0.7303\n",
      "Epoch 261/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.5973 - accuracy: 0.8091 - val_loss: 0.7972 - val_accuracy: 0.7412\n",
      "Epoch 262/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6524 - accuracy: 0.7886 - val_loss: 0.7928 - val_accuracy: 0.7419\n",
      "Epoch 263/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6516 - accuracy: 0.7994 - val_loss: 0.7905 - val_accuracy: 0.7322\n",
      "Epoch 264/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6554 - accuracy: 0.7972 - val_loss: 0.8058 - val_accuracy: 0.7303\n",
      "Epoch 265/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6011 - accuracy: 0.8119 - val_loss: 0.7969 - val_accuracy: 0.7366\n",
      "Epoch 266/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6153 - accuracy: 0.8080 - val_loss: 0.7824 - val_accuracy: 0.7422\n",
      "Epoch 267/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6064 - accuracy: 0.8080 - val_loss: 0.7971 - val_accuracy: 0.7419\n",
      "Epoch 268/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6188 - accuracy: 0.8006 - val_loss: 0.7877 - val_accuracy: 0.7437\n",
      "Epoch 269/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6424 - accuracy: 0.8034 - val_loss: 0.8077 - val_accuracy: 0.7297\n",
      "Epoch 270/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6007 - accuracy: 0.8153 - val_loss: 0.8101 - val_accuracy: 0.7387\n",
      "Epoch 271/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6145 - accuracy: 0.8068 - val_loss: 0.7952 - val_accuracy: 0.7391\n",
      "Epoch 272/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6107 - accuracy: 0.8108 - val_loss: 0.8039 - val_accuracy: 0.7425\n",
      "Epoch 273/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5671 - accuracy: 0.8313 - val_loss: 0.8235 - val_accuracy: 0.7356\n",
      "Epoch 274/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6015 - accuracy: 0.8062 - val_loss: 0.8043 - val_accuracy: 0.7400\n",
      "Epoch 275/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5742 - accuracy: 0.8159 - val_loss: 0.8453 - val_accuracy: 0.7191\n",
      "Epoch 276/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6534 - accuracy: 0.8000 - val_loss: 0.8222 - val_accuracy: 0.7266\n",
      "Epoch 277/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6148 - accuracy: 0.8074 - val_loss: 0.8282 - val_accuracy: 0.7294\n",
      "Epoch 278/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5802 - accuracy: 0.8182 - val_loss: 0.8104 - val_accuracy: 0.7437\n",
      "Epoch 279/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6586 - accuracy: 0.7852 - val_loss: 0.7987 - val_accuracy: 0.7431\n",
      "Epoch 280/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5941 - accuracy: 0.8222 - val_loss: 0.8046 - val_accuracy: 0.7356\n",
      "Epoch 281/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5842 - accuracy: 0.8119 - val_loss: 0.8128 - val_accuracy: 0.7334\n",
      "Epoch 282/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6281 - accuracy: 0.8097 - val_loss: 0.8052 - val_accuracy: 0.7341\n",
      "Epoch 283/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6013 - accuracy: 0.8159 - val_loss: 0.7836 - val_accuracy: 0.7462\n",
      "Epoch 284/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6195 - accuracy: 0.8051 - val_loss: 0.8031 - val_accuracy: 0.7372\n",
      "Epoch 285/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6217 - accuracy: 0.8057 - val_loss: 0.8191 - val_accuracy: 0.7312\n",
      "Epoch 286/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6087 - accuracy: 0.8142 - val_loss: 0.8025 - val_accuracy: 0.7353\n",
      "Epoch 287/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.6257 - accuracy: 0.8023 - val_loss: 0.8406 - val_accuracy: 0.7241\n",
      "Epoch 288/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6270 - accuracy: 0.8057 - val_loss: 0.8047 - val_accuracy: 0.7369\n",
      "Epoch 289/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.6537 - accuracy: 0.7949 - val_loss: 0.8665 - val_accuracy: 0.7147\n",
      "Epoch 290/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5905 - accuracy: 0.8199 - val_loss: 0.7958 - val_accuracy: 0.7394\n",
      "Epoch 291/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5994 - accuracy: 0.8034 - val_loss: 0.8195 - val_accuracy: 0.7322\n",
      "Epoch 292/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6351 - accuracy: 0.7960 - val_loss: 0.8389 - val_accuracy: 0.7225\n",
      "Epoch 293/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6449 - accuracy: 0.8040 - val_loss: 0.8186 - val_accuracy: 0.7287\n",
      "Epoch 294/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5832 - accuracy: 0.8176 - val_loss: 0.8263 - val_accuracy: 0.7312\n",
      "Epoch 295/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5914 - accuracy: 0.8148 - val_loss: 0.8337 - val_accuracy: 0.7272\n",
      "Epoch 296/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6368 - accuracy: 0.7852 - val_loss: 0.8162 - val_accuracy: 0.7253\n",
      "Epoch 297/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6121 - accuracy: 0.8074 - val_loss: 0.7891 - val_accuracy: 0.7409\n",
      "Epoch 298/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6057 - accuracy: 0.8097 - val_loss: 0.7935 - val_accuracy: 0.7353\n",
      "Epoch 299/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6286 - accuracy: 0.8028 - val_loss: 0.7896 - val_accuracy: 0.7419\n",
      "Epoch 300/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5897 - accuracy: 0.8153 - val_loss: 0.7877 - val_accuracy: 0.7434\n",
      "Epoch 301/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6363 - accuracy: 0.8074 - val_loss: 0.8021 - val_accuracy: 0.7359\n",
      "Epoch 302/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5971 - accuracy: 0.8131 - val_loss: 0.8108 - val_accuracy: 0.7316\n",
      "Epoch 303/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6334 - accuracy: 0.8097 - val_loss: 0.7809 - val_accuracy: 0.7450\n",
      "Epoch 304/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5882 - accuracy: 0.8142 - val_loss: 0.7721 - val_accuracy: 0.7500\n",
      "Epoch 305/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5881 - accuracy: 0.8210 - val_loss: 0.7969 - val_accuracy: 0.7334\n",
      "Epoch 306/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5708 - accuracy: 0.8193 - val_loss: 0.7941 - val_accuracy: 0.7369\n",
      "Epoch 307/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5870 - accuracy: 0.8222 - val_loss: 0.7680 - val_accuracy: 0.7481\n",
      "Epoch 308/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6234 - accuracy: 0.7955 - val_loss: 0.8185 - val_accuracy: 0.7306\n",
      "Epoch 309/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5988 - accuracy: 0.8256 - val_loss: 0.8130 - val_accuracy: 0.7237\n",
      "Epoch 310/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6233 - accuracy: 0.8125 - val_loss: 0.8138 - val_accuracy: 0.7291\n",
      "Epoch 311/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6153 - accuracy: 0.8136 - val_loss: 0.8161 - val_accuracy: 0.7356\n",
      "Epoch 312/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6062 - accuracy: 0.8159 - val_loss: 0.8413 - val_accuracy: 0.7231\n",
      "Epoch 313/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6252 - accuracy: 0.8023 - val_loss: 0.8306 - val_accuracy: 0.7378\n",
      "Epoch 314/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6123 - accuracy: 0.8176 - val_loss: 0.8157 - val_accuracy: 0.7381\n",
      "Epoch 315/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6034 - accuracy: 0.8159 - val_loss: 0.8024 - val_accuracy: 0.7412\n",
      "Epoch 316/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6024 - accuracy: 0.8131 - val_loss: 0.8031 - val_accuracy: 0.7350\n",
      "Epoch 317/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6007 - accuracy: 0.8193 - val_loss: 0.8143 - val_accuracy: 0.7312\n",
      "Epoch 318/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5904 - accuracy: 0.8176 - val_loss: 0.8395 - val_accuracy: 0.7228\n",
      "Epoch 319/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6113 - accuracy: 0.8091 - val_loss: 0.8064 - val_accuracy: 0.7331\n",
      "Epoch 320/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5798 - accuracy: 0.8210 - val_loss: 0.8035 - val_accuracy: 0.7303\n",
      "Epoch 321/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5849 - accuracy: 0.8136 - val_loss: 0.8320 - val_accuracy: 0.7337\n",
      "Epoch 322/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5787 - accuracy: 0.8227 - val_loss: 0.8362 - val_accuracy: 0.7272\n",
      "Epoch 323/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5846 - accuracy: 0.8205 - val_loss: 0.8041 - val_accuracy: 0.7381\n",
      "Epoch 324/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5883 - accuracy: 0.8199 - val_loss: 0.8011 - val_accuracy: 0.7441\n",
      "Epoch 325/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.6207 - accuracy: 0.7983 - val_loss: 0.8273 - val_accuracy: 0.7284\n",
      "Epoch 326/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5862 - accuracy: 0.8199 - val_loss: 0.8153 - val_accuracy: 0.7400\n",
      "Epoch 327/600\n",
      "110/110 [==============================] - 55s 498ms/step - loss: 0.6202 - accuracy: 0.8068 - val_loss: 0.8051 - val_accuracy: 0.7381\n",
      "Epoch 328/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.5781 - accuracy: 0.8205 - val_loss: 0.8040 - val_accuracy: 0.7400\n",
      "Epoch 329/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5768 - accuracy: 0.8148 - val_loss: 0.7900 - val_accuracy: 0.7472\n",
      "Epoch 330/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5987 - accuracy: 0.8131 - val_loss: 0.8315 - val_accuracy: 0.7291\n",
      "Epoch 331/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5663 - accuracy: 0.8267 - val_loss: 0.8338 - val_accuracy: 0.7250\n",
      "Epoch 332/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6036 - accuracy: 0.8131 - val_loss: 0.8276 - val_accuracy: 0.7253\n",
      "Epoch 333/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5717 - accuracy: 0.8142 - val_loss: 0.7969 - val_accuracy: 0.7456\n",
      "Epoch 334/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5724 - accuracy: 0.8210 - val_loss: 0.7992 - val_accuracy: 0.7462\n",
      "Epoch 335/600\n",
      "110/110 [==============================] - 54s 489ms/step - loss: 0.5668 - accuracy: 0.8165 - val_loss: 0.8128 - val_accuracy: 0.7412\n",
      "Epoch 336/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5790 - accuracy: 0.8313 - val_loss: 0.8038 - val_accuracy: 0.7409\n",
      "Epoch 337/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5897 - accuracy: 0.8199 - val_loss: 0.8541 - val_accuracy: 0.7269\n",
      "Epoch 338/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5754 - accuracy: 0.8148 - val_loss: 0.8368 - val_accuracy: 0.7322\n",
      "Epoch 339/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5757 - accuracy: 0.8142 - val_loss: 0.8668 - val_accuracy: 0.7194\n",
      "Epoch 340/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5555 - accuracy: 0.8290 - val_loss: 0.8549 - val_accuracy: 0.7278\n",
      "Epoch 341/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5239 - accuracy: 0.8415 - val_loss: 0.8391 - val_accuracy: 0.7278\n",
      "Epoch 342/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5918 - accuracy: 0.8165 - val_loss: 0.8178 - val_accuracy: 0.7337\n",
      "Epoch 343/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6331 - accuracy: 0.8148 - val_loss: 0.8672 - val_accuracy: 0.7200\n",
      "Epoch 344/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5612 - accuracy: 0.8284 - val_loss: 0.8260 - val_accuracy: 0.7319\n",
      "Epoch 345/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5687 - accuracy: 0.8176 - val_loss: 0.8578 - val_accuracy: 0.7247\n",
      "Epoch 346/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6002 - accuracy: 0.8114 - val_loss: 0.8407 - val_accuracy: 0.7294\n",
      "Epoch 347/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5919 - accuracy: 0.8222 - val_loss: 0.8655 - val_accuracy: 0.7141\n",
      "Epoch 348/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5938 - accuracy: 0.8216 - val_loss: 0.8199 - val_accuracy: 0.7359\n",
      "Epoch 349/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5837 - accuracy: 0.8159 - val_loss: 0.8314 - val_accuracy: 0.7294\n",
      "Epoch 350/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5774 - accuracy: 0.8176 - val_loss: 0.8504 - val_accuracy: 0.7278\n",
      "Epoch 351/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5656 - accuracy: 0.8347 - val_loss: 0.8246 - val_accuracy: 0.7306\n",
      "Epoch 352/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5606 - accuracy: 0.8290 - val_loss: 0.8167 - val_accuracy: 0.7387\n",
      "Epoch 353/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5865 - accuracy: 0.8148 - val_loss: 0.8404 - val_accuracy: 0.7303\n",
      "Epoch 354/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5890 - accuracy: 0.8165 - val_loss: 0.8366 - val_accuracy: 0.7253\n",
      "Epoch 355/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5794 - accuracy: 0.8176 - val_loss: 0.8158 - val_accuracy: 0.7444\n",
      "Epoch 356/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5844 - accuracy: 0.8324 - val_loss: 0.8394 - val_accuracy: 0.7347\n",
      "Epoch 357/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6019 - accuracy: 0.8114 - val_loss: 0.8488 - val_accuracy: 0.7394\n",
      "Epoch 358/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5623 - accuracy: 0.8176 - val_loss: 0.8419 - val_accuracy: 0.7362\n",
      "Epoch 359/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5958 - accuracy: 0.8205 - val_loss: 0.8716 - val_accuracy: 0.7191\n",
      "Epoch 360/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5952 - accuracy: 0.8108 - val_loss: 0.8272 - val_accuracy: 0.7325\n",
      "Epoch 361/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6078 - accuracy: 0.8045 - val_loss: 0.8343 - val_accuracy: 0.7256\n",
      "Epoch 362/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5863 - accuracy: 0.8165 - val_loss: 0.8471 - val_accuracy: 0.7287\n",
      "Epoch 363/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6136 - accuracy: 0.8188 - val_loss: 0.8156 - val_accuracy: 0.7431\n",
      "Epoch 364/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5690 - accuracy: 0.8176 - val_loss: 0.8499 - val_accuracy: 0.7262\n",
      "Epoch 365/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5748 - accuracy: 0.8148 - val_loss: 0.8469 - val_accuracy: 0.7325\n",
      "Epoch 366/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5802 - accuracy: 0.8199 - val_loss: 0.8351 - val_accuracy: 0.7400\n",
      "Epoch 367/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5521 - accuracy: 0.8318 - val_loss: 0.8406 - val_accuracy: 0.7294\n",
      "Epoch 368/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5728 - accuracy: 0.8136 - val_loss: 0.8263 - val_accuracy: 0.7359\n",
      "Epoch 369/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5741 - accuracy: 0.8273 - val_loss: 0.8500 - val_accuracy: 0.7384\n",
      "Epoch 370/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5951 - accuracy: 0.8216 - val_loss: 0.8038 - val_accuracy: 0.7406\n",
      "Epoch 371/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5880 - accuracy: 0.8199 - val_loss: 0.8147 - val_accuracy: 0.7419\n",
      "Epoch 372/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5775 - accuracy: 0.8244 - val_loss: 0.8290 - val_accuracy: 0.7403\n",
      "Epoch 373/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5510 - accuracy: 0.8261 - val_loss: 0.8031 - val_accuracy: 0.7453\n",
      "Epoch 374/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5936 - accuracy: 0.8165 - val_loss: 0.8575 - val_accuracy: 0.7328\n",
      "Epoch 375/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5642 - accuracy: 0.8222 - val_loss: 0.8248 - val_accuracy: 0.7328\n",
      "Epoch 376/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5618 - accuracy: 0.8199 - val_loss: 0.8203 - val_accuracy: 0.7372\n",
      "Epoch 377/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5612 - accuracy: 0.8205 - val_loss: 0.8466 - val_accuracy: 0.7316\n",
      "Epoch 378/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6104 - accuracy: 0.8102 - val_loss: 0.8384 - val_accuracy: 0.7347\n",
      "Epoch 379/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6431 - accuracy: 0.8131 - val_loss: 0.8169 - val_accuracy: 0.7406\n",
      "Epoch 380/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5652 - accuracy: 0.8301 - val_loss: 0.8545 - val_accuracy: 0.7225\n",
      "Epoch 381/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5580 - accuracy: 0.8358 - val_loss: 0.8679 - val_accuracy: 0.7303\n",
      "Epoch 382/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5686 - accuracy: 0.8182 - val_loss: 0.8592 - val_accuracy: 0.7212\n",
      "Epoch 383/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6067 - accuracy: 0.8153 - val_loss: 0.8725 - val_accuracy: 0.7306\n",
      "Epoch 384/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5876 - accuracy: 0.8205 - val_loss: 0.7741 - val_accuracy: 0.7484\n",
      "Epoch 385/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5634 - accuracy: 0.8182 - val_loss: 0.8208 - val_accuracy: 0.7397\n",
      "Epoch 386/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6051 - accuracy: 0.8205 - val_loss: 0.8461 - val_accuracy: 0.7306\n",
      "Epoch 387/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5990 - accuracy: 0.8068 - val_loss: 0.8188 - val_accuracy: 0.7350\n",
      "Epoch 388/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5584 - accuracy: 0.8244 - val_loss: 0.8438 - val_accuracy: 0.7316\n",
      "Epoch 389/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5705 - accuracy: 0.8170 - val_loss: 0.8310 - val_accuracy: 0.7359\n",
      "Epoch 390/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5607 - accuracy: 0.8341 - val_loss: 0.8312 - val_accuracy: 0.7312\n",
      "Epoch 391/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.5790 - accuracy: 0.8256 - val_loss: 0.8707 - val_accuracy: 0.7219\n",
      "Epoch 392/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5293 - accuracy: 0.8364 - val_loss: 0.8244 - val_accuracy: 0.7322\n",
      "Epoch 393/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5878 - accuracy: 0.8119 - val_loss: 0.8438 - val_accuracy: 0.7250\n",
      "Epoch 394/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5445 - accuracy: 0.8358 - val_loss: 0.8330 - val_accuracy: 0.7325\n",
      "Epoch 395/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5830 - accuracy: 0.8182 - val_loss: 0.8348 - val_accuracy: 0.7334\n",
      "Epoch 396/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5476 - accuracy: 0.8330 - val_loss: 0.8366 - val_accuracy: 0.7359\n",
      "Epoch 397/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.6187 - accuracy: 0.8119 - val_loss: 0.8452 - val_accuracy: 0.7403\n",
      "Epoch 398/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5410 - accuracy: 0.8324 - val_loss: 0.8927 - val_accuracy: 0.7184\n",
      "Epoch 399/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.4838 - accuracy: 0.8460 - val_loss: 0.8335 - val_accuracy: 0.7337\n",
      "Epoch 400/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5558 - accuracy: 0.8205 - val_loss: 0.8573 - val_accuracy: 0.7331\n",
      "Epoch 401/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5381 - accuracy: 0.8330 - val_loss: 0.8252 - val_accuracy: 0.7397\n",
      "Epoch 402/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5680 - accuracy: 0.8210 - val_loss: 0.8958 - val_accuracy: 0.7237\n",
      "Epoch 403/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5460 - accuracy: 0.8307 - val_loss: 0.8221 - val_accuracy: 0.7350\n",
      "Epoch 404/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5480 - accuracy: 0.8250 - val_loss: 0.8483 - val_accuracy: 0.7359\n",
      "Epoch 405/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5490 - accuracy: 0.8284 - val_loss: 0.8297 - val_accuracy: 0.7391\n",
      "Epoch 406/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5595 - accuracy: 0.8290 - val_loss: 0.8514 - val_accuracy: 0.7294\n",
      "Epoch 407/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5794 - accuracy: 0.8284 - val_loss: 0.8534 - val_accuracy: 0.7281\n",
      "Epoch 408/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5241 - accuracy: 0.8477 - val_loss: 0.9088 - val_accuracy: 0.7119\n",
      "Epoch 409/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5214 - accuracy: 0.8398 - val_loss: 0.8827 - val_accuracy: 0.7225\n",
      "Epoch 410/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5869 - accuracy: 0.8250 - val_loss: 0.8769 - val_accuracy: 0.7163\n",
      "Epoch 411/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5697 - accuracy: 0.8295 - val_loss: 0.8602 - val_accuracy: 0.7212\n",
      "Epoch 412/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5509 - accuracy: 0.8290 - val_loss: 0.8739 - val_accuracy: 0.7222\n",
      "Epoch 413/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5729 - accuracy: 0.8176 - val_loss: 0.8782 - val_accuracy: 0.7197\n",
      "Epoch 414/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5195 - accuracy: 0.8352 - val_loss: 0.8521 - val_accuracy: 0.7256\n",
      "Epoch 415/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5444 - accuracy: 0.8307 - val_loss: 0.8760 - val_accuracy: 0.7150\n",
      "Epoch 416/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5920 - accuracy: 0.8244 - val_loss: 0.8665 - val_accuracy: 0.7225\n",
      "Epoch 417/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5977 - accuracy: 0.8102 - val_loss: 0.8606 - val_accuracy: 0.7256\n",
      "Epoch 418/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5530 - accuracy: 0.8250 - val_loss: 0.8462 - val_accuracy: 0.7341\n",
      "Epoch 419/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5939 - accuracy: 0.8239 - val_loss: 0.8232 - val_accuracy: 0.7356\n",
      "Epoch 420/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5406 - accuracy: 0.8392 - val_loss: 0.8877 - val_accuracy: 0.7125\n",
      "Epoch 421/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5766 - accuracy: 0.8210 - val_loss: 0.8254 - val_accuracy: 0.7344\n",
      "Epoch 422/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5617 - accuracy: 0.8347 - val_loss: 0.8387 - val_accuracy: 0.7312\n",
      "Epoch 423/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5368 - accuracy: 0.8256 - val_loss: 0.8548 - val_accuracy: 0.7303\n",
      "Epoch 424/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5607 - accuracy: 0.8261 - val_loss: 0.8748 - val_accuracy: 0.7166\n",
      "Epoch 425/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5367 - accuracy: 0.8278 - val_loss: 0.8520 - val_accuracy: 0.7369\n",
      "Epoch 426/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5247 - accuracy: 0.8301 - val_loss: 0.8941 - val_accuracy: 0.7144\n",
      "Epoch 427/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5713 - accuracy: 0.8199 - val_loss: 0.8822 - val_accuracy: 0.7175\n",
      "Epoch 428/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5204 - accuracy: 0.8460 - val_loss: 0.8267 - val_accuracy: 0.7369\n",
      "Epoch 429/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5173 - accuracy: 0.8347 - val_loss: 0.8023 - val_accuracy: 0.7503\n",
      "Epoch 430/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5557 - accuracy: 0.8210 - val_loss: 0.8267 - val_accuracy: 0.7431\n",
      "Epoch 431/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5361 - accuracy: 0.8267 - val_loss: 0.8843 - val_accuracy: 0.7287\n",
      "Epoch 432/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5501 - accuracy: 0.8358 - val_loss: 0.8308 - val_accuracy: 0.7359\n",
      "Epoch 433/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5445 - accuracy: 0.8352 - val_loss: 0.8248 - val_accuracy: 0.7478\n",
      "Epoch 434/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5570 - accuracy: 0.8278 - val_loss: 0.8176 - val_accuracy: 0.7384\n",
      "Epoch 435/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5693 - accuracy: 0.8216 - val_loss: 0.8479 - val_accuracy: 0.7266\n",
      "Epoch 436/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5250 - accuracy: 0.8466 - val_loss: 0.8247 - val_accuracy: 0.7403\n",
      "Epoch 437/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5203 - accuracy: 0.8278 - val_loss: 0.8183 - val_accuracy: 0.7484\n",
      "Epoch 438/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5749 - accuracy: 0.8233 - val_loss: 0.7964 - val_accuracy: 0.7475\n",
      "Epoch 439/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5219 - accuracy: 0.8398 - val_loss: 0.8182 - val_accuracy: 0.7425\n",
      "Epoch 440/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5412 - accuracy: 0.8341 - val_loss: 0.7996 - val_accuracy: 0.7466\n",
      "Epoch 441/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5777 - accuracy: 0.8205 - val_loss: 0.8162 - val_accuracy: 0.7466\n",
      "Epoch 442/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5426 - accuracy: 0.8347 - val_loss: 0.8611 - val_accuracy: 0.7316\n",
      "Epoch 443/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5369 - accuracy: 0.8313 - val_loss: 0.8367 - val_accuracy: 0.7384\n",
      "Epoch 444/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5654 - accuracy: 0.8386 - val_loss: 0.8106 - val_accuracy: 0.7466\n",
      "Epoch 445/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5401 - accuracy: 0.8250 - val_loss: 0.8403 - val_accuracy: 0.7325\n",
      "Epoch 446/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.4920 - accuracy: 0.8585 - val_loss: 0.7927 - val_accuracy: 0.7497\n",
      "Epoch 447/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5540 - accuracy: 0.8318 - val_loss: 0.8389 - val_accuracy: 0.7353\n",
      "Epoch 448/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5278 - accuracy: 0.8449 - val_loss: 0.8409 - val_accuracy: 0.7412\n",
      "Epoch 449/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5427 - accuracy: 0.8278 - val_loss: 0.8397 - val_accuracy: 0.7444\n",
      "Epoch 450/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5493 - accuracy: 0.8250 - val_loss: 0.8487 - val_accuracy: 0.7381\n",
      "Epoch 451/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5472 - accuracy: 0.8330 - val_loss: 0.8081 - val_accuracy: 0.7466\n",
      "Epoch 452/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5801 - accuracy: 0.8233 - val_loss: 0.8379 - val_accuracy: 0.7456\n",
      "Epoch 453/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5773 - accuracy: 0.8216 - val_loss: 0.8418 - val_accuracy: 0.7341\n",
      "Epoch 454/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5542 - accuracy: 0.8335 - val_loss: 0.8288 - val_accuracy: 0.7425\n",
      "Epoch 455/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5751 - accuracy: 0.8301 - val_loss: 0.8294 - val_accuracy: 0.7391\n",
      "Epoch 456/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5628 - accuracy: 0.8256 - val_loss: 0.8117 - val_accuracy: 0.7484\n",
      "Epoch 457/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.6057 - accuracy: 0.8119 - val_loss: 0.8321 - val_accuracy: 0.7381\n",
      "Epoch 458/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.5647 - accuracy: 0.8307 - val_loss: 0.8049 - val_accuracy: 0.7453\n",
      "Epoch 459/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5310 - accuracy: 0.8381 - val_loss: 0.8293 - val_accuracy: 0.7497\n",
      "Epoch 460/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5685 - accuracy: 0.8250 - val_loss: 0.8182 - val_accuracy: 0.7472\n",
      "Epoch 461/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5602 - accuracy: 0.8256 - val_loss: 0.8090 - val_accuracy: 0.7487\n",
      "Epoch 462/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5046 - accuracy: 0.8500 - val_loss: 0.8181 - val_accuracy: 0.7491\n",
      "Epoch 463/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5666 - accuracy: 0.8267 - val_loss: 0.8453 - val_accuracy: 0.7387\n",
      "Epoch 464/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5453 - accuracy: 0.8460 - val_loss: 0.8325 - val_accuracy: 0.7372\n",
      "Epoch 465/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5568 - accuracy: 0.8301 - val_loss: 0.8331 - val_accuracy: 0.7375\n",
      "Epoch 466/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5906 - accuracy: 0.8080 - val_loss: 0.8432 - val_accuracy: 0.7278\n",
      "Epoch 467/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5538 - accuracy: 0.8239 - val_loss: 0.8443 - val_accuracy: 0.7344\n",
      "Epoch 468/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5379 - accuracy: 0.8352 - val_loss: 0.8475 - val_accuracy: 0.7453\n",
      "Epoch 469/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5694 - accuracy: 0.8244 - val_loss: 0.8160 - val_accuracy: 0.7481\n",
      "Epoch 470/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5631 - accuracy: 0.8290 - val_loss: 0.8243 - val_accuracy: 0.7437\n",
      "Epoch 471/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5179 - accuracy: 0.8415 - val_loss: 0.8194 - val_accuracy: 0.7487\n",
      "Epoch 472/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5806 - accuracy: 0.8244 - val_loss: 0.8178 - val_accuracy: 0.7453\n",
      "Epoch 473/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5525 - accuracy: 0.8318 - val_loss: 0.8514 - val_accuracy: 0.7325\n",
      "Epoch 474/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5587 - accuracy: 0.8261 - val_loss: 0.8280 - val_accuracy: 0.7447\n",
      "Epoch 475/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5616 - accuracy: 0.8318 - val_loss: 0.8224 - val_accuracy: 0.7497\n",
      "Epoch 476/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5397 - accuracy: 0.8330 - val_loss: 0.8761 - val_accuracy: 0.7194\n",
      "Epoch 477/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5397 - accuracy: 0.8284 - val_loss: 0.7987 - val_accuracy: 0.7497\n",
      "Epoch 478/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5822 - accuracy: 0.8313 - val_loss: 0.8322 - val_accuracy: 0.7403\n",
      "Epoch 479/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5156 - accuracy: 0.8443 - val_loss: 0.8164 - val_accuracy: 0.7437\n",
      "Epoch 480/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5853 - accuracy: 0.8318 - val_loss: 0.8416 - val_accuracy: 0.7391\n",
      "Epoch 481/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5458 - accuracy: 0.8307 - val_loss: 0.8354 - val_accuracy: 0.7375\n",
      "Epoch 482/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5552 - accuracy: 0.8301 - val_loss: 0.8405 - val_accuracy: 0.7328\n",
      "Epoch 483/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5787 - accuracy: 0.8301 - val_loss: 0.8703 - val_accuracy: 0.7269\n",
      "Epoch 484/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5556 - accuracy: 0.8352 - val_loss: 0.8237 - val_accuracy: 0.7422\n",
      "Epoch 485/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5696 - accuracy: 0.8295 - val_loss: 0.8407 - val_accuracy: 0.7375\n",
      "Epoch 486/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5533 - accuracy: 0.8290 - val_loss: 0.8248 - val_accuracy: 0.7441\n",
      "Epoch 487/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5682 - accuracy: 0.8233 - val_loss: 0.8433 - val_accuracy: 0.7369\n",
      "Epoch 488/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5222 - accuracy: 0.8449 - val_loss: 0.8566 - val_accuracy: 0.7391\n",
      "Epoch 489/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5348 - accuracy: 0.8324 - val_loss: 0.8656 - val_accuracy: 0.7341\n",
      "Epoch 490/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5256 - accuracy: 0.8313 - val_loss: 0.8735 - val_accuracy: 0.7297\n",
      "Epoch 491/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5572 - accuracy: 0.8267 - val_loss: 0.8844 - val_accuracy: 0.7234\n",
      "Epoch 492/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5169 - accuracy: 0.8511 - val_loss: 0.8839 - val_accuracy: 0.7334\n",
      "Epoch 493/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5214 - accuracy: 0.8369 - val_loss: 0.8667 - val_accuracy: 0.7366\n",
      "Epoch 494/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5534 - accuracy: 0.8364 - val_loss: 0.8644 - val_accuracy: 0.7297\n",
      "Epoch 495/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.4932 - accuracy: 0.8489 - val_loss: 0.8641 - val_accuracy: 0.7369\n",
      "Epoch 496/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5276 - accuracy: 0.8352 - val_loss: 0.8539 - val_accuracy: 0.7350\n",
      "Epoch 497/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5555 - accuracy: 0.8386 - val_loss: 0.8518 - val_accuracy: 0.7434\n",
      "Epoch 498/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5126 - accuracy: 0.8472 - val_loss: 0.8638 - val_accuracy: 0.7375\n",
      "Epoch 499/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5085 - accuracy: 0.8233 - val_loss: 0.8257 - val_accuracy: 0.7444\n",
      "Epoch 500/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5062 - accuracy: 0.8438 - val_loss: 0.8230 - val_accuracy: 0.7513\n",
      "Epoch 501/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5668 - accuracy: 0.8301 - val_loss: 0.8690 - val_accuracy: 0.7344\n",
      "Epoch 502/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5160 - accuracy: 0.8352 - val_loss: 0.8378 - val_accuracy: 0.7412\n",
      "Epoch 503/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5156 - accuracy: 0.8443 - val_loss: 0.8273 - val_accuracy: 0.7462\n",
      "Epoch 504/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.4953 - accuracy: 0.8472 - val_loss: 0.8348 - val_accuracy: 0.7447\n",
      "Epoch 505/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5324 - accuracy: 0.8295 - val_loss: 0.8756 - val_accuracy: 0.7362\n",
      "Epoch 506/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5260 - accuracy: 0.8381 - val_loss: 0.8448 - val_accuracy: 0.7409\n",
      "Epoch 507/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5405 - accuracy: 0.8386 - val_loss: 0.8584 - val_accuracy: 0.7325\n",
      "Epoch 508/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5651 - accuracy: 0.8256 - val_loss: 0.8491 - val_accuracy: 0.7378\n",
      "Epoch 509/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5461 - accuracy: 0.8324 - val_loss: 0.8769 - val_accuracy: 0.7350\n",
      "Epoch 510/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.4642 - accuracy: 0.8608 - val_loss: 0.8381 - val_accuracy: 0.7462\n",
      "Epoch 511/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5477 - accuracy: 0.8278 - val_loss: 0.8447 - val_accuracy: 0.7362\n",
      "Epoch 512/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5182 - accuracy: 0.8347 - val_loss: 0.8308 - val_accuracy: 0.7447\n",
      "Epoch 513/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5237 - accuracy: 0.8494 - val_loss: 0.8729 - val_accuracy: 0.7362\n",
      "Epoch 514/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5222 - accuracy: 0.8375 - val_loss: 0.8624 - val_accuracy: 0.7331\n",
      "Epoch 515/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5068 - accuracy: 0.8409 - val_loss: 0.8452 - val_accuracy: 0.7381\n",
      "Epoch 516/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5132 - accuracy: 0.8438 - val_loss: 0.8782 - val_accuracy: 0.7237\n",
      "Epoch 517/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5112 - accuracy: 0.8386 - val_loss: 0.8825 - val_accuracy: 0.7225\n",
      "Epoch 518/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5264 - accuracy: 0.8415 - val_loss: 0.8645 - val_accuracy: 0.7350\n",
      "Epoch 519/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5363 - accuracy: 0.8301 - val_loss: 0.8559 - val_accuracy: 0.7397\n",
      "Epoch 520/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5593 - accuracy: 0.8284 - val_loss: 0.8360 - val_accuracy: 0.7466\n",
      "Epoch 521/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5372 - accuracy: 0.8455 - val_loss: 0.8492 - val_accuracy: 0.7394\n",
      "Epoch 522/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5283 - accuracy: 0.8432 - val_loss: 0.8658 - val_accuracy: 0.7391\n",
      "Epoch 523/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5407 - accuracy: 0.8290 - val_loss: 0.8507 - val_accuracy: 0.7387\n",
      "Epoch 524/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5420 - accuracy: 0.8409 - val_loss: 0.8707 - val_accuracy: 0.7359\n",
      "Epoch 525/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5617 - accuracy: 0.8210 - val_loss: 0.8969 - val_accuracy: 0.7300\n",
      "Epoch 526/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5075 - accuracy: 0.8392 - val_loss: 0.9076 - val_accuracy: 0.7159\n",
      "Epoch 527/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5374 - accuracy: 0.8472 - val_loss: 0.8998 - val_accuracy: 0.7216\n",
      "Epoch 528/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5042 - accuracy: 0.8375 - val_loss: 0.8530 - val_accuracy: 0.7425\n",
      "Epoch 529/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5123 - accuracy: 0.8466 - val_loss: 0.8440 - val_accuracy: 0.7469\n",
      "Epoch 530/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5194 - accuracy: 0.8517 - val_loss: 0.8729 - val_accuracy: 0.7387\n",
      "Epoch 531/600\n",
      "110/110 [==============================] - 54s 489ms/step - loss: 0.5215 - accuracy: 0.8386 - val_loss: 0.9067 - val_accuracy: 0.7228\n",
      "Epoch 532/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5194 - accuracy: 0.8398 - val_loss: 0.8651 - val_accuracy: 0.7403\n",
      "Epoch 533/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5615 - accuracy: 0.8313 - val_loss: 0.8631 - val_accuracy: 0.7362\n",
      "Epoch 534/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5220 - accuracy: 0.8347 - val_loss: 0.8598 - val_accuracy: 0.7381\n",
      "Epoch 535/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5233 - accuracy: 0.8415 - val_loss: 0.8458 - val_accuracy: 0.7394\n",
      "Epoch 536/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5265 - accuracy: 0.8443 - val_loss: 0.8612 - val_accuracy: 0.7344\n",
      "Epoch 537/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5565 - accuracy: 0.8335 - val_loss: 0.8829 - val_accuracy: 0.7281\n",
      "Epoch 538/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.4962 - accuracy: 0.8432 - val_loss: 0.8818 - val_accuracy: 0.7356\n",
      "Epoch 539/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5614 - accuracy: 0.8244 - val_loss: 0.9058 - val_accuracy: 0.7172\n",
      "Epoch 540/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5641 - accuracy: 0.8324 - val_loss: 0.8593 - val_accuracy: 0.7331\n",
      "Epoch 541/600\n",
      "110/110 [==============================] - 55s 500ms/step - loss: 0.5277 - accuracy: 0.8381 - val_loss: 0.8535 - val_accuracy: 0.7384\n",
      "Epoch 542/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.5405 - accuracy: 0.8386 - val_loss: 0.8415 - val_accuracy: 0.7419\n",
      "Epoch 543/600\n",
      "110/110 [==============================] - 55s 498ms/step - loss: 0.5080 - accuracy: 0.8460 - val_loss: 0.9001 - val_accuracy: 0.7272\n",
      "Epoch 544/600\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 0.5168 - accuracy: 0.8403 - val_loss: 0.8823 - val_accuracy: 0.7347\n",
      "Epoch 545/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5424 - accuracy: 0.8324 - val_loss: 0.8474 - val_accuracy: 0.7450\n",
      "Epoch 546/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5141 - accuracy: 0.8347 - val_loss: 0.8690 - val_accuracy: 0.7337\n",
      "Epoch 547/600\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.5375 - accuracy: 0.8301 - val_loss: 0.8882 - val_accuracy: 0.7291\n",
      "Epoch 548/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5331 - accuracy: 0.8420 - val_loss: 0.8865 - val_accuracy: 0.7344\n",
      "Epoch 549/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5413 - accuracy: 0.8426 - val_loss: 0.8746 - val_accuracy: 0.7369\n",
      "Epoch 550/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5628 - accuracy: 0.8409 - val_loss: 0.8690 - val_accuracy: 0.7391\n",
      "Epoch 551/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5164 - accuracy: 0.8466 - val_loss: 0.8699 - val_accuracy: 0.7337\n",
      "Epoch 552/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.4972 - accuracy: 0.8528 - val_loss: 0.8925 - val_accuracy: 0.7291\n",
      "Epoch 553/600\n",
      "110/110 [==============================] - 54s 491ms/step - loss: 0.5117 - accuracy: 0.8489 - val_loss: 0.8462 - val_accuracy: 0.7472\n",
      "Epoch 554/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5334 - accuracy: 0.8341 - val_loss: 0.8525 - val_accuracy: 0.7431\n",
      "Epoch 555/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5413 - accuracy: 0.8364 - val_loss: 0.8805 - val_accuracy: 0.7259\n",
      "Epoch 556/600\n",
      "110/110 [==============================] - 59s 532ms/step - loss: 0.5456 - accuracy: 0.8239 - val_loss: 0.8329 - val_accuracy: 0.7506\n",
      "Epoch 557/600\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 0.5112 - accuracy: 0.8517 - val_loss: 0.8817 - val_accuracy: 0.7266\n",
      "Epoch 558/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5480 - accuracy: 0.8330 - val_loss: 0.8816 - val_accuracy: 0.7306\n",
      "Epoch 559/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5372 - accuracy: 0.8386 - val_loss: 0.8954 - val_accuracy: 0.7312\n",
      "Epoch 560/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5304 - accuracy: 0.8420 - val_loss: 0.9150 - val_accuracy: 0.7300\n",
      "Epoch 561/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5036 - accuracy: 0.8500 - val_loss: 0.9004 - val_accuracy: 0.7241\n",
      "Epoch 562/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5649 - accuracy: 0.8210 - val_loss: 0.8600 - val_accuracy: 0.7422\n",
      "Epoch 563/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5573 - accuracy: 0.8307 - val_loss: 0.8680 - val_accuracy: 0.7425\n",
      "Epoch 564/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5272 - accuracy: 0.8477 - val_loss: 0.8699 - val_accuracy: 0.7422\n",
      "Epoch 565/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5055 - accuracy: 0.8432 - val_loss: 0.9308 - val_accuracy: 0.7209\n",
      "Epoch 566/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5900 - accuracy: 0.8102 - val_loss: 0.8793 - val_accuracy: 0.7312\n",
      "Epoch 567/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5390 - accuracy: 0.8432 - val_loss: 0.8824 - val_accuracy: 0.7431\n",
      "Epoch 568/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5091 - accuracy: 0.8449 - val_loss: 0.8820 - val_accuracy: 0.7331\n",
      "Epoch 569/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5505 - accuracy: 0.8278 - val_loss: 0.8586 - val_accuracy: 0.7469\n",
      "Epoch 570/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5517 - accuracy: 0.8358 - val_loss: 0.9006 - val_accuracy: 0.7306\n",
      "Epoch 571/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5688 - accuracy: 0.8301 - val_loss: 0.8593 - val_accuracy: 0.7422\n",
      "Epoch 572/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5412 - accuracy: 0.8375 - val_loss: 0.8871 - val_accuracy: 0.7303\n",
      "Epoch 573/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5110 - accuracy: 0.8483 - val_loss: 0.8461 - val_accuracy: 0.7456\n",
      "Epoch 574/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5400 - accuracy: 0.8324 - val_loss: 0.8707 - val_accuracy: 0.7397\n",
      "Epoch 575/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5286 - accuracy: 0.8398 - val_loss: 0.8635 - val_accuracy: 0.7444\n",
      "Epoch 576/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.4913 - accuracy: 0.8511 - val_loss: 0.8584 - val_accuracy: 0.7434\n",
      "Epoch 577/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5312 - accuracy: 0.8386 - val_loss: 0.8740 - val_accuracy: 0.7387\n",
      "Epoch 578/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5503 - accuracy: 0.8364 - val_loss: 0.8577 - val_accuracy: 0.7416\n",
      "Epoch 579/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.5099 - accuracy: 0.8426 - val_loss: 0.8730 - val_accuracy: 0.7391\n",
      "Epoch 580/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.4795 - accuracy: 0.8523 - val_loss: 0.8606 - val_accuracy: 0.7456\n",
      "Epoch 581/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.4987 - accuracy: 0.8585 - val_loss: 0.8767 - val_accuracy: 0.7419\n",
      "Epoch 582/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5047 - accuracy: 0.8472 - val_loss: 0.9026 - val_accuracy: 0.7309\n",
      "Epoch 583/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.4805 - accuracy: 0.8443 - val_loss: 0.8636 - val_accuracy: 0.7444\n",
      "Epoch 584/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5159 - accuracy: 0.8415 - val_loss: 0.8541 - val_accuracy: 0.7484\n",
      "Epoch 585/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5355 - accuracy: 0.8409 - val_loss: 0.8848 - val_accuracy: 0.7328\n",
      "Epoch 586/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5051 - accuracy: 0.8392 - val_loss: 0.9028 - val_accuracy: 0.7244\n",
      "Epoch 587/600\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.5156 - accuracy: 0.8358 - val_loss: 0.8766 - val_accuracy: 0.7356\n",
      "Epoch 588/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.4931 - accuracy: 0.8472 - val_loss: 0.9203 - val_accuracy: 0.7259\n",
      "Epoch 589/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5417 - accuracy: 0.8341 - val_loss: 0.8795 - val_accuracy: 0.7394\n",
      "Epoch 590/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5280 - accuracy: 0.8409 - val_loss: 0.8968 - val_accuracy: 0.7231\n",
      "Epoch 591/600\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 0.4957 - accuracy: 0.8420 - val_loss: 0.8921 - val_accuracy: 0.7262\n",
      "Epoch 592/600\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.5266 - accuracy: 0.8511 - val_loss: 0.8621 - val_accuracy: 0.7369\n",
      "Epoch 593/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5147 - accuracy: 0.8466 - val_loss: 0.8904 - val_accuracy: 0.7362\n",
      "Epoch 594/600\n",
      "110/110 [==============================] - 54s 493ms/step - loss: 0.5045 - accuracy: 0.8466 - val_loss: 0.9164 - val_accuracy: 0.7350\n",
      "Epoch 595/600\n",
      "110/110 [==============================] - 54s 492ms/step - loss: 0.5135 - accuracy: 0.8426 - val_loss: 0.8856 - val_accuracy: 0.7306\n",
      "Epoch 596/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5545 - accuracy: 0.8301 - val_loss: 0.8722 - val_accuracy: 0.7425\n",
      "Epoch 597/600\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.5160 - accuracy: 0.8415 - val_loss: 0.8529 - val_accuracy: 0.7406\n",
      "Epoch 598/600\n",
      "110/110 [==============================] - 56s 508ms/step - loss: 0.4856 - accuracy: 0.8551 - val_loss: 0.8769 - val_accuracy: 0.7322\n",
      "Epoch 599/600\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.5009 - accuracy: 0.8477 - val_loss: 0.8817 - val_accuracy: 0.7372\n",
      "Epoch 600/600\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.5232 - accuracy: 0.8369 - val_loss: 0.8789 - val_accuracy: 0.7356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205cb519348>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try improving with learning rate=0.00001\n",
    "model_3.fit(train,\n",
    "            epochs=600,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_3.predict(val)\n",
    "\n",
    "# Convert to a dataframe with original labels\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_3_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.7318 - accuracy: 0.7569\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_3_val_metrics = model_3.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_3_val_metrics[0]], \n",
    "                                    'Accuracy':[model_3_val_metrics[1]]})\n",
    "model_3_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_3_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731836</td>\n",
       "      <td>0.756875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0            0.731836  0.756875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model3 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model3.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(model3.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model3 = tf.keras.models.Model(model3.input, x)\n",
    "\n",
    "model3.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'categorical_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\imgs\\\\testlabeled\\\\unsorted'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('D:\\\\Users\\\\Dylan\\\\Documents\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 73s 667ms/step - loss: 2.5233 - acc: 0.1318 - val_loss: 2.2212 - val_acc: 0.1472\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 73s 666ms/step - loss: 2.2779 - acc: 0.1562 - val_loss: 2.1070 - val_acc: 0.3166\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 73s 663ms/step - loss: 2.1991 - acc: 0.2000 - val_loss: 1.9553 - val_acc: 0.4006\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 68s 621ms/step - loss: 2.0999 - acc: 0.2307 - val_loss: 1.8996 - val_acc: 0.4181\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 71s 644ms/step - loss: 2.0020 - acc: 0.2710 - val_loss: 1.6876 - val_acc: 0.4712\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 65s 587ms/step - loss: 1.9430 - acc: 0.3136 - val_loss: 1.6530 - val_acc: 0.5459\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 65s 590ms/step - loss: 1.8607 - acc: 0.3432 - val_loss: 1.5234 - val_acc: 0.4947\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 64s 584ms/step - loss: 1.7939 - acc: 0.3670 - val_loss: 1.4623 - val_acc: 0.6050\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 66s 597ms/step - loss: 1.7174 - acc: 0.4040 - val_loss: 1.3616 - val_acc: 0.5884\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 64s 584ms/step - loss: 1.6940 - acc: 0.4199 - val_loss: 1.3336 - val_acc: 0.6266\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 62s 563ms/step - loss: 1.6020 - acc: 0.4619 - val_loss: 1.2495 - val_acc: 0.6841\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 1.6074 - acc: 0.4358 - val_loss: 1.1923 - val_acc: 0.6463\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 61s 558ms/step - loss: 1.5346 - acc: 0.4841 - val_loss: 1.1994 - val_acc: 0.6397\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 59s 533ms/step - loss: 1.5103 - acc: 0.4750 - val_loss: 1.1984 - val_acc: 0.5722\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 59s 537ms/step - loss: 1.4732 - acc: 0.5045 - val_loss: 1.0659 - val_acc: 0.6828\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 60s 541ms/step - loss: 1.4102 - acc: 0.5182 - val_loss: 1.1323 - val_acc: 0.6678\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.3891 - acc: 0.5199 - val_loss: 1.1047 - val_acc: 0.6637\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 61s 551ms/step - loss: 1.3679 - acc: 0.5335 - val_loss: 1.0054 - val_acc: 0.6997\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 62s 563ms/step - loss: 1.3247 - acc: 0.5534 - val_loss: 1.0692 - val_acc: 0.5931\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 67s 611ms/step - loss: 1.3033 - acc: 0.5608 - val_loss: 0.9165 - val_acc: 0.7212\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.2867 - acc: 0.5625 - val_loss: 0.9930 - val_acc: 0.6725\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.2725 - acc: 0.5574 - val_loss: 0.9397 - val_acc: 0.6950\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.2546 - acc: 0.5864 - val_loss: 0.9265 - val_acc: 0.6875\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 1.2080 - acc: 0.5881 - val_loss: 0.9437 - val_acc: 0.7044\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.1980 - acc: 0.5977 - val_loss: 1.0010 - val_acc: 0.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ee1d5e888>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train,\n",
    "                epochs=50,\n",
    "                steps_per_epoch=110,\n",
    "                validation_data=test,\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = model3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_data = df_test.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p050</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_37057.jpg</td>\n",
       "      <td>imgs/train/c9/img_37057.jpg</td>\n",
       "      <td>0.038092</td>\n",
       "      <td>0.047378</td>\n",
       "      <td>0.055674</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.036965</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.043091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p056</td>\n",
       "      <td>c1</td>\n",
       "      <td>img_70214.jpg</td>\n",
       "      <td>imgs/train/c1/img_70214.jpg</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.665885</td>\n",
       "      <td>0.046201</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.147198</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.066739</td>\n",
       "      <td>0.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p050</td>\n",
       "      <td>c7</td>\n",
       "      <td>img_89317.jpg</td>\n",
       "      <td>imgs/train/c7/img_89317.jpg</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.058346</td>\n",
       "      <td>0.321970</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.522277</td>\n",
       "      <td>0.043075</td>\n",
       "      <td>0.025248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p041</td>\n",
       "      <td>c1</td>\n",
       "      <td>img_9714.jpg</td>\n",
       "      <td>imgs/train/c1/img_9714.jpg</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>0.579883</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.050977</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.064224</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.048320</td>\n",
       "      <td>0.138128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p016</td>\n",
       "      <td>c2</td>\n",
       "      <td>img_46158.jpg</td>\n",
       "      <td>imgs/train/c2/img_46158.jpg</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.329363</td>\n",
       "      <td>0.136421</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.121248</td>\n",
       "      <td>0.182954</td>\n",
       "      <td>0.082555</td>\n",
       "      <td>0.102285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>p041</td>\n",
       "      <td>c3</td>\n",
       "      <td>img_78650.jpg</td>\n",
       "      <td>imgs/train/c3/img_78650.jpg</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.822273</td>\n",
       "      <td>0.130280</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.006525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>p041</td>\n",
       "      <td>c4</td>\n",
       "      <td>img_83455.jpg</td>\n",
       "      <td>imgs/train/c4/img_83455.jpg</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.164005</td>\n",
       "      <td>0.793564</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.003310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>p041</td>\n",
       "      <td>c6</td>\n",
       "      <td>img_58453.jpg</td>\n",
       "      <td>imgs/train/c6/img_58453.jpg</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.390130</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.084743</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.285895</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.016109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>p041</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_51874.jpg</td>\n",
       "      <td>imgs/train/c0/img_51874.jpg</td>\n",
       "      <td>0.409633</td>\n",
       "      <td>0.021191</td>\n",
       "      <td>0.047486</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.039794</td>\n",
       "      <td>0.050137</td>\n",
       "      <td>0.308477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>p056</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_90247.jpg</td>\n",
       "      <td>imgs/train/c9/img_90247.jpg</td>\n",
       "      <td>0.174123</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.026641</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>0.078980</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>0.616062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject classname            img                      imgpath        c0  \\\n",
       "0       p050        c9  img_37057.jpg  imgs/train/c9/img_37057.jpg  0.038092   \n",
       "1       p056        c1  img_70214.jpg  imgs/train/c1/img_70214.jpg  0.001814   \n",
       "2       p050        c7  img_89317.jpg  imgs/train/c7/img_89317.jpg  0.004418   \n",
       "3       p041        c1   img_9714.jpg   imgs/train/c1/img_9714.jpg  0.021931   \n",
       "4       p016        c2  img_46158.jpg  imgs/train/c2/img_46158.jpg  0.003152   \n",
       "...      ...       ...            ...                          ...       ...   \n",
       "3195    p041        c3  img_78650.jpg  imgs/train/c3/img_78650.jpg  0.009461   \n",
       "3196    p041        c4  img_83455.jpg  imgs/train/c4/img_83455.jpg  0.007229   \n",
       "3197    p041        c6  img_58453.jpg  imgs/train/c6/img_58453.jpg  0.005851   \n",
       "3198    p041        c0  img_51874.jpg  imgs/train/c0/img_51874.jpg  0.409633   \n",
       "3199    p056        c9  img_90247.jpg  imgs/train/c9/img_90247.jpg  0.174123   \n",
       "\n",
       "            c1        c2        c3        c4        c5        c6        c7  \\\n",
       "0     0.047378  0.055674  0.003527  0.011132  0.032342  0.036965  0.002194   \n",
       "1     0.665885  0.046201  0.011587  0.001652  0.002267  0.147198  0.049998   \n",
       "2     0.058346  0.321970  0.004580  0.001134  0.001784  0.017168  0.522277   \n",
       "3     0.579883  0.051502  0.050977  0.004998  0.064224  0.037028  0.003008   \n",
       "4     0.329363  0.136421  0.014852  0.012734  0.014436  0.121248  0.182954   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3195  0.001977  0.004556  0.822273  0.130280  0.014533  0.001842  0.000328   \n",
       "3196  0.000311  0.011610  0.164005  0.793564  0.010024  0.003079  0.000376   \n",
       "3197  0.024534  0.390130  0.028171  0.084743  0.035849  0.285895  0.004593   \n",
       "3198  0.021191  0.047486  0.014772  0.004590  0.097627  0.006294  0.039794   \n",
       "3199  0.042037  0.019459  0.026641  0.004215  0.016195  0.003116  0.078980   \n",
       "\n",
       "            c8        c9  \n",
       "0     0.729606  0.043091  \n",
       "1     0.066739  0.006660  \n",
       "2     0.043075  0.025248  \n",
       "3     0.048320  0.138128  \n",
       "4     0.082555  0.102285  \n",
       "...        ...       ...  \n",
       "3195  0.008226  0.006525  \n",
       "3196  0.006493  0.003310  \n",
       "3197  0.124124  0.016109  \n",
       "3198  0.050137  0.308477  \n",
       "3199  0.019172  0.616062  \n",
       "\n",
       "[3200 rows x 14 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_data.to_csv('../processed/VGG16_classifier_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classifier_train_data.drop(columns=['subject', 'classname', 'img', 'imgpath'])\n",
    "y= classifier_train_data[['classname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "          'min_samples_split':np.arange(2, 20, 1),\n",
    "          'min_samples_leaf':np.arange(1, 20, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandForest = RandomizedSearchCV(clf, params, scoring='accuracy', \n",
    "                           n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(n_jobs=-2), n_iter=30,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'min_samples_leaf': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                                        'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19])},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandForest.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "print(RandForest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RandForest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          c0       0.88      0.97      0.93        77\n",
      "          c1       0.96      0.96      0.96        82\n",
      "          c2       0.92      0.92      0.92        78\n",
      "          c3       0.99      0.95      0.97        87\n",
      "          c4       0.98      0.99      0.98        89\n",
      "          c5       1.00      1.00      1.00        76\n",
      "          c6       0.89      0.95      0.92        78\n",
      "          c7       0.95      0.99      0.97        70\n",
      "          c8       0.99      0.85      0.91        84\n",
      "          c9       0.97      0.95      0.96        79\n",
      "\n",
      "    accuracy                           0.95       800\n",
      "   macro avg       0.95      0.95      0.95       800\n",
      "weighted avg       0.95      0.95      0.95       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models are created now. Let's evaluate on the small labeled test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled_df = pd.read_csv('../processed/labeled_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_101570.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_102035.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_22.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_23.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_24.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>img_54733.jpg</td>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>img_54928.jpg</td>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>img_54990.jpg</td>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>img_55171.jpg</td>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>img_55896.jpg</td>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename classname\n",
       "0    img_101570.jpg        c0\n",
       "1    img_102035.jpg        c0\n",
       "2        img_22.jpg        c0\n",
       "3        img_23.jpg        c0\n",
       "4        img_24.jpg        c0\n",
       "..              ...       ...\n",
       "195   img_54733.jpg        c9\n",
       "196   img_54928.jpg        c9\n",
       "197   img_54990.jpg        c9\n",
       "198   img_55171.jpg        c9\n",
       "199   img_55896.jpg        c9\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\imgs\\\\testlabeled\\\\unsorted'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'imgs/testlabeled/unsorted'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-cde23e6205a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imgs/testlabeled/unsorted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'imgs/testlabeled/unsorted'"
     ]
    }
   ],
   "source": [
    "os.chdir('imgs/testlabeled/unsorted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = test_dgen.flow_from_dataframe(test_labeled_df,\n",
    "                                     x_col='filename',\n",
    "                                     y_col='classname',\n",
    "                                     target_size=(227,227),\n",
    "                                     batch_size=16,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_output = model3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "13/13 [==============================] - 2s 125ms/step - loss: 0.8906 - acc: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8905925131761111, 0.73]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labeled_test=test_labeled_df[['classname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled_test = pd.DataFrame(test_nn_output, \n",
    "                              columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047275</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>0.096730</td>\n",
       "      <td>0.443145</td>\n",
       "      <td>0.157516</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.106239</td>\n",
       "      <td>0.040052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.757133</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.082580</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.129122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.393718</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.249553</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.262715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469957</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.127384</td>\n",
       "      <td>0.066894</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.278104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.102216</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.464914</td>\n",
       "      <td>0.107785</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.053829</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>0.033943</td>\n",
       "      <td>0.102189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.107628</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.498552</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.343667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>0.019866</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.944786</td>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.486174</td>\n",
       "      <td>0.046821</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.012781</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.115279</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.328040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.106881</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.058115</td>\n",
       "      <td>0.084603</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.143699</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.341437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.069602</td>\n",
       "      <td>0.038255</td>\n",
       "      <td>0.028288</td>\n",
       "      <td>0.071635</td>\n",
       "      <td>0.063002</td>\n",
       "      <td>0.039964</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.057093</td>\n",
       "      <td>0.617061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           c0        c1        c2        c3        c4        c5        c6  \\\n",
       "0    0.047275  0.005121  0.027903  0.069816  0.096730  0.443145  0.157516   \n",
       "1    0.757133  0.000159  0.000689  0.019632  0.008444  0.082580  0.000070   \n",
       "2    0.393718  0.007405  0.000747  0.249553  0.039259  0.031297  0.001105   \n",
       "3    0.469957  0.009404  0.002149  0.127384  0.066894  0.024054  0.001107   \n",
       "4    0.102190  0.102216  0.010231  0.464914  0.107785  0.008216  0.053829   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.004901  0.107628  0.026312  0.000329  0.000066  0.002584  0.002301   \n",
       "196  0.001136  0.006047  0.019866  0.002046  0.004147  0.001085  0.005265   \n",
       "197  0.486174  0.046821  0.000994  0.012781  0.000907  0.115279  0.001817   \n",
       "198  0.106881  0.007360  0.058115  0.084603  0.080829  0.007823  0.006192   \n",
       "199  0.069602  0.038255  0.028288  0.071635  0.063002  0.039964  0.006913   \n",
       "\n",
       "           c7        c8        c9  \n",
       "0    0.006203  0.106239  0.040052  \n",
       "1    0.000231  0.001939  0.129122  \n",
       "2    0.001983  0.012218  0.262715  \n",
       "3    0.005694  0.015252  0.278104  \n",
       "4    0.014488  0.033943  0.102189  \n",
       "..        ...       ...       ...  \n",
       "195  0.498552  0.013659  0.343667  \n",
       "196  0.003656  0.944786  0.011967  \n",
       "197  0.001643  0.005545  0.328040  \n",
       "198  0.143699  0.163061  0.341437  \n",
       "199  0.008187  0.057093  0.617061  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labeled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>c9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    classname\n",
       "0          c0\n",
       "1          c0\n",
       "2          c0\n",
       "3          c0\n",
       "4          c0\n",
       "..        ...\n",
       "195        c9\n",
       "196        c9\n",
       "197        c9\n",
       "198        c9\n",
       "199        c9\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labeled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_predictions = RandForest.predict(X_labeled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c6', 'c0', 'c0', 'c0', 'c3', 'c0', 'c0', 'c0', 'c0', 'c0', 'c5',\n",
       "       'c0', 'c0', 'c0', 'c0', 'c4', 'c0', 'c0', 'c0', 'c0', 'c1', 'c1',\n",
       "       'c1', 'c1', 'c1', 'c8', 'c2', 'c1', 'c1', 'c6', 'c1', 'c8', 'c1',\n",
       "       'c1', 'c6', 'c1', 'c1', 'c2', 'c1', 'c1', 'c6', 'c6', 'c8', 'c2',\n",
       "       'c1', 'c7', 'c1', 'c1', 'c2', 'c6', 'c7', 'c2', 'c2', 'c8', 'c1',\n",
       "       'c7', 'c8', 'c2', 'c2', 'c2', 'c3', 'c5', 'c3', 'c4', 'c3', 'c3',\n",
       "       'c3', 'c3', 'c4', 'c4', 'c3', 'c3', 'c3', 'c3', 'c3', 'c3', 'c3',\n",
       "       'c3', 'c0', 'c3', 'c8', 'c3', 'c4', 'c4', 'c8', 'c4', 'c4', 'c4',\n",
       "       'c4', 'c4', 'c3', 'c3', 'c4', 'c4', 'c4', 'c4', 'c4', 'c3', 'c4',\n",
       "       'c4', 'c5', 'c5', 'c5', 'c5', 'c5', 'c5', 'c5', 'c5', 'c5', 'c5',\n",
       "       'c5', 'c5', 'c5', 'c5', 'c8', 'c5', 'c5', 'c5', 'c5', 'c5', 'c6',\n",
       "       'c6', 'c6', 'c6', 'c6', 'c1', 'c6', 'c6', 'c6', 'c6', 'c6', 'c1',\n",
       "       'c8', 'c8', 'c6', 'c8', 'c6', 'c6', 'c6', 'c6', 'c7', 'c7', 'c7',\n",
       "       'c8', 'c8', 'c8', 'c7', 'c8', 'c1', 'c7', 'c7', 'c7', 'c7', 'c7',\n",
       "       'c8', 'c7', 'c6', 'c1', 'c8', 'c7', 'c6', 'c8', 'c8', 'c8', 'c8',\n",
       "       'c8', 'c8', 'c8', 'c8', 'c8', 'c8', 'c3', 'c7', 'c8', 'c8', 'c1',\n",
       "       'c8', 'c8', 'c8', 'c8', 'c5', 'c9', 'c0', 'c9', 'c8', 'c8', 'c8',\n",
       "       'c0', 'c9', 'c0', 'c0', 'c8', 'c9', 'c9', 'c0', 'c9', 'c8', 'c0',\n",
       "       'c9', 'c9'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          c0       0.70      0.80      0.74        20\n",
      "          c1       0.61      0.70      0.65        20\n",
      "          c2       0.78      0.35      0.48        20\n",
      "          c3       0.71      0.75      0.73        20\n",
      "          c4       0.78      0.70      0.74        20\n",
      "          c5       0.86      0.95      0.90        20\n",
      "          c6       0.65      0.75      0.70        20\n",
      "          c7       0.73      0.55      0.63        20\n",
      "          c8       0.42      0.80      0.55        20\n",
      "          c9       1.00      0.40      0.57        20\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.72      0.68      0.67       200\n",
      "weighted avg       0.72      0.68      0.67       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_labeled_test, labeled_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01       0.006      0.04404762 ... 0.002      0.1195     0.01      ]\n",
      " [0.90940476 0.         0.         ... 0.01       0.04083333 0.0225    ]\n",
      " [0.94166667 0.         0.         ... 0.         0.         0.05833333]\n",
      " ...\n",
      " [0.92666667 0.         0.         ... 0.         0.         0.06      ]\n",
      " [0.2202619  0.00666667 0.0205     ... 0.015      0.17980952 0.36592857]\n",
      " [0.11433333 0.00916667 0.0165     ... 0.         0.022      0.6155    ]]\n"
     ]
    }
   ],
   "source": [
    "print(RandForest.predict_proba(X_labeled_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datagen for actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir('data/raw/imgs/test/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = pd.DataFrame({'filename':test_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename\n",
       "0           img_1.jpg\n",
       "1          img_10.jpg\n",
       "2         img_100.jpg\n",
       "3        img_1000.jpg\n",
       "4      img_100000.jpg\n",
       "...               ...\n",
       "79721   img_99994.jpg\n",
       "79722   img_99995.jpg\n",
       "79723   img_99996.jpg\n",
       "79724   img_99998.jpg\n",
       "79725   img_99999.jpg\n",
       "\n",
       "[79726 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames.to_csv('data/raw/test_filenames.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename\n",
       "0           img_1.jpg\n",
       "1          img_10.jpg\n",
       "2         img_100.jpg\n",
       "3        img_1000.jpg\n",
       "4      img_100000.jpg\n",
       "...               ...\n",
       "79721   img_99994.jpg\n",
       "79722   img_99995.jpg\n",
       "79723   img_99996.jpg\n",
       "79724   img_99998.jpg\n",
       "79725   img_99999.jpg\n",
       "\n",
       "[79726 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['filename'] = df_test[['filename']].apply(lambda x: 'C:/Users/Dylan/Desktop/Data Science/Projects/DistractedDrivers/data/raw/imgs/test/test/' + x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>C:/Users/Dylan/Desktop/Data Science/Projects/D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename\n",
       "0      C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "1      C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "2      C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "3      C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "4      C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "...                                                  ...\n",
       "79721  C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "79722  C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "79723  C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "79724  C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "79725  C:/Users/Dylan/Desktop/Data Science/Projects/D...\n",
       "\n",
       "[79726 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\imgs\\\\test\\\\test'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['class'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('C:/Users/Dylan/Desktop/Data Science/Projects/DistractedDrivers/data/raw/test_filenames.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test = test_dgen.flow_from_dataframe(test_filenames,\n",
    "                                     target_size=(227,227),\n",
    "                                     batch_size=16,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame(test_predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.085207</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.600935</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.022482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.941262</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200818</td>\n",
       "      <td>0.249065</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.062749</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>0.311247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.943617</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.701084</td>\n",
       "      <td>0.199329</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.186477</td>\n",
       "      <td>0.133851</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.029475</td>\n",
       "      <td>0.449997</td>\n",
       "      <td>0.096771</td>\n",
       "      <td>0.085079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>0.013295</td>\n",
       "      <td>0.035097</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.931134</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.041994</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>0.099453</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.085182</td>\n",
       "      <td>0.286448</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.328923</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>0.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.934877</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             c0        c1        c2        c3        c4        c5        c6  \\\n",
       "0      0.008604  0.085207  0.018095  0.113947  0.040185  0.600935  0.077657   \n",
       "1      0.019094  0.000826  0.001663  0.006799  0.003642  0.941262  0.001846   \n",
       "2      0.200818  0.249065  0.058669  0.010818  0.004579  0.048115  0.014242   \n",
       "3      0.004387  0.002688  0.024336  0.000805  0.002280  0.009872  0.004561   \n",
       "4      0.045187  0.001458  0.000840  0.701084  0.199329  0.022523  0.005878   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "79721  0.004477  0.186477  0.133851  0.001749  0.000536  0.011587  0.029475   \n",
       "79722  0.013295  0.035097  0.000265  0.931134  0.004813  0.001793  0.002391   \n",
       "79723  0.000791  0.041994  0.000147  0.846906  0.099453  0.000325  0.007390   \n",
       "79724  0.000449  0.085182  0.286448  0.000522  0.000433  0.000592  0.328923   \n",
       "79725  0.036727  0.002992  0.000412  0.005636  0.001364  0.934877  0.000635   \n",
       "\n",
       "             c7        c8        c9  \n",
       "0      0.006483  0.026404  0.022482  \n",
       "1      0.000832  0.017235  0.006800  \n",
       "2      0.062749  0.039698  0.311247  \n",
       "3      0.000767  0.943617  0.006687  \n",
       "4      0.001054  0.016436  0.006211  \n",
       "...         ...       ...       ...  \n",
       "79721  0.449997  0.096771  0.085079  \n",
       "79722  0.000746  0.002524  0.007941  \n",
       "79723  0.000138  0.002115  0.000740  \n",
       "79724  0.205457  0.084118  0.007875  \n",
       "79725  0.000332  0.008541  0.008485  \n",
       "\n",
       "[79726 rows x 10 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.085207</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.600935</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.022482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.941262</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.200818</td>\n",
       "      <td>0.249065</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.062749</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>0.311247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.943617</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.701084</td>\n",
       "      <td>0.199329</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.186477</td>\n",
       "      <td>0.133851</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.029475</td>\n",
       "      <td>0.449997</td>\n",
       "      <td>0.096771</td>\n",
       "      <td>0.085079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>0.035097</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.931134</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.041994</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>0.099453</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.085182</td>\n",
       "      <td>0.286448</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.328923</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>0.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.934877</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img        c0        c1        c2        c3        c4  \\\n",
       "0           img_1.jpg  0.008604  0.085207  0.018095  0.113947  0.040185   \n",
       "1          img_10.jpg  0.019094  0.000826  0.001663  0.006799  0.003642   \n",
       "2         img_100.jpg  0.200818  0.249065  0.058669  0.010818  0.004579   \n",
       "3        img_1000.jpg  0.004387  0.002688  0.024336  0.000805  0.002280   \n",
       "4      img_100000.jpg  0.045187  0.001458  0.000840  0.701084  0.199329   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "79721   img_99994.jpg  0.004477  0.186477  0.133851  0.001749  0.000536   \n",
       "79722   img_99995.jpg  0.013295  0.035097  0.000265  0.931134  0.004813   \n",
       "79723   img_99996.jpg  0.000791  0.041994  0.000147  0.846906  0.099453   \n",
       "79724   img_99998.jpg  0.000449  0.085182  0.286448  0.000522  0.000433   \n",
       "79725   img_99999.jpg  0.036727  0.002992  0.000412  0.005636  0.001364   \n",
       "\n",
       "             c5        c6        c7        c8        c9  \n",
       "0      0.600935  0.077657  0.006483  0.026404  0.022482  \n",
       "1      0.941262  0.001846  0.000832  0.017235  0.006800  \n",
       "2      0.048115  0.014242  0.062749  0.039698  0.311247  \n",
       "3      0.009872  0.004561  0.000767  0.943617  0.006687  \n",
       "4      0.022523  0.005878  0.001054  0.016436  0.006211  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "79721  0.011587  0.029475  0.449997  0.096771  0.085079  \n",
       "79722  0.001793  0.002391  0.000746  0.002524  0.007941  \n",
       "79723  0.000325  0.007390  0.000138  0.002115  0.000740  \n",
       "79724  0.000592  0.328923  0.205457  0.084118  0.007875  \n",
       "79725  0.934877  0.000635  0.000332  0.008541  0.008485  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_df = test_filenames.join(test_predictions)\n",
    "test_predictions_df.drop(columns=['class'], inplace=True)\n",
    "test_predictions_df.rename(columns={'filename':'img'}, inplace=True)\n",
    "test_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df.to_csv('C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\test_predictions(VGG16_Transfer_Learning).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = model.predict_proba(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01277273, 0.05188699, 0.06216909, ..., 0.0022028 , 0.07507054,\n",
       "        0.02621848],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.0188447 ,\n",
       "        0.00457516],\n",
       "       [0.50327548, 0.19732263, 0.00961905, ..., 0.        , 0.02691071,\n",
       "        0.22182527],\n",
       "       ...,\n",
       "       [0.00173611, 0.        , 0.        , ..., 0.        , 0.00291667,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.19470271, ..., 0.38539343, 0.19947546,\n",
       "        0.03235011],\n",
       "       [0.        , 0.        , 0.00482759, ..., 0.00206897, 0.0069697 ,\n",
       "        0.01766667]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_predictions = pd.DataFrame(rf_predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_filenames.join(rf_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.drop(columns=['class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.rename(columns={'filename': 'img'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.051887</td>\n",
       "      <td>0.062169</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.075507</td>\n",
       "      <td>0.612750</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.075071</td>\n",
       "      <td>0.026218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.964648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.004575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.503275</td>\n",
       "      <td>0.197323</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>0.221825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.770966</td>\n",
       "      <td>0.143027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957205</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.240912</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.127919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>0.854877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.015068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991806</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.186774</td>\n",
       "      <td>0.385393</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.032350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.955980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.017667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img        c0        c1        c2        c3        c4  \\\n",
       "0           img_1.jpg  0.012773  0.051887  0.062169  0.045604  0.075507   \n",
       "1          img_10.jpg  0.000000  0.000000  0.000000  0.000000  0.011932   \n",
       "2         img_100.jpg  0.503275  0.197323  0.009619  0.003040  0.000000   \n",
       "3        img_1000.jpg  0.000526  0.001600  0.003887  0.003750  0.005671   \n",
       "4      img_100000.jpg  0.006813  0.000000  0.000000  0.957205  0.029316   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "79721   img_99994.jpg  0.028851  0.258388  0.141071  0.000000  0.000000   \n",
       "79722   img_99995.jpg  0.012290  0.010714  0.021952  0.854877  0.000000   \n",
       "79723   img_99996.jpg  0.001736  0.000000  0.000000  0.991806  0.001667   \n",
       "79724   img_99998.jpg  0.000000  0.000000  0.194703  0.000000  0.000000   \n",
       "79725   img_99999.jpg  0.000000  0.000000  0.004828  0.000000  0.012487   \n",
       "\n",
       "             c5        c6        c7        c8        c9  \n",
       "0      0.612750  0.035819  0.002203  0.075071  0.026218  \n",
       "1      0.964648  0.000000  0.000000  0.018845  0.004575  \n",
       "2      0.024722  0.013285  0.000000  0.026911  0.221825  \n",
       "3      0.037143  0.023430  0.010000  0.770966  0.143027  \n",
       "4      0.001250  0.000000  0.000000  0.005417  0.000000  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "79721  0.009987  0.022551  0.240912  0.170321  0.127919  \n",
       "79722  0.039625  0.010625  0.022601  0.012248  0.015068  \n",
       "79723  0.001250  0.000625  0.000000  0.002917  0.000000  \n",
       "79724  0.001304  0.186774  0.385393  0.199475  0.032350  \n",
       "79725  0.955980  0.000000  0.002069  0.006970  0.017667  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\imgs\\\\test\\\\test'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\test_predictions(VGG16_Transfer_Learning_with_RandFor).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.085207</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.600935</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.022482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.941262</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.200818</td>\n",
       "      <td>0.249065</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.062749</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>0.311247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.943617</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.701084</td>\n",
       "      <td>0.199329</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.186477</td>\n",
       "      <td>0.133851</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.029475</td>\n",
       "      <td>0.449997</td>\n",
       "      <td>0.096771</td>\n",
       "      <td>0.085079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>0.035097</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.931134</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.041994</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>0.099453</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.085182</td>\n",
       "      <td>0.286448</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.328923</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>0.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.934877</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img        c0        c1        c2        c3        c4  \\\n",
       "0           img_1.jpg  0.008604  0.085207  0.018095  0.113947  0.040185   \n",
       "1          img_10.jpg  0.019094  0.000826  0.001663  0.006799  0.003642   \n",
       "2         img_100.jpg  0.200818  0.249065  0.058669  0.010818  0.004579   \n",
       "3        img_1000.jpg  0.004387  0.002688  0.024336  0.000805  0.002280   \n",
       "4      img_100000.jpg  0.045187  0.001458  0.000840  0.701084  0.199329   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "79721   img_99994.jpg  0.004477  0.186477  0.133851  0.001749  0.000536   \n",
       "79722   img_99995.jpg  0.013295  0.035097  0.000265  0.931134  0.004813   \n",
       "79723   img_99996.jpg  0.000791  0.041994  0.000147  0.846906  0.099453   \n",
       "79724   img_99998.jpg  0.000449  0.085182  0.286448  0.000522  0.000433   \n",
       "79725   img_99999.jpg  0.036727  0.002992  0.000412  0.005636  0.001364   \n",
       "\n",
       "             c5        c6        c7        c8        c9  \n",
       "0      0.600935  0.077657  0.006483  0.026404  0.022482  \n",
       "1      0.941262  0.001846  0.000832  0.017235  0.006800  \n",
       "2      0.048115  0.014242  0.062749  0.039698  0.311247  \n",
       "3      0.009872  0.004561  0.000767  0.943617  0.006687  \n",
       "4      0.022523  0.005878  0.001054  0.016436  0.006211  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "79721  0.011587  0.029475  0.449997  0.096771  0.085079  \n",
       "79722  0.001793  0.002391  0.000746  0.002524  0.007941  \n",
       "79723  0.000325  0.007390  0.000138  0.002115  0.000740  \n",
       "79724  0.000592  0.328923  0.205457  0.084118  0.007875  \n",
       "79725  0.934877  0.000635  0.000332  0.008541  0.008485  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.051887</td>\n",
       "      <td>0.062169</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.075507</td>\n",
       "      <td>0.612750</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.075071</td>\n",
       "      <td>0.026218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.964648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.004575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.503275</td>\n",
       "      <td>0.197323</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>0.221825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.770966</td>\n",
       "      <td>0.143027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957205</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.240912</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.127919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>0.854877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.015068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991806</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.186774</td>\n",
       "      <td>0.385393</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.032350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.955980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.017667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img        c0        c1        c2        c3        c4  \\\n",
       "0           img_1.jpg  0.012773  0.051887  0.062169  0.045604  0.075507   \n",
       "1          img_10.jpg  0.000000  0.000000  0.000000  0.000000  0.011932   \n",
       "2         img_100.jpg  0.503275  0.197323  0.009619  0.003040  0.000000   \n",
       "3        img_1000.jpg  0.000526  0.001600  0.003887  0.003750  0.005671   \n",
       "4      img_100000.jpg  0.006813  0.000000  0.000000  0.957205  0.029316   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "79721   img_99994.jpg  0.028851  0.258388  0.141071  0.000000  0.000000   \n",
       "79722   img_99995.jpg  0.012290  0.010714  0.021952  0.854877  0.000000   \n",
       "79723   img_99996.jpg  0.001736  0.000000  0.000000  0.991806  0.001667   \n",
       "79724   img_99998.jpg  0.000000  0.000000  0.194703  0.000000  0.000000   \n",
       "79725   img_99999.jpg  0.000000  0.000000  0.004828  0.000000  0.012487   \n",
       "\n",
       "             c5        c6        c7        c8        c9  \n",
       "0      0.612750  0.035819  0.002203  0.075071  0.026218  \n",
       "1      0.964648  0.000000  0.000000  0.018845  0.004575  \n",
       "2      0.024722  0.013285  0.000000  0.026911  0.221825  \n",
       "3      0.037143  0.023430  0.010000  0.770966  0.143027  \n",
       "4      0.001250  0.000000  0.000000  0.005417  0.000000  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "79721  0.009987  0.022551  0.240912  0.170321  0.127919  \n",
       "79722  0.039625  0.010625  0.022601  0.012248  0.015068  \n",
       "79723  0.001250  0.000625  0.000000  0.002917  0.000000  \n",
       "79724  0.001304  0.186774  0.385393  0.199475  0.032350  \n",
       "79725  0.955980  0.000000  0.002069  0.006970  0.017667  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

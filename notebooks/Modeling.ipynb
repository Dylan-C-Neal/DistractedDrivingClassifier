{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Endpoint: <samp>https://notify.run/iQhQYswADagsJ0bd</samp></p>\n",
       "<p>To subscribe, open: <a href=\"https://notify.run/c/iQhQYswADagsJ0bd\">https://notify.run/c/iQhQYswADagsJ0bd</a></p>\n",
       "<p>Or scan this QR code:</p>\n",
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"222\" width=\"222\" class=\"pyqrcode\"><path transform=\"scale(6)\" stroke=\"#000\" class=\"pyqrline\" d=\"M4 4.5h7m3 0h1m3 0h2m6 0h7m-29 1h1m5 0h1m2 0h1m3 0h3m1 0h1m1 0h2m1 0h1m5 0h1m-29 1h1m1 0h3m1 0h1m1 0h1m2 0h1m2 0h3m3 0h1m1 0h1m1 0h3m1 0h1m-29 1h1m1 0h3m1 0h1m2 0h1m2 0h2m1 0h1m2 0h1m3 0h1m1 0h3m1 0h1m-29 1h1m1 0h3m1 0h1m2 0h1m2 0h4m1 0h3m2 0h1m1 0h3m1 0h1m-29 1h1m5 0h1m3 0h3m1 0h2m1 0h1m1 0h2m1 0h1m5 0h1m-29 1h7m1 0h1m1 0h1m1 0h1m1 0h1m1 0h1m1 0h1m1 0h1m1 0h7m-21 1h1m2 0h1m3 0h1m1 0h1m2 0h1m-21 1h3m1 0h5m3 0h1m6 0h4m3 0h1m-27 1h1m1 0h4m1 0h1m1 0h1m1 0h3m3 0h2m2 0h2m2 0h1m2 0h1m-26 1h1m2 0h1m3 0h3m1 0h1m1 0h1m1 0h1m2 0h4m1 0h3m-25 1h1m3 0h3m1 0h3m2 0h2m2 0h4m2 0h1m-28 1h1m1 0h1m2 0h4m1 0h2m2 0h3m3 0h3m2 0h1m1 0h2m-28 1h1m3 0h1m2 0h1m1 0h2m2 0h3m1 0h1m1 0h1m1 0h1m2 0h1m2 0h1m-29 1h4m1 0h3m2 0h1m2 0h1m4 0h1m5 0h2m1 0h2m-29 1h5m2 0h1m3 0h1m5 0h2m1 0h1m4 0h1m1 0h1m-28 1h4m1 0h4m3 0h1m4 0h1m1 0h2m1 0h2m1 0h1m1 0h2m-28 1h1m1 0h1m3 0h1m1 0h5m2 0h3m2 0h2m2 0h2m1 0h1m-29 1h1m1 0h2m1 0h3m1 0h1m1 0h2m1 0h1m2 0h2m1 0h2m1 0h1m3 0h2m-28 1h3m4 0h2m2 0h3m1 0h3m1 0h3m1 0h2m1 0h1m-28 1h1m1 0h2m1 0h4m2 0h1m2 0h1m1 0h2m1 0h6m-17 1h4m2 0h1m1 0h5m3 0h1m1 0h3m-29 1h7m1 0h1m1 0h1m2 0h1m3 0h1m1 0h2m1 0h1m1 0h2m1 0h2m-29 1h1m5 0h1m1 0h4m3 0h1m1 0h2m1 0h1m3 0h2m-26 1h1m1 0h3m1 0h1m1 0h1m1 0h1m1 0h1m3 0h1m3 0h5m2 0h2m-29 1h1m1 0h3m1 0h1m2 0h1m1 0h3m2 0h2m5 0h2m1 0h3m-29 1h1m1 0h3m1 0h1m1 0h1m1 0h3m1 0h1m1 0h1m1 0h4m1 0h3m2 0h1m-29 1h1m5 0h1m1 0h1m3 0h7m1 0h2m1 0h2m2 0h1m-28 1h7m1 0h4m2 0h1m1 0h1m2 0h2m2 0h1m3 0h2\"/></svg>\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "Endpoint: https://notify.run/iQhQYswADagsJ0bd\n",
       "To subscribe, open: https://notify.run/c/iQhQYswADagsJ0bd\n",
       "Or scan this QR code:\n",
       "\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notify_run import Notify\n",
    "notify = Notify()\n",
    "notify.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom functions\n",
    "sys.path.append('C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\functions')\n",
    "from ddfuncs import trainsampling, cvrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Set memory limit on GPU to keep it from freezing up when fitting TensorFlow models later\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 3 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], \\\n",
    "                                                                [tf.config.experimental.\\\n",
    "                                                                 VirtualDeviceConfiguration\\\n",
    "                                                                 (memory_limit=1024 * 3)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed training data\n",
    "os.chdir('../data/processed')\n",
    "df = pd.read_csv('driver_image_list_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainsampling(df, samples=80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "      <th>imgpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_13073.jpg</td>\n",
       "      <td>imgs/train/c0/img_13073.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_5585.jpg</td>\n",
       "      <td>imgs/train/c0/img_5585.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_48187.jpg</td>\n",
       "      <td>imgs/train/c0/img_48187.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_98115.jpg</td>\n",
       "      <td>imgs/train/c0/img_98115.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_66355.jpg</td>\n",
       "      <td>imgs/train/c0/img_66355.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22364</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_95966.jpg</td>\n",
       "      <td>imgs/train/c9/img_95966.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_18412.jpg</td>\n",
       "      <td>imgs/train/c9/img_18412.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22415</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_23818.jpg</td>\n",
       "      <td>imgs/train/c9/img_23818.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22358</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_54961.jpg</td>\n",
       "      <td>imgs/train/c9/img_54961.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22395</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_13314.jpg</td>\n",
       "      <td>imgs/train/c9/img_13314.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject classname            img                      imgpath\n",
       "51       p002        c0  img_13073.jpg  imgs/train/c0/img_13073.jpg\n",
       "14       p002        c0   img_5585.jpg   imgs/train/c0/img_5585.jpg\n",
       "71       p002        c0  img_48187.jpg  imgs/train/c0/img_48187.jpg\n",
       "60       p002        c0  img_98115.jpg  imgs/train/c0/img_98115.jpg\n",
       "20       p002        c0  img_66355.jpg  imgs/train/c0/img_66355.jpg\n",
       "...       ...       ...            ...                          ...\n",
       "22364    p081        c9  img_95966.jpg  imgs/train/c9/img_95966.jpg\n",
       "22404    p081        c9  img_18412.jpg  imgs/train/c9/img_18412.jpg\n",
       "22415    p081        c9  img_23818.jpg  imgs/train/c9/img_23818.jpg\n",
       "22358    p081        c9  img_54961.jpg  imgs/train/c9/img_54961.jpg\n",
       "22395    p081        c9  img_13314.jpg  imgs/train/c9/img_13314.jpg\n",
       "\n",
       "[20800 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to appropriate directory for data generation\n",
    "os.chdir('../raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - 1 Conv, 1 MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6250)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 62,790\n",
      "Trainable params: 62,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))\n",
    "model1.add(MaxPool2D(10))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdgen = ImageDataGenerator(rescale=1./255)\n",
    "tedgen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV iteration 1 of 13\n",
      "Validation subjects are ['p026' 'p050' 'p002']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 115 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 31s 266ms/step - loss: 2.2712 - accuracy: 0.1598 - val_loss: 2.3211 - val_accuracy: 0.1175\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 26s 229ms/step - loss: 2.1409 - accuracy: 0.2522 - val_loss: 2.2922 - val_accuracy: 0.1158\n",
      "Epoch 3/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 1.9539 - accuracy: 0.3865"
     ]
    }
   ],
   "source": [
    "model1data = cvrand(model1,\n",
    "                    df,\n",
    "                    trdgen,\n",
    "                    tedgen,\n",
    "                    n_iterations=13,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=115,\n",
    "                    target_size=(256,256),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1data.to_csv('../metrics/model1metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Add Dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(MaxPool2D(10))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdgen = ImageDataGenerator(rescale=1./255)\n",
    "tedgen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2data = cvrand(model2, \n",
    "                    df,\n",
    "                    trdgen,\n",
    "                    tedgen,\n",
    "                    n_iterations=30,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=125,\n",
    "                    target_size=(256, 256),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2data.to_csv('../metrics/model2metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - Architecture Modeled off AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(99,\n",
    "                 kernel_size=11,\n",
    "                 strides=4,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(227, 227, 3)))\n",
    "model3.add(MaxPool2D(3,\n",
    "                    strides=2,\n",
    "                    padding='valid'))\n",
    "model3.add(Conv2D(256,\n",
    "                 kernel_size=5,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(MaxPool2D(3,\n",
    "                    strides=2,\n",
    "                    padding='valid'))\n",
    "model3.add(Conv2D(384,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(Conv2D(384,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(Conv2D(256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdgen = ImageDataGenerator(rescale=1./255)\n",
    "tedgen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3data = cvrand(model3, \n",
    "                    df,\n",
    "                    trdgen,\n",
    "                    tedgen,\n",
    "                    n_iterations=30,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=125,\n",
    "                    target_size=(227,227),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3data.to_csv('../metrics/model3metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(99,\n",
    "                  kernel_size=11,\n",
    "                  strides=4,\n",
    "                  padding='valid',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPool2D(3,\n",
    "                     strides=2,\n",
    "                     padding='valid'))\n",
    "model4.add(Conv2D(256,\n",
    "                  kernel_size=5,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPool2D(3,\n",
    "                    strides=2,\n",
    "                    padding='valid'))\n",
    "model4.add(Conv2D(384,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(384,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(256,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPool2D(3,\n",
    "                     strides=2,\n",
    "                     padding='valid'))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(4096, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(4096, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.00001)\n",
    "model4.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a batch size of 16 and training set consisting of 18,400 images, performing 50 epochs of 115 steps will mean that the training data is gone over 5 times. Early stopping callback is set to 10, so if the validation accuracy does not improve 10 times in a row then the training will cease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdgen = ImageDataGenerator(rescale=1./255)\n",
    "tedgen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model4data = cvrand(model4, \n",
    "                    df,\n",
    "                    trdgen,\n",
    "                    tedgen,\n",
    "                    n_iterations=13,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=115,\n",
    "                    target_size=(227,227),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4data.to_csv('../metrics/model4metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10,10))\n",
    "_ = plt.xlim(0, 1)\n",
    "_ = plt.ylim(0, 1)\n",
    "_ = sns.scatterplot(data=model4data, x='train_accuracies', y='validation_accuracy')\n",
    "_ = plt.plot([0,1], [0,1])\n",
    "_ = plt.title('Cross Validation Training Accuracies by Validation Accuracies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed pretty well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 with Datagen Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelbuild():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(99,\n",
    "                  kernel_size=11,\n",
    "                  strides=4,\n",
    "                  padding='valid',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                        strides=2,\n",
    "                        padding='valid'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = Adam(learning_rate=0.00001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model5 = modelbuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdgen = ImageDataGenerator(rescale=1./255, samplewise_center=True)\n",
    "tedgen = ImageDataGenerator(rescale=1./255, samplewise_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model5data = cvrand(model5, \n",
    "                    df,\n",
    "                    trdgen,\n",
    "                    tedgen,\n",
    "                    n_iterations=13,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=115,\n",
    "                    target_size=(227,227),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with additional Datagen Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model6 = modelbuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdgen = ImageDataGenerator(samplewise_center=True,\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=10,\n",
    "                            width_shift_range=0.05,\n",
    "                            height_shift_range=0.05,\n",
    "                            brightness_range=[0.8, 1.2])\n",
    "\n",
    "tedgen = ImageDataGenerator(samplewise_center=True,\n",
    "                            rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model6data = cvrand(model6, \n",
    "                    df,\n",
    "                    trdgen,\n",
    "                    tedgen,\n",
    "                    n_iterations=13,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=115,\n",
    "                    target_size=(227,227),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

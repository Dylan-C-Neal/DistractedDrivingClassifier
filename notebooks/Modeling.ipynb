{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from functions import cvmodeleval,samplecv, trainsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training filename dataframe\n",
    "df = pd.read_csv('data/processed/driver_image_list_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeled and unlabeled test filename dataframes\n",
    "df_test_labeled = pd.read_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/processed/labeled_test_df.csv')\n",
    "df_test = pd.read_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/test_filenames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to over/undersample classes occurance by subject so dataset is completely balanced.\n",
    "df = trainsampling(df, samples=80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path variables for data\n",
    "train_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/train'\n",
    "labeled_test_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/testlabeled'\n",
    "unlabeled_test_path = 'D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/raw/imgs/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 subjects were chosen from the training data to be used for validation during model training. These subjects represent one woman and man with dark skin and one woman and man with light skin. This is to help balance any potential racial bias in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of validation subjects\n",
    "val_subjects = ['p056', 'p050', 'p041', 'p016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects)]\n",
    "df_val = df[df['subject'].isin(val_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing and Data-Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataGenerators for training and test/validation data. Generators include randomized preprocessing for \n",
    "# called out parameters. Test_dgen will be used for both validation data and test data.\n",
    "\n",
    "train_dgen = ImageDataGenerator(samplewise_center=True,\n",
    "                                rescale=1./255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                channel_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_dgen = ImageDataGenerator(samplewise_center=True,\n",
    "                               rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 validated image filenames belonging to 10 classes.\n",
      "Found 3200 validated image filenames belonging to 10 classes.\n",
      "Found 200 validated image filenames belonging to 10 classes.\n",
      "Found 79726 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)\n",
    "\n",
    "test_labeled = test_dgen.flow_from_dataframe(df_test_labeled,\n",
    "                                             x_col='filename',\n",
    "                                             y_col='classname',\n",
    "                                             target_size=(227,227),\n",
    "                                             shuffle=False)\n",
    "\n",
    "test = test_dgen.flow_from_dataframe(df_test,\n",
    "                                     x_col='filename',\n",
    "                                     y_col='class',\n",
    "                                     target_size=(227,227),\n",
    "                                     shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1 - AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture below is based off of AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for initializing model\n",
    "def alexNet_arch(opt):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(99,\n",
    "                  kernel_size=11,\n",
    "                  strides=4,\n",
    "                  padding='valid',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                        strides=2,\n",
    "                        padding='valid'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(3,\n",
    "                         strides=2,\n",
    "                         padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer variable\n",
    "opt = RMSprop(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model_1\n",
    "model_1 = alexNet_arch(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model1_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 37s 323ms/step - loss: 6.9370 - accuracy: 0.0918 - val_loss: 2.4704 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 36s 326ms/step - loss: 2.7232 - accuracy: 0.0996 - val_loss: 2.3143 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 35s 320ms/step - loss: 2.4712 - accuracy: 0.1074 - val_loss: 2.3308 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 35s 319ms/step - loss: 2.4106 - accuracy: 0.1175 - val_loss: 2.3382 - val_accuracy: 0.0819\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 34s 312ms/step - loss: 2.3365 - accuracy: 0.1322 - val_loss: 2.2670 - val_accuracy: 0.1278\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 2.2182 - accuracy: 0.1680 - val_loss: 2.1761 - val_accuracy: 0.1900\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 2.1847 - accuracy: 0.1627 - val_loss: 2.0818 - val_accuracy: 0.2309\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 35s 320ms/step - loss: 2.1023 - accuracy: 0.1848 - val_loss: 1.9907 - val_accuracy: 0.2228\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 34s 307ms/step - loss: 2.0495 - accuracy: 0.2408 - val_loss: 1.8269 - val_accuracy: 0.3141\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 1.9844 - accuracy: 0.2580 - val_loss: 1.8713 - val_accuracy: 0.2309\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 1.9225 - accuracy: 0.2545 - val_loss: 2.1298 - val_accuracy: 0.3403\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.8979 - accuracy: 0.2744 - val_loss: 1.8953 - val_accuracy: 0.2503\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.8064 - accuracy: 0.2888 - val_loss: 1.8129 - val_accuracy: 0.4009\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.7552 - accuracy: 0.3207 - val_loss: 2.0009 - val_accuracy: 0.3169\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 1.6673 - accuracy: 0.3460 - val_loss: 2.1884 - val_accuracy: 0.3591\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 1.6882 - accuracy: 0.3380 - val_loss: 1.5826 - val_accuracy: 0.3728\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.6024 - accuracy: 0.3839 - val_loss: 1.7211 - val_accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.6260 - accuracy: 0.3626 - val_loss: 1.6332 - val_accuracy: 0.4556\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 33s 305ms/step - loss: 1.4911 - accuracy: 0.4248 - val_loss: 1.4591 - val_accuracy: 0.4403\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 33s 298ms/step - loss: 1.5116 - accuracy: 0.4450 - val_loss: 1.6147 - val_accuracy: 0.4241\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 1.4967 - accuracy: 0.4111 - val_loss: 2.6076 - val_accuracy: 0.3853\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.5100 - accuracy: 0.4253 - val_loss: 1.6006 - val_accuracy: 0.4572\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 1.3689 - accuracy: 0.4725 - val_loss: 1.5605 - val_accuracy: 0.3922\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 33s 303ms/step - loss: 1.4382 - accuracy: 0.4313 - val_loss: 2.1730 - val_accuracy: 0.4162\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.3154 - accuracy: 0.4958 - val_loss: 1.3790 - val_accuracy: 0.4725\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.2592 - accuracy: 0.5069 - val_loss: 2.0544 - val_accuracy: 0.4209\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 34s 305ms/step - loss: 1.2776 - accuracy: 0.4922 - val_loss: 1.3580 - val_accuracy: 0.5391\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 1.2141 - accuracy: 0.5467 - val_loss: 2.7274 - val_accuracy: 0.4297\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.2181 - accuracy: 0.5566 - val_loss: 1.7309 - val_accuracy: 0.4519\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.1889 - accuracy: 0.5543 - val_loss: 1.9721 - val_accuracy: 0.4659\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 33s 304ms/step - loss: 1.1153 - accuracy: 0.5788 - val_loss: 2.2953 - val_accuracy: 0.5484\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 1.1607 - accuracy: 0.5432 - val_loss: 2.1510 - val_accuracy: 0.4722\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 1.0466 - accuracy: 0.6067 - val_loss: 2.1928 - val_accuracy: 0.5200\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.0721 - accuracy: 0.6115 - val_loss: 3.5886 - val_accuracy: 0.4822\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 1.0939 - accuracy: 0.6083 - val_loss: 1.2664 - val_accuracy: 0.5797\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 1.0112 - accuracy: 0.6376 - val_loss: 3.8568 - val_accuracy: 0.34030111 - ac\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.9635 - accuracy: 0.6643 - val_loss: 1.8653 - val_accuracy: 0.5362- loss: - ETA: 0s - loss: 0.9634 - accuracy: 0.\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.9672 - accuracy: 0.6250 - val_loss: 4.3620 - val_accuracy: 0.5213\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.9016 - accuracy: 0.6907 - val_loss: 1.5191 - val_accuracy: 0.5622\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.9299 - accuracy: 0.6766 - val_loss: 1.8797 - val_accuracy: 0.5406\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.9072 - accuracy: 0.6725 - val_loss: 1.5550 - val_accuracy: 0.5744\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.8576 - accuracy: 0.7003 - val_loss: 1.2470 - val_accuracy: 0.5897\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.7888 - accuracy: 0.7128 - val_loss: 1.7872 - val_accuracy: 0.6278\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.8785 - accuracy: 0.7049 - val_loss: 1.6290 - val_accuracy: 0.6516\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.8114 - accuracy: 0.7252 - val_loss: 1.3758 - val_accuracy: 0.6003\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.8449 - accuracy: 0.7165 - val_loss: 3.1881 - val_accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 32s 286ms/step - loss: 0.7990 - accuracy: 0.7181 - val_loss: 1.2954 - val_accuracy: 0.6356\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7620 - accuracy: 0.7261 - val_loss: 1.0843 - val_accuracy: 0.6575\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7879 - accuracy: 0.7454 - val_loss: 2.5816 - val_accuracy: 0.6044\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.6449 - accuracy: 0.7890 - val_loss: 2.4861 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7814 - accuracy: 0.7390 - val_loss: 3.0154 - val_accuracy: 0.4925\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.7237 - accuracy: 0.7633 - val_loss: 1.8533 - val_accuracy: 0.6072\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.6905 - accuracy: 0.7591 - val_loss: 1.3254 - val_accuracy: 0.6137\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.7218 - accuracy: 0.7610 - val_loss: 3.5828 - val_accuracy: 0.5547\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.7115 - accuracy: 0.7712 - val_loss: 2.0833 - val_accuracy: 0.5666\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6871 - accuracy: 0.7649 - val_loss: 3.9417 - val_accuracy: 0.5825\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.7307 - accuracy: 0.7818 - val_loss: 1.1655 - val_accuracy: 0.6803\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.6096 - accuracy: 0.7805 - val_loss: 1.3496 - val_accuracy: 0.5738\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.6752 - accuracy: 0.7550 - val_loss: 2.7699 - val_accuracy: 0.6125\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 32s 292ms/step - loss: 0.6621 - accuracy: 0.7665 - val_loss: 0.9719 - val_accuracy: 0.6928\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6555 - accuracy: 0.7714 - val_loss: 1.6889 - val_accuracy: 0.6097: 0.6557 - accuracy: 0.\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 32s 287ms/step - loss: 0.6568 - accuracy: 0.7847 - val_loss: 1.0797 - val_accuracy: 0.6553\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 32s 292ms/step - loss: 0.5286 - accuracy: 0.8196 - val_loss: 3.4980 - val_accuracy: 0.5675\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5640 - accuracy: 0.8030 - val_loss: 2.0961 - val_accuracy: 0.6269\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 32s 290ms/step - loss: 0.5747 - accuracy: 0.8205 - val_loss: 1.9404 - val_accuracy: 0.6381\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.6131 - accuracy: 0.8072 - val_loss: 1.0244 - val_accuracy: 0.7038\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 32s 293ms/step - loss: 0.6409 - accuracy: 0.8094 - val_loss: 1.2645 - val_accuracy: 0.7022\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 32s 291ms/step - loss: 0.5321 - accuracy: 0.8291 - val_loss: 1.0098 - val_accuracy: 0.7075\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 32s 295ms/step - loss: 0.5949 - accuracy: 0.8158 - val_loss: 1.5364 - val_accuracy: 0.6219\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 33s 296ms/step - loss: 0.5694 - accuracy: 0.8236 - val_loss: 1.2908 - val_accuracy: 0.6587\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5534 - accuracy: 0.8104 - val_loss: 1.5745 - val_accuracy: 0.6662\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.4999 - accuracy: 0.8354 - val_loss: 6.3533 - val_accuracy: 0.5203\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.5988 - accuracy: 0.8055 - val_loss: 1.9124 - val_accuracy: 0.6078\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 33s 297ms/step - loss: 0.6210 - accuracy: 0.7965 - val_loss: 1.0781 - val_accuracy: 0.6884\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 32s 291ms/step - loss: 0.5594 - accuracy: 0.8237 - val_loss: 1.2082 - val_accuracy: 0.6325\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.4701 - accuracy: 0.8397 - val_loss: 2.0178 - val_accuracy: 0.6169\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 0.5477 - accuracy: 0.8369 - val_loss: 2.1251 - val_accuracy: 0.6300\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.6061 - accuracy: 0.8016 - val_loss: 2.4876 - val_accuracy: 0.6166\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.5179 - accuracy: 0.8301 - val_loss: 1.1209 - val_accuracy: 0.7175\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 32s 288ms/step - loss: 0.5503 - accuracy: 0.8343 - val_loss: 1.2862 - val_accuracy: 0.6447\n",
      "Wall time: 44min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ed51c4400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train model_1\n",
    "model_1.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_1.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to a dataframe with original labeles\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_1_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 10s 105ms/step - loss: 0.9719 - accuracy: 0.6928\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_1_val_metrics = model_1.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_1_val_metrics[0]], \n",
    "                                    'Accuracy':[model_1_val_metrics[1]]})\n",
    "model_1_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_1_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971922</td>\n",
       "      <td>0.692813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0            0.971922  0.692813"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9719 cross-entropy loss and 0.6928 accuracy are not a bad start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Xception Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a method desribed at this url (https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/), I loaded a pre-trained Xception model through keras with weights optimized for imagenet. I made all of the existing layers non-trainable and then added a few trainable layers which will be fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 227, 227, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 113, 113, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 113, 113, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 113, 113, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 111, 111, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 111, 111, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 111, 111, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 111, 111, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 111, 111, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 111, 111, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 111, 111, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 111, 111, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 56, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 56, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 56, 56, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 56, 56, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 56, 56, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 56, 56, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          51380736    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 72,247,346\n",
      "Trainable params: 51,385,866\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_2 = tf.keras.applications.Xception(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_2.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_2 = tf.keras.models.Model(base_model_2.input, x)\n",
    "model_2.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model2_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 71s 647ms/step - loss: 2.8249 - accuracy: 0.1415 - val_loss: 2.1583 - val_accuracy: 0.2169\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 60s 549ms/step - loss: 2.3187 - accuracy: 0.1727 - val_loss: 2.2208 - val_accuracy: 0.2288\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 62s 560ms/step - loss: 2.1792 - accuracy: 0.2364 - val_loss: 2.4904 - val_accuracy: 0.1937\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 60s 548ms/step - loss: 2.1252 - accuracy: 0.2557 - val_loss: 2.3664 - val_accuracy: 0.2147\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 2.0460 - accuracy: 0.3051 - val_loss: 2.4786 - val_accuracy: 0.2256\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 1.9675 - accuracy: 0.3210 - val_loss: 2.5725 - val_accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.9526 - accuracy: 0.3301 - val_loss: 2.5295 - val_accuracy: 0.2122\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.8587 - accuracy: 0.3682 - val_loss: 2.5472 - val_accuracy: 0.2769\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 1.8533 - accuracy: 0.3812 - val_loss: 2.8614 - val_accuracy: 0.2166\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 1.7944 - accuracy: 0.4011 - val_loss: 2.6684 - val_accuracy: 0.2356\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.8344 - accuracy: 0.3812 - val_loss: 3.1513 - val_accuracy: 0.1700\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.7937 - accuracy: 0.3932 - val_loss: 2.8103 - val_accuracy: 0.2384\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.7601 - accuracy: 0.4131 - val_loss: 3.1716 - val_accuracy: 0.2109\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.6830 - accuracy: 0.4295 - val_loss: 3.0304 - val_accuracy: 0.2269\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 1.6815 - accuracy: 0.4347 - val_loss: 3.2372 - val_accuracy: 0.2266\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 1.6595 - accuracy: 0.4472 - val_loss: 3.4794 - val_accuracy: 0.2262\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 1.6560 - accuracy: 0.4392 - val_loss: 3.7069 - val_accuracy: 0.2525\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 1.6152 - accuracy: 0.4466 - val_loss: 3.3362 - val_accuracy: 0.2156\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.5994 - accuracy: 0.4517 - val_loss: 3.3340 - val_accuracy: 0.2119\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 1.5447 - accuracy: 0.4710 - val_loss: 4.2985 - val_accuracy: 0.1969\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.6734 - accuracy: 0.4443 - val_loss: 4.0363 - val_accuracy: 0.2087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ba027de48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_2.predict(val)\n",
    "\n",
    "# Convert to a dataframe with original labels\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_2_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 2.1583 - accuracy: 0.2169\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_2_val_metrics = model_2.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_2_val_metrics[0]], \n",
    "                                    'Accuracy':[model_2_val_metrics[1]]})\n",
    "model_2_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_2_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Entropy Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.15828</td>\n",
       "      <td>0.216875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cross Entropy Loss  Accuracy\n",
       "0             2.15828  0.216875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - VGG16 Transfer-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_3 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_3.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_3 = tf.keras.models.Model(base_model_3.input, x)\n",
    "model_3.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 110 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 63s 569ms/step - loss: 2.5059 - accuracy: 0.1324 - val_loss: 2.1846 - val_accuracy: 0.1606\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 59s 541ms/step - loss: 2.2511 - accuracy: 0.1653 - val_loss: 2.0830 - val_accuracy: 0.2734\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 59s 538ms/step - loss: 2.1532 - accuracy: 0.2284 - val_loss: 1.9477 - val_accuracy: 0.2266\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 59s 535ms/step - loss: 2.1002 - accuracy: 0.2295 - val_loss: 1.8449 - val_accuracy: 0.3663\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 59s 537ms/step - loss: 1.9959 - accuracy: 0.2886 - val_loss: 1.6320 - val_accuracy: 0.5341\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 1.9342 - accuracy: 0.3034 - val_loss: 1.5335 - val_accuracy: 0.6256\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.8685 - accuracy: 0.3528 - val_loss: 1.5222 - val_accuracy: 0.5369\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 58s 525ms/step - loss: 1.7947 - accuracy: 0.3693 - val_loss: 1.3815 - val_accuracy: 0.6181\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.6574 - accuracy: 0.4341 - val_loss: 1.3276 - val_accuracy: 0.6159\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 1.6994 - accuracy: 0.4136 - val_loss: 1.2882 - val_accuracy: 0.6109\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 1.6211 - accuracy: 0.4517 - val_loss: 1.2407 - val_accuracy: 0.5769\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 1.5630 - accuracy: 0.4597 - val_loss: 1.1015 - val_accuracy: 0.7384\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 1.5050 - accuracy: 0.4801 - val_loss: 1.1019 - val_accuracy: 0.6950\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 1.4783 - accuracy: 0.4892 - val_loss: 1.2250 - val_accuracy: 0.5638\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.4343 - accuracy: 0.5261 - val_loss: 1.0464 - val_accuracy: 0.6612\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 1.4105 - accuracy: 0.5102 - val_loss: 0.9985 - val_accuracy: 0.7241\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.3692 - accuracy: 0.5278 - val_loss: 1.0238 - val_accuracy: 0.6775\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 56s 513ms/step - loss: 1.3585 - accuracy: 0.5330 - val_loss: 0.9533 - val_accuracy: 0.7362\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.3233 - accuracy: 0.5449 - val_loss: 1.0242 - val_accuracy: 0.6547\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 1.2883 - accuracy: 0.5665 - val_loss: 0.9397 - val_accuracy: 0.7272\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 1.2685 - accuracy: 0.5767 - val_loss: 0.9362 - val_accuracy: 0.7056\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 56s 509ms/step - loss: 1.2557 - accuracy: 0.5705 - val_loss: 0.8747 - val_accuracy: 0.7334\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 55s 498ms/step - loss: 1.2587 - accuracy: 0.5744 - val_loss: 0.9221 - val_accuracy: 0.7116\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 55s 500ms/step - loss: 1.2557 - accuracy: 0.5778 - val_loss: 0.9435 - val_accuracy: 0.7075\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 55s 502ms/step - loss: 1.1779 - accuracy: 0.6017 - val_loss: 1.0846 - val_accuracy: 0.6075\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 55s 499ms/step - loss: 1.1667 - accuracy: 0.6028 - val_loss: 0.9744 - val_accuracy: 0.6831\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 1.1335 - accuracy: 0.6187 - val_loss: 0.9020 - val_accuracy: 0.7016\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 1.1551 - accuracy: 0.6034 - val_loss: 0.9316 - val_accuracy: 0.6975\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 63s 570ms/step - loss: 1.1354 - accuracy: 0.6193 - val_loss: 0.8170 - val_accuracy: 0.7541\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 58s 530ms/step - loss: 1.0773 - accuracy: 0.6386 - val_loss: 0.7890 - val_accuracy: 0.7556\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0984 - accuracy: 0.6187 - val_loss: 1.0447 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 57s 514ms/step - loss: 1.0777 - accuracy: 0.6403 - val_loss: 0.9368 - val_accuracy: 0.7003\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 58s 523ms/step - loss: 1.0628 - accuracy: 0.6494 - val_loss: 0.8261 - val_accuracy: 0.7578\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 60s 545ms/step - loss: 1.0540 - accuracy: 0.6415 - val_loss: 1.0391 - val_accuracy: 0.6538\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 1.0416 - accuracy: 0.6608 - val_loss: 0.9632 - val_accuracy: 0.6944\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.9996 - accuracy: 0.6591 - val_loss: 0.8432 - val_accuracy: 0.7303\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0333 - accuracy: 0.6602 - val_loss: 0.8632 - val_accuracy: 0.7194\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 1.0168 - accuracy: 0.6597 - val_loss: 0.9146 - val_accuracy: 0.6700\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 58s 531ms/step - loss: 0.9422 - accuracy: 0.6801 - val_loss: 0.9312 - val_accuracy: 0.6928\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.9547 - accuracy: 0.6824 - val_loss: 0.8237 - val_accuracy: 0.7566\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 57s 515ms/step - loss: 0.9504 - accuracy: 0.6801 - val_loss: 0.8506 - val_accuracy: 0.7231\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9649 - accuracy: 0.6722 - val_loss: 0.9130 - val_accuracy: 0.6844\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9749 - accuracy: 0.6756 - val_loss: 0.8606 - val_accuracy: 0.7175\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 57s 516ms/step - loss: 0.9777 - accuracy: 0.6727 - val_loss: 0.8787 - val_accuracy: 0.7169\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 59s 539ms/step - loss: 0.9161 - accuracy: 0.6926 - val_loss: 0.7318 - val_accuracy: 0.7569\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 57s 519ms/step - loss: 0.9721 - accuracy: 0.6699 - val_loss: 0.8721 - val_accuracy: 0.6997\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.9386 - accuracy: 0.6812 - val_loss: 0.8388 - val_accuracy: 0.7153\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.9135 - accuracy: 0.6960 - val_loss: 0.8732 - val_accuracy: 0.6919\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.8933 - accuracy: 0.7006 - val_loss: 0.8399 - val_accuracy: 0.7178\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 57s 522ms/step - loss: 0.9312 - accuracy: 0.6960 - val_loss: 0.8972 - val_accuracy: 0.6975\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.9067 - accuracy: 0.7006 - val_loss: 0.8612 - val_accuracy: 0.7234\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 57s 521ms/step - loss: 0.9091 - accuracy: 0.6898 - val_loss: 0.8654 - val_accuracy: 0.7147\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 57s 518ms/step - loss: 0.8836 - accuracy: 0.6926 - val_loss: 1.0139 - val_accuracy: 0.6822\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 58s 526ms/step - loss: 0.9084 - accuracy: 0.6994 - val_loss: 0.8808 - val_accuracy: 0.6988\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.8851 - accuracy: 0.7000 - val_loss: 0.8380 - val_accuracy: 0.7188\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 58s 528ms/step - loss: 0.8359 - accuracy: 0.7199 - val_loss: 0.9066 - val_accuracy: 0.6913\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 60s 544ms/step - loss: 0.8708 - accuracy: 0.7142 - val_loss: 0.8984 - val_accuracy: 0.6897\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 59s 539ms/step - loss: 0.8583 - accuracy: 0.7125 - val_loss: 0.8167 - val_accuracy: 0.7334\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 0.8788 - accuracy: 0.7142 - val_loss: 0.8421 - val_accuracy: 0.7034\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 60s 547ms/step - loss: 0.8753 - accuracy: 0.7028 - val_loss: 0.8929 - val_accuracy: 0.6784\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 63s 571ms/step - loss: 0.8081 - accuracy: 0.7312 - val_loss: 0.9423 - val_accuracy: 0.6841\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 60s 543ms/step - loss: 0.8400 - accuracy: 0.7193 - val_loss: 0.8140 - val_accuracy: 0.7406\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 58s 527ms/step - loss: 0.8432 - accuracy: 0.7159 - val_loss: 0.7726 - val_accuracy: 0.7328\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 58s 524ms/step - loss: 0.8556 - accuracy: 0.7182 - val_loss: 0.8617 - val_accuracy: 0.6963\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.8331 - accuracy: 0.7295 - val_loss: 0.9490 - val_accuracy: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x204e7f42d08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I renamed the weight file for this first run to model3_weights_first_run.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from first run\n",
    "model_3.load_weights('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model3_weights_first_run.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions of validation data\n",
    "validation_predictions = model_3.predict(val)\n",
    "\n",
    "# Convert to a dataframe with original labels\n",
    "validation_predictions = pd.DataFrame(validation_predictions, \n",
    "                                         columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "validation_predictions = df_val.reset_index(drop=True).join(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions\n",
    "validation_predictions.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/validation_predictions/model_3_validation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 15s 150ms/step - loss: 0.7258 - accuracy: 0.7607\n"
     ]
    }
   ],
   "source": [
    "# Evaluate validation data with best coefficients\n",
    "model_3_val_metrics = model_3.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_val_metrics = pd.DataFrame({'Cross Entropy Loss':[model_3_val_metrics[0]], \n",
    "                                    'Accuracy':[model_3_val_metrics[1]]})\n",
    "model_3_val_metrics.to_csv('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/metrics/model_3_val_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7318361401557922, 0.7568749785423279]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to cross-validate, the same pre-trained VGG16 Model will be trained on 4 additional CV-folds. The predictions from all 4 models will be ensembled together to ideally improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation subjects for upcoming CV-folds.\n",
    "val_subjects_cv2 = ['p002', 'p014', 'p022', 'p042']\n",
    "val_subjects_cv3 = ['p012', 'p015', 'p045', 'p049']\n",
    "val_subjects_cv4 = ['p075', 'p066', 'p064', 'p051']\n",
    "val_subjects_cv5 = ['p052', 'p047', 'p061', 'p035']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd CV Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation datasets\n",
    "df_train = df[~df['subject'].isin(val_subjects_cv2)]\n",
    "df_val = df[df['subject'].isin(val_subjects_cv2)]\n",
    "\n",
    "# Shuffle the dataframes\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_val = df_val.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 validated image filenames belonging to 10 classes.\n",
      "Found 3200 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training, validation, and test data\n",
    "train = train_dgen.flow_from_dataframe(df_train,\n",
    "                                       x_col='imgpath',\n",
    "                                       y_col='classname',\n",
    "                                       batch_size=16, \n",
    "                                       target_size=(227,227),\n",
    "                                       shuffle=True)\n",
    "\n",
    "val = test_dgen.flow_from_dataframe(df_val,\n",
    "                                    x_col='imgpath',\n",
    "                                    y_col='classname',\n",
    "                                    target_size=(227,227),\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_cv2 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(227,227,3))\n",
    "for layer in base_model_cv2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model_cv2.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_cv2 = tf.keras.models.Model(base_model_cv2.input, x)\n",
    "model_cv2.compile(optimizer = RMSprop(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model_cv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate ModelCheckpoint and EarlyStopping callbacks_list\n",
    "checkpoint = ModelCheckpoint('D:/Users/Dylan/Documents/Data Science/Projects/DistractedDrivers/data/weights/model_cv2_weights.hdf5',\n",
    "                              mode='min',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.025, patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 41s 339ms/step - loss: 2.7870 - accuracy: 0.1189 - val_loss: 2.1574 - val_accuracy: 0.2506\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 37s 335ms/step - loss: 2.2966 - accuracy: 0.1594 - val_loss: 2.0629 - val_accuracy: 0.3734\n",
      "Epoch 3/100\n",
      " 51/110 [============>.................] - ETA: 11s - loss: 2.2283 - accuracy: 0.2052- ETA: 16s - loss: 2.2150 - accuracy: 0.221 - ETA: 16s - loss: 2.2159 - acc - ETA: 13s - loss: 2.2234 - accu"
     ]
    }
   ],
   "source": [
    "model_cv2.fit(train,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=110,\n",
    "            validation_data=val,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_output = model_3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df = pd.DataFrame(test_nn_output, \n",
    "                              columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_filenames = os.listdir('D:\\\\Users\\\\Dylan\\\\Documents\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\raw\\\\imgs\\\\test\\\\test')\n",
    "test_filenames = pd.DataFrame({'filename':test_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.851118</td>\n",
       "      <td>0.080587</td>\n",
       "      <td>2.725571e-03</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.003962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.988080</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>4.734514e-05</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.442520</td>\n",
       "      <td>0.191491</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>8.597373e-02</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.227242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>4.882125e-05</td>\n",
       "      <td>0.964899</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.912742</td>\n",
       "      <td>0.070103</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>1.139908e-05</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.038359</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>8.648908e-01</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.035290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.020845</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.960031</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>8.723551e-06</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.955001</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>9.573871e-07</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.303719</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.448532</td>\n",
       "      <td>2.306005e-01</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.874217</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>3.652179e-05</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img        c0        c1        c2        c3        c4  \\\n",
       "0           img_1.jpg  0.001619  0.004821  0.011293  0.027774  0.004447   \n",
       "1          img_10.jpg  0.009783  0.000062  0.000048  0.001064  0.000109   \n",
       "2         img_100.jpg  0.442520  0.191491  0.027255  0.000582  0.000186   \n",
       "3        img_1000.jpg  0.000202  0.000092  0.032745  0.000010  0.000036   \n",
       "4      img_100000.jpg  0.013909  0.000152  0.000098  0.912742  0.070103   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "79721   img_99994.jpg  0.000934  0.038359  0.027704  0.000053  0.000013   \n",
       "79722   img_99995.jpg  0.020845  0.015850  0.000383  0.960031  0.000601   \n",
       "79723   img_99996.jpg  0.000387  0.019609  0.000071  0.955001  0.022456   \n",
       "79724   img_99998.jpg  0.000054  0.005063  0.303719  0.000002  0.000006   \n",
       "79725   img_99999.jpg  0.121082  0.000519  0.000056  0.000894  0.000026   \n",
       "\n",
       "             c5        c6            c7        c8        c9  \n",
       "0      0.851118  0.080587  2.725571e-03  0.011653  0.003962  \n",
       "1      0.988080  0.000144  4.734514e-05  0.000493  0.000171  \n",
       "2      0.003014  0.009266  8.597373e-02  0.012470  0.227242  \n",
       "3      0.000366  0.000595  4.882125e-05  0.964899  0.001007  \n",
       "4      0.000915  0.000669  1.139908e-05  0.001219  0.000180  \n",
       "...         ...       ...           ...       ...       ...  \n",
       "79721  0.004159  0.006234  8.648908e-01  0.022365  0.035290  \n",
       "79722  0.000080  0.000600  8.723551e-06  0.000224  0.001378  \n",
       "79723  0.000004  0.002145  9.573871e-07  0.000252  0.000074  \n",
       "79724  0.000013  0.448532  2.306005e-01  0.011783  0.000227  \n",
       "79725  0.874217  0.000096  3.652179e-05  0.002041  0.001033  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_df = test_filenames.join(test_predictions)\n",
    "test_predictions_df.rename(columns={'filename':'img'}, inplace=True)\n",
    "test_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df.to_csv('D:\\\\Users\\\\Dylan\\\\Documents\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\data\\\\test_predictions(VGG16_Transfer_Learning_2).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

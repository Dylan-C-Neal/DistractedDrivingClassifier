{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Endpoint: <samp>https://notify.run/I1cGWfOCavlbHNC7</samp></p>\n",
       "<p>To subscribe, open: <a href=\"https://notify.run/c/I1cGWfOCavlbHNC7\">https://notify.run/c/I1cGWfOCavlbHNC7</a></p>\n",
       "<p>Or scan this QR code:</p>\n",
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"222\" width=\"222\" class=\"pyqrcode\"><path transform=\"scale(6)\" stroke=\"#000\" class=\"pyqrline\" d=\"M4 4.5h7m2 0h3m1 0h1m2 0h2m2 0h1m1 0h7m-29 1h1m5 0h1m4 0h4m1 0h1m1 0h1m1 0h1m1 0h1m5 0h1m-29 1h1m1 0h3m1 0h1m2 0h3m2 0h1m7 0h1m1 0h3m1 0h1m-29 1h1m1 0h3m1 0h1m1 0h1m1 0h2m2 0h1m1 0h2m1 0h2m1 0h1m1 0h3m1 0h1m-29 1h1m1 0h3m1 0h1m1 0h1m1 0h1m1 0h2m1 0h2m1 0h1m1 0h1m1 0h1m1 0h3m1 0h1m-29 1h1m5 0h1m2 0h2m2 0h2m2 0h2m1 0h1m1 0h1m5 0h1m-29 1h7m1 0h1m1 0h1m1 0h1m1 0h1m1 0h1m1 0h1m1 0h1m1 0h7m-20 1h1m2 0h2m1 0h2m2 0h2m-21 1h2m3 0h3m1 0h2m1 0h1m1 0h1m4 0h1m4 0h2m-26 1h1m2 0h2m5 0h1m3 0h1m3 0h3m2 0h2m1 0h2m-26 1h1m3 0h2m1 0h1m1 0h2m2 0h1m1 0h1m2 0h1m2 0h2m-25 1h2m2 0h2m4 0h2m2 0h1m4 0h1m2 0h1m2 0h1m-26 1h2m2 0h1m1 0h1m2 0h2m2 0h2m1 0h2m1 0h2m1 0h2m4 0h1m-29 1h4m3 0h4m1 0h3m1 0h1m2 0h6m2 0h2m-29 1h2m4 0h2m1 0h1m3 0h3m1 0h1m2 0h3m1 0h3m-27 1h2m3 0h1m1 0h1m1 0h1m2 0h5m2 0h1m1 0h4m1 0h1m1 0h1m-29 1h3m1 0h1m1 0h5m1 0h1m1 0h2m1 0h1m1 0h1m1 0h1m1 0h1m1 0h2m-27 1h1m1 0h4m1 0h1m1 0h1m5 0h2m1 0h2m2 0h3m1 0h3m-29 1h2m2 0h3m3 0h1m1 0h5m2 0h2m4 0h1m2 0h1m-29 1h1m1 0h3m5 0h2m2 0h1m1 0h1m1 0h3m1 0h2m-24 1h1m2 0h1m2 0h1m4 0h1m7 0h6m1 0h3m-21 1h2m2 0h2m1 0h1m1 0h2m1 0h1m3 0h2m-26 1h7m1 0h1m4 0h3m1 0h1m1 0h2m1 0h1m1 0h3m-27 1h1m5 0h1m1 0h1m3 0h2m1 0h2m2 0h2m3 0h1m2 0h1m-28 1h1m1 0h3m1 0h1m3 0h4m1 0h1m1 0h1m1 0h7m2 0h1m-29 1h1m1 0h3m1 0h1m2 0h1m5 0h2m1 0h2m1 0h1m3 0h2m1 0h1m-29 1h1m1 0h3m1 0h1m2 0h1m1 0h2m2 0h5m2 0h6m-28 1h1m5 0h1m1 0h2m1 0h1m4 0h1m2 0h1m2 0h1m2 0h2m1 0h1m-29 1h7m1 0h4m3 0h1m1 0h1m1 0h1m1 0h3m2 0h1\"/></svg>\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "Endpoint: https://notify.run/I1cGWfOCavlbHNC7\n",
       "To subscribe, open: https://notify.run/c/I1cGWfOCavlbHNC7\n",
       "Or scan this QR code:\n",
       "\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[49m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\u001b[7m  \u001b[0m\n",
       "\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notify_run import Notify\n",
    "notify = Notify()\n",
    "notify.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom functions\n",
    "sys.path.append('C:\\\\Users\\\\Dylan\\\\Desktop\\\\Data Science\\\\Projects\\\\DistractedDrivers\\\\functions')\n",
    "from ddfuncs import trainsampling, cvrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Set memory limit on GPU to keep it from freezing up when fitting TensorFlow models later\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 3 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], \\\n",
    "                                                                [tf.config.experimental.\\\n",
    "                                                                 VirtualDeviceConfiguration\\\n",
    "                                                                 (memory_limit=1024 * 3)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed training data\n",
    "os.chdir('../data/processed')\n",
    "df = pd.read_csv('driver_image_list_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainsampling(df, samples=80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "      <th>imgpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_13073.jpg</td>\n",
       "      <td>imgs/train/c0/img_13073.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_5585.jpg</td>\n",
       "      <td>imgs/train/c0/img_5585.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_48187.jpg</td>\n",
       "      <td>imgs/train/c0/img_48187.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_98115.jpg</td>\n",
       "      <td>imgs/train/c0/img_98115.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_66355.jpg</td>\n",
       "      <td>imgs/train/c0/img_66355.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22364</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_95966.jpg</td>\n",
       "      <td>imgs/train/c9/img_95966.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_18412.jpg</td>\n",
       "      <td>imgs/train/c9/img_18412.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22415</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_23818.jpg</td>\n",
       "      <td>imgs/train/c9/img_23818.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22358</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_54961.jpg</td>\n",
       "      <td>imgs/train/c9/img_54961.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22395</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_13314.jpg</td>\n",
       "      <td>imgs/train/c9/img_13314.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject classname            img                      imgpath\n",
       "51       p002        c0  img_13073.jpg  imgs/train/c0/img_13073.jpg\n",
       "14       p002        c0   img_5585.jpg   imgs/train/c0/img_5585.jpg\n",
       "71       p002        c0  img_48187.jpg  imgs/train/c0/img_48187.jpg\n",
       "60       p002        c0  img_98115.jpg  imgs/train/c0/img_98115.jpg\n",
       "20       p002        c0  img_66355.jpg  imgs/train/c0/img_66355.jpg\n",
       "...       ...       ...            ...                          ...\n",
       "22364    p081        c9  img_95966.jpg  imgs/train/c9/img_95966.jpg\n",
       "22404    p081        c9  img_18412.jpg  imgs/train/c9/img_18412.jpg\n",
       "22415    p081        c9  img_23818.jpg  imgs/train/c9/img_23818.jpg\n",
       "22358    p081        c9  img_54961.jpg  imgs/train/c9/img_54961.jpg\n",
       "22395    p081        c9  img_13314.jpg  imgs/train/c9/img_13314.jpg\n",
       "\n",
       "[20800 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to appropriate directory for data generation\n",
    "os.chdir('../raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - 1 Conv, 1 MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6250)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 62,790\n",
      "Trainable params: 62,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))\n",
    "model1.add(MaxPool2D(10))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV iteration 1 of 13\n",
      "Validation subjects are ['p026' 'p050' 'p002']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 115 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 30s 262ms/step - loss: 63.9846 - accuracy: 0.1495 - val_loss: 57.7408 - val_accuracy: 0.1050\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 30s 260ms/step - loss: 27.8950 - accuracy: 0.2772 - val_loss: 45.9950 - val_accuracy: 0.1550\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 32s 278ms/step - loss: 18.5662 - accuracy: 0.3696 - val_loss: 44.0138 - val_accuracy: 0.1650\n",
      "Epoch 4/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 13.3103 - accuracy: 0.4819"
     ]
    }
   ],
   "source": [
    "model1data = cvrand(model1, \n",
    "                    df,\n",
    "                    n_iterations=13,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=115,\n",
    "                    target_size=(256,256),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1data.to_csv('../metrics/model1metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Add Dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(10, kernel_size=3, activation='relu', input_shape=(256, 256, 3)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(MaxPool2D(10))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2data = cvrand(model2, \n",
    "                    df,\n",
    "                    n_iterations=30,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=125,\n",
    "                    target_size=(256, 256),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2data.to_csv('../metrics/model2metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - Architecture Modeled off AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(99,\n",
    "                 kernel_size=11,\n",
    "                 strides=4,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(227, 227, 3)))\n",
    "model3.add(MaxPool2D(3,\n",
    "                    strides=2,\n",
    "                    padding='valid'))\n",
    "model3.add(Conv2D(256,\n",
    "                 kernel_size=5,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(MaxPool2D(3,\n",
    "                    strides=2,\n",
    "                    padding='valid'))\n",
    "model3.add(Conv2D(384,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(Conv2D(384,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(Conv2D(256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3data = cvrand(model3, \n",
    "                    df,\n",
    "                    n_iterations=30,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=125,\n",
    "                    target_size=(227,227),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3data.to_csv('../metrics/model3metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "notify.send('model 3 cv complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 55, 55, 99)        36036     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 55, 55, 99)        396       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 55, 55, 99)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 27, 27, 99)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 27, 27, 256)       633856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 58,348,122\n",
      "Trainable params: 58,345,364\n",
      "Non-trainable params: 2,758\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(99,\n",
    "                  kernel_size=11,\n",
    "                  strides=4,\n",
    "                  padding='valid',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPool2D(3,\n",
    "                     strides=2,\n",
    "                     padding='valid'))\n",
    "model4.add(Conv2D(256,\n",
    "                  kernel_size=5,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPool2D(3,\n",
    "                    strides=2,\n",
    "                    padding='valid'))\n",
    "model4.add(Conv2D(384,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(384,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(256,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPool2D(3,\n",
    "                     strides=2,\n",
    "                     padding='valid'))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(4096, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(4096, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.00005)\n",
    "model4.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a batch size of 16 and training set consisting of 20,000 images, performing 50 epochs of 125 steps will mean that the training data is gone over 5 times. Early stopping callback is set to 10, so if the validation accuracy does not improve 10 times in a row then the training will cease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV iteration 1 of 30\n",
      "Validation subjects are ['p026' 'p050' 'p002']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 3.4584 - accuracy: 0.1540 - val_loss: 2.7696 - val_accuracy: 0.1404\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 29s 235ms/step - loss: 2.0438 - accuracy: 0.2985 - val_loss: 2.2866 - val_accuracy: 0.1971\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 30s 241ms/step - loss: 1.6327 - accuracy: 0.4220 - val_loss: 2.3050 - val_accuracy: 0.2646\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 1.3364 - accuracy: 0.5135 - val_loss: 2.5752 - val_accuracy: 0.2296\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 1.0647 - accuracy: 0.6085 - val_loss: 3.0852 - val_accuracy: 0.2129\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.8743 - accuracy: 0.6995 - val_loss: 2.1564 - val_accuracy: 0.3654\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.6626 - accuracy: 0.7785 - val_loss: 2.4172 - val_accuracy: 0.2996\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 0.6084 - accuracy: 0.7985 - val_loss: 2.2496 - val_accuracy: 0.3550\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.3953 - accuracy: 0.8755 - val_loss: 2.3718 - val_accuracy: 0.4158\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 0.3685 - accuracy: 0.8780 - val_loss: 2.3498 - val_accuracy: 0.3742\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.2850 - accuracy: 0.9055 - val_loss: 1.8370 - val_accuracy: 0.4446\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 29s 236ms/step - loss: 0.2494 - accuracy: 0.9205 - val_loss: 2.2360 - val_accuracy: 0.4617 - accuracy - ETA: 0s - loss: 0.2463 - accuracy: 0. - ETA: 0s - loss: 0.2519 - accuracy\n",
      "CV iteration 2 of 30\n",
      "Validation subjects are ['p049' 'p039' 'p035']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.4728 - accuracy: 0.1185 - val_loss: 2.5984 - val_accuracy: 0.1475\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 2.0950 - accuracy: 0.2335 - val_loss: 1.8382 - val_accuracy: 0.2946\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.8164 - accuracy: 0.3425 - val_loss: 1.5423 - val_accuracy: 0.4054\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.6193 - accuracy: 0.4000 - val_loss: 1.4806 - val_accuracy: 0.4121\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.3535 - accuracy: 0.4935 - val_loss: 1.3730 - val_accuracy: 0.4608\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.1709 - accuracy: 0.5495 - val_loss: 1.4156 - val_accuracy: 0.4504\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 1.0180 - accuracy: 0.6245 - val_loss: 1.8449 - val_accuracy: 0.4433\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.8474 - accuracy: 0.6810 - val_loss: 1.5762 - val_accuracy: 0.5437\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 30s 236ms/step - loss: 0.6822 - accuracy: 0.7600 - val_loss: 1.1278 - val_accuracy: 0.5867\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.6027 - accuracy: 0.7955 - val_loss: 0.9320 - val_accuracy: 0.5838\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4693 - accuracy: 0.8375 - val_loss: 2.0279 - val_accuracy: 0.4471\n",
      "CV iteration 3 of 30\n",
      "Validation subjects are ['p066' 'p050' 'p075']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.2345 - accuracy: 0.1175 - val_loss: 2.3626 - val_accuracy: 0.1254\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 2.0983 - accuracy: 0.2455 - val_loss: 2.3434 - val_accuracy: 0.1450\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.7780 - accuracy: 0.3385 - val_loss: 2.5350 - val_accuracy: 0.1558\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.5430 - accuracy: 0.4055 - val_loss: 2.9369 - val_accuracy: 0.2225\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.3212 - accuracy: 0.5130 - val_loss: 2.5801 - val_accuracy: 0.3117\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.0916 - accuracy: 0.5865 - val_loss: 2.5298 - val_accuracy: 0.3154\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.9095 - accuracy: 0.6565 - val_loss: 3.0225 - val_accuracy: 0.3692\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.7314 - accuracy: 0.7395 - val_loss: 3.2470 - val_accuracy: 0.3363\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.6199 - accuracy: 0.7710 - val_loss: 2.8729 - val_accuracy: 0.3708\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.5423 - accuracy: 0.8025 - val_loss: 3.7657 - val_accuracy: 0.3004\n",
      "CV iteration 4 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.4173 - accuracy: 0.1010 - val_loss: 2.4016 - val_accuracy: 0.2250\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.3188 - accuracy: 0.1180 - val_loss: 2.1786 - val_accuracy: 0.2296\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.1567 - accuracy: 0.2110 - val_loss: 1.9542 - val_accuracy: 0.3392\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.8614 - accuracy: 0.2915 - val_loss: 1.9042 - val_accuracy: 0.2488\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.6411 - accuracy: 0.3725 - val_loss: 1.7383 - val_accuracy: 0.3892\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.3712 - accuracy: 0.4690 - val_loss: 1.8915 - val_accuracy: 0.3762\n",
      "CV iteration 5 of 30\n",
      "Validation subjects are ['p041' 'p016' 'p026']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.3606 - accuracy: 0.1190 - val_loss: 2.3726 - val_accuracy: 0.1004\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.1919 - accuracy: 0.1955 - val_loss: 2.0425 - val_accuracy: 0.2108\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 25s 198ms/step - loss: 1.8857 - accuracy: 0.2995 - val_loss: 1.6817 - val_accuracy: 0.3504\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.6465 - accuracy: 0.3780 - val_loss: 1.7345 - val_accuracy: 0.3050\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 1.4374 - accuracy: 0.4470 - val_loss: 1.4095 - val_accuracy: 0.4313\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.2155 - accuracy: 0.5395 - val_loss: 1.0868 - val_accuracy: 0.5808\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.1026 - accuracy: 0.5720 - val_loss: 1.5165 - val_accuracy: 0.4308\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.8997 - accuracy: 0.6480 - val_loss: 1.4380 - val_accuracy: 0.4683\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.7929 - accuracy: 0.7165 - val_loss: 1.5220 - val_accuracy: 0.5204\n",
      "CV iteration 6 of 30\n",
      "Validation subjects are ['p045' 'p035' 'p049']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.3450 - accuracy: 0.1080 - val_loss: 2.4186 - val_accuracy: 0.1663\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.2813 - accuracy: 0.1575 - val_loss: 2.0612 - val_accuracy: 0.2862\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 2.0312 - accuracy: 0.2535 - val_loss: 1.7427 - val_accuracy: 0.4096\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 1.8321 - accuracy: 0.3020 - val_loss: 1.5242 - val_accuracy: 0.4917\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.5728 - accuracy: 0.3940 - val_loss: 1.3605 - val_accuracy: 0.4963\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.2956 - accuracy: 0.4980 - val_loss: 1.2740 - val_accuracy: 0.4717\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.1450 - accuracy: 0.5710 - val_loss: 1.2387 - val_accuracy: 0.4963\n",
      "CV iteration 7 of 30\n",
      "Validation subjects are ['p064' 'p021' 'p022']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 4.3664 - accuracy: 0.1150 - val_loss: 2.6368 - val_accuracy: 0.1029\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 2.1204 - accuracy: 0.2295 - val_loss: 1.9833 - val_accuracy: 0.2104\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.8795 - accuracy: 0.2950 - val_loss: 1.9138 - val_accuracy: 0.2250\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.5984 - accuracy: 0.4035 - val_loss: 1.7901 - val_accuracy: 0.2933\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.3438 - accuracy: 0.4935 - val_loss: 1.5287 - val_accuracy: 0.3858\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.1696 - accuracy: 0.5550 - val_loss: 1.2420 - val_accuracy: 0.5425\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.9952 - accuracy: 0.6130 - val_loss: 1.1498 - val_accuracy: 0.5258\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.8284 - accuracy: 0.6960 - val_loss: 1.3787 - val_accuracy: 0.5117\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.6680 - accuracy: 0.7610 - val_loss: 2.0663 - val_accuracy: 0.3133\n",
      "CV iteration 8 of 30\n",
      "Validation subjects are ['p045' 'p035' 'p049']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.3951 - accuracy: 0.1225 - val_loss: 2.3130 - val_accuracy: 0.2521\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 2.1953 - accuracy: 0.2010 - val_loss: 1.7895 - val_accuracy: 0.3546\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.9271 - accuracy: 0.2900 - val_loss: 1.4789 - val_accuracy: 0.4542\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.6686 - accuracy: 0.3850 - val_loss: 1.3714 - val_accuracy: 0.4846\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 1.4326 - accuracy: 0.4705 - val_loss: 1.3504 - val_accuracy: 0.4696\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.2650 - accuracy: 0.5260 - val_loss: 1.4793 - val_accuracy: 0.4363\n",
      "CV iteration 9 of 30\n",
      "Validation subjects are ['p041' 'p016' 'p026']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.2762 - accuracy: 0.1305 - val_loss: 2.3906 - val_accuracy: 0.1008\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.2331 - accuracy: 0.1750 - val_loss: 2.0031 - val_accuracy: 0.4462\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.9542 - accuracy: 0.2765 - val_loss: 1.7557 - val_accuracy: 0.4142\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.7329 - accuracy: 0.3565 - val_loss: 1.5461 - val_accuracy: 0.4717\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.4858 - accuracy: 0.4280 - val_loss: 1.6260 - val_accuracy: 0.3812\n",
      "CV iteration 10 of 30\n",
      "Validation subjects are ['p045' 'p056' 'p022']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.2745 - accuracy: 0.1125 - val_loss: 2.3406 - val_accuracy: 0.1083\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 2.1963 - accuracy: 0.1940 - val_loss: 2.0683 - val_accuracy: 0.2313\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.8976 - accuracy: 0.3015 - val_loss: 2.0757 - val_accuracy: 0.2837\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.6639 - accuracy: 0.3535 - val_loss: 2.1523 - val_accuracy: 0.3571\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.4053 - accuracy: 0.4630 - val_loss: 2.4622 - val_accuracy: 0.3546\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.2152 - accuracy: 0.5500 - val_loss: 2.1104 - val_accuracy: 0.3817\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 1.0577 - accuracy: 0.6175 - val_loss: 1.4799 - val_accuracy: 0.5308\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.8478 - accuracy: 0.6905 - val_loss: 1.5982 - val_accuracy: 0.5304\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 38s 303ms/step - loss: 0.7710 - accuracy: 0.7180 - val_loss: 1.7612 - val_accuracy: 0.5133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "125/125 [==============================] - 39s 312ms/step - loss: 0.6172 - accuracy: 0.7815 - val_loss: 1.0920 - val_accuracy: 0.6075\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.4949 - accuracy: 0.8175 - val_loss: 1.2041 - val_accuracy: 0.5846\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 30s 236ms/step - loss: 0.4351 - accuracy: 0.8500 - val_loss: 1.0028 - val_accuracy: 0.6571\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.3619 - accuracy: 0.8705 - val_loss: 1.2574 - val_accuracy: 0.6233\n",
      "CV iteration 11 of 30\n",
      "Validation subjects are ['p042' 'p075' 'p041']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.4049 - accuracy: 0.1135 - val_loss: 2.3616 - val_accuracy: 0.1592\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.2099 - accuracy: 0.1920 - val_loss: 1.9509 - val_accuracy: 0.2600\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.8909 - accuracy: 0.2995 - val_loss: 1.7016 - val_accuracy: 0.4354\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.6680 - accuracy: 0.3840 - val_loss: 1.8597 - val_accuracy: 0.3550\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.4181 - accuracy: 0.4715 - val_loss: 1.8677 - val_accuracy: 0.4008\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.2552 - accuracy: 0.5105 - val_loss: 1.7338 - val_accuracy: 0.4171\n",
      "CV iteration 12 of 30\n",
      "Validation subjects are ['p041' 'p016' 'p026']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 4.4921 - accuracy: 0.1330 - val_loss: 2.4136 - val_accuracy: 0.1225\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.1583 - accuracy: 0.2200 - val_loss: 1.8229 - val_accuracy: 0.3471\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.9089 - accuracy: 0.3010 - val_loss: 1.6045 - val_accuracy: 0.4521\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.6640 - accuracy: 0.3825 - val_loss: 1.5638 - val_accuracy: 0.4013\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.4037 - accuracy: 0.4720 - val_loss: 1.2737 - val_accuracy: 0.5088\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.2089 - accuracy: 0.5390 - val_loss: 1.2464 - val_accuracy: 0.5779\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.0186 - accuracy: 0.6210 - val_loss: 1.0423 - val_accuracy: 0.6146\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 29s 235ms/step - loss: 0.9070 - accuracy: 0.6615 - val_loss: 0.8430 - val_accuracy: 0.6913\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.7177 - accuracy: 0.7380 - val_loss: 2.1993 - val_accuracy: 0.5288\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.6286 - accuracy: 0.7845 - val_loss: 1.0339 - val_accuracy: 0.6471\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.5148 - accuracy: 0.8240 - val_loss: 0.8557 - val_accuracy: 0.6971s - loss: 0.5199 \n",
      "CV iteration 13 of 30\n",
      "Validation subjects are ['p066' 'p050' 'p075']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 4.3057 - accuracy: 0.1185 - val_loss: 2.8574 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.1430 - accuracy: 0.2075 - val_loss: 2.3605 - val_accuracy: 0.1546\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.8098 - accuracy: 0.3235 - val_loss: 2.7071 - val_accuracy: 0.0988 - accuracy: \n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.5488 - accuracy: 0.3885 - val_loss: 2.9503 - val_accuracy: 0.1462\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.2952 - accuracy: 0.4985 - val_loss: 2.9611 - val_accuracy: 0.2396\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.1387 - accuracy: 0.5540 - val_loss: 2.2731 - val_accuracy: 0.3254\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.9354 - accuracy: 0.6390 - val_loss: 2.5411 - val_accuracy: 0.2962\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.8553 - accuracy: 0.6755 - val_loss: 2.4940 - val_accuracy: 0.3358\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.6363 - accuracy: 0.7755 - val_loss: 2.4908 - val_accuracy: 0.3817\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.5812 - accuracy: 0.7920 - val_loss: 2.6698 - val_accuracy: 0.4033\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.4020 - accuracy: 0.8540 - val_loss: 3.0120 - val_accuracy: 0.4058\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.4023 - accuracy: 0.8495 - val_loss: 2.9742 - val_accuracy: 0.4050\n",
      "CV iteration 14 of 30\n",
      "Validation subjects are ['p049' 'p039' 'p035']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.2968 - accuracy: 0.1200 - val_loss: 2.3481 - val_accuracy: 0.1533\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 2.2387 - accuracy: 0.1780 - val_loss: 2.0481 - val_accuracy: 0.2267\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.9849 - accuracy: 0.2730 - val_loss: 1.8368 - val_accuracy: 0.3433\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.7847 - accuracy: 0.3170 - val_loss: 1.6552 - val_accuracy: 0.3167\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.5159 - accuracy: 0.4185 - val_loss: 1.4890 - val_accuracy: 0.4367\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 1.2916 - accuracy: 0.5035 - val_loss: 1.4593 - val_accuracy: 0.3900\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.1266 - accuracy: 0.5795 - val_loss: 1.5691 - val_accuracy: 0.4579\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.0323 - accuracy: 0.6160 - val_loss: 1.9396 - val_accuracy: 0.4458\n",
      "CV iteration 15 of 30\n",
      "Validation subjects are ['p012' 'p035' 'p002']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.5329 - accuracy: 0.1330 - val_loss: 2.5986 - val_accuracy: 0.1854\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 25s 199ms/step - loss: 2.0665 - accuracy: 0.2485 - val_loss: 2.1033 - val_accuracy: 0.2308\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.7324 - accuracy: 0.3525 - val_loss: 2.2240 - val_accuracy: 0.1583\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.4887 - accuracy: 0.4490 - val_loss: 2.1699 - val_accuracy: 0.2833\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.2947 - accuracy: 0.4980 - val_loss: 2.2654 - val_accuracy: 0.2754\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.1375 - accuracy: 0.5730 - val_loss: 2.7998 - val_accuracy: 0.2592\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.9455 - accuracy: 0.6415 - val_loss: 3.1005 - val_accuracy: 0.2796\n",
      "CV iteration 16 of 30\n",
      "Validation subjects are ['p064' 'p021' 'p022']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 4.4059 - accuracy: 0.1150 - val_loss: 2.6872 - val_accuracy: 0.0933\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 2.1667 - accuracy: 0.2085 - val_loss: 2.0300 - val_accuracy: 0.2721\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 1.8931 - accuracy: 0.3110 - val_loss: 1.8563 - val_accuracy: 0.3096\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 1.6489 - accuracy: 0.3735 - val_loss: 1.8764 - val_accuracy: 0.2854\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 1.4232 - accuracy: 0.4775 - val_loss: 1.8067 - val_accuracy: 0.3258\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 1.2196 - accuracy: 0.5415 - val_loss: 1.4278 - val_accuracy: 0.4283\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.0815 - accuracy: 0.5865 - val_loss: 1.1752 - val_accuracy: 0.5467\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.9012 - accuracy: 0.6720 - val_loss: 1.2947 - val_accuracy: 0.5450\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.7188 - accuracy: 0.7435 - val_loss: 1.1645 - val_accuracy: 0.5683\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.5818 - accuracy: 0.7960 - val_loss: 1.0865 - val_accuracy: 0.5867\n",
      "CV iteration 17 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.3924 - accuracy: 0.1130 - val_loss: 2.3869 - val_accuracy: 0.1046\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 2.2143 - accuracy: 0.1930 - val_loss: 2.0104 - val_accuracy: 0.2188\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.9445 - accuracy: 0.2880 - val_loss: 1.9384 - val_accuracy: 0.2717\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.6920 - accuracy: 0.3665 - val_loss: 1.8362 - val_accuracy: 0.2488\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.4113 - accuracy: 0.4630 - val_loss: 2.0143 - val_accuracy: 0.3746\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.2402 - accuracy: 0.5070 - val_loss: 2.1270 - val_accuracy: 0.3908\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.0759 - accuracy: 0.5865 - val_loss: 3.0774 - val_accuracy: 0.4842\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.9588 - accuracy: 0.6360 - val_loss: 2.2805 - val_accuracy: 0.3963\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.8260 - accuracy: 0.6800 - val_loss: 3.6050 - val_accuracy: 0.5121\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.7037 - accuracy: 0.7505 - val_loss: 3.2809 - val_accuracy: 0.4079\n",
      "CV iteration 18 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.1924 - accuracy: 0.1180 - val_loss: 2.4033 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 2.2814 - accuracy: 0.1520 - val_loss: 2.1053 - val_accuracy: 0.2717\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.9698 - accuracy: 0.2865 - val_loss: 1.9340 - val_accuracy: 0.3242\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.7191 - accuracy: 0.3590 - val_loss: 2.0549 - val_accuracy: 0.3233\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.4681 - accuracy: 0.4285 - val_loss: 1.8115 - val_accuracy: 0.3567\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.2666 - accuracy: 0.5165 - val_loss: 1.8430 - val_accuracy: 0.3579\n",
      "CV iteration 19 of 30\n",
      "Validation subjects are ['p041' 'p016' 'p026']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 4.4532 - accuracy: 0.1210 - val_loss: 2.3847 - val_accuracy: 0.1258\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 2.2561 - accuracy: 0.1625 - val_loss: 2.1257 - val_accuracy: 0.2350\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 2.0103 - accuracy: 0.2560 - val_loss: 1.8922 - val_accuracy: 0.2329\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.8117 - accuracy: 0.3190 - val_loss: 1.7806 - val_accuracy: 0.2883\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.5511 - accuracy: 0.4135 - val_loss: 1.4865 - val_accuracy: 0.4046\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.3615 - accuracy: 0.4705 - val_loss: 1.2069 - val_accuracy: 0.5725\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.2098 - accuracy: 0.5375 - val_loss: 1.1977 - val_accuracy: 0.5442\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.0149 - accuracy: 0.6070 - val_loss: 1.1808 - val_accuracy: 0.5346\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.8269 - accuracy: 0.6935 - val_loss: 1.1643 - val_accuracy: 0.5792\n",
      "CV iteration 20 of 30\n",
      "Validation subjects are ['p045' 'p035' 'p049']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 4.2849 - accuracy: 0.1220 - val_loss: 2.1958 - val_accuracy: 0.2017\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 25s 196ms/step - loss: 2.1976 - accuracy: 0.1960 - val_loss: 1.7648 - val_accuracy: 0.3900\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 1.9406 - accuracy: 0.2815 - val_loss: 1.4440 - val_accuracy: 0.4567\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 1.6532 - accuracy: 0.3805 - val_loss: 1.3762 - val_accuracy: 0.4604\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 1.3557 - accuracy: 0.4890 - val_loss: 1.1960 - val_accuracy: 0.5067\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 1.1736 - accuracy: 0.5360 - val_loss: 1.1477 - val_accuracy: 0.5592\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1.0156 - accuracy: 0.6110 - val_loss: 1.3255 - val_accuracy: 0.5688\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.9258 - accuracy: 0.6485 - val_loss: 1.1305 - val_accuracy: 0.6304\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.7723 - accuracy: 0.7180 - val_loss: 1.0578 - val_accuracy: 0.6762\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.6015 - accuracy: 0.7780 - val_loss: 1.2447 - val_accuracy: 0.5892\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.5278 - accuracy: 0.8115 - val_loss: 1.5510 - val_accuracy: 0.5558\n",
      "CV iteration 21 of 30\n",
      "Validation subjects are ['p066' 'p050' 'p075']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 4.4389 - accuracy: 0.1195 - val_loss: 2.3785 - val_accuracy: 0.1108\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 2.1142 - accuracy: 0.2310 - val_loss: 2.4232 - val_accuracy: 0.1267\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.7896 - accuracy: 0.3210 - val_loss: 2.9436 - val_accuracy: 0.1600\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.5481 - accuracy: 0.4025 - val_loss: 3.1611 - val_accuracy: 0.2250\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.3361 - accuracy: 0.4855 - val_loss: 3.2668 - val_accuracy: 0.2358\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.1368 - accuracy: 0.5640 - val_loss: 3.2685 - val_accuracy: 0.3262\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.9718 - accuracy: 0.6430 - val_loss: 3.8265 - val_accuracy: 0.2817s - loss: 1 - ETA: 1s - loss:\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.8201 - accuracy: 0.7050 - val_loss: 3.7723 - val_accuracy: 0.2883\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.6804 - accuracy: 0.7505 - val_loss: 4.3190 - val_accuracy: 0.2704\n",
      "CV iteration 22 of 30\n",
      "Validation subjects are ['p045' 'p035' 'p049']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 4.4653 - accuracy: 0.1180 - val_loss: 2.1937 - val_accuracy: 0.1992\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 2.1693 - accuracy: 0.2040 - val_loss: 1.8959 - val_accuracy: 0.2804\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.9403 - accuracy: 0.2560 - val_loss: 1.7994 - val_accuracy: 0.3429\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.7111 - accuracy: 0.3405 - val_loss: 1.3616 - val_accuracy: 0.4246\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.4497 - accuracy: 0.4495 - val_loss: 1.4448 - val_accuracy: 0.4379\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.1509 - accuracy: 0.5650 - val_loss: 1.9027 - val_accuracy: 0.4083\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.0649 - accuracy: 0.6025 - val_loss: 1.6316 - val_accuracy: 0.4704\n",
      "CV iteration 23 of 30\n",
      "Validation subjects are ['p064' 'p021' 'p022']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 4.4173 - accuracy: 0.1225 - val_loss: 2.3947 - val_accuracy: 0.1088\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 2.1428 - accuracy: 0.2210 - val_loss: 2.0772 - val_accuracy: 0.2212\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.8376 - accuracy: 0.3215 - val_loss: 1.7568 - val_accuracy: 0.3379\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.5805 - accuracy: 0.4105 - val_loss: 1.6009 - val_accuracy: 0.3521\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 1.3255 - accuracy: 0.4950 - val_loss: 1.4254 - val_accuracy: 0.4258\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.1154 - accuracy: 0.5830 - val_loss: 1.1925 - val_accuracy: 0.5121\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.0401 - accuracy: 0.6250 - val_loss: 1.1298 - val_accuracy: 0.5858\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.8484 - accuracy: 0.6925 - val_loss: 1.2460 - val_accuracy: 0.5604\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.7304 - accuracy: 0.7465 - val_loss: 0.9414 - val_accuracy: 0.6629\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.5842 - accuracy: 0.7860 - val_loss: 1.2082 - val_accuracy: 0.6154\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.5562 - accuracy: 0.7995 - val_loss: 0.9344 - val_accuracy: 0.6633\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.4024 - accuracy: 0.8655 - val_loss: 1.0378 - val_accuracy: 0.6254\n",
      "CV iteration 24 of 30\n",
      "Validation subjects are ['p049' 'p039' 'p035']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 4.4720 - accuracy: 0.1175 - val_loss: 2.4545 - val_accuracy: 0.1325\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.2242 - accuracy: 0.1900 - val_loss: 2.1507 - val_accuracy: 0.2521\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.9832 - accuracy: 0.2475 - val_loss: 2.0424 - val_accuracy: 0.2212\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.7707 - accuracy: 0.3175 - val_loss: 2.0621 - val_accuracy: 0.2204\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.5972 - accuracy: 0.3815 - val_loss: 1.7720 - val_accuracy: 0.3954\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 1.3543 - accuracy: 0.4780 - val_loss: 1.5558 - val_accuracy: 0.4517\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 1.1623 - accuracy: 0.5585 - val_loss: 1.3737 - val_accuracy: 0.5017\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 25s 203ms/step - loss: 1.0307 - accuracy: 0.6030 - val_loss: 1.4027 - val_accuracy: 0.4542\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.8988 - accuracy: 0.6540 - val_loss: 1.5970 - val_accuracy: 0.4558\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.7576 - accuracy: 0.7265 - val_loss: 1.6985 - val_accuracy: 0.4396\n",
      "CV iteration 25 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 4.4041 - accuracy: 0.1055 - val_loss: 2.2100 - val_accuracy: 0.2358\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 2.2389 - accuracy: 0.1685 - val_loss: 2.1320 - val_accuracy: 0.1950\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 2.0092 - accuracy: 0.2480 - val_loss: 1.9124 - val_accuracy: 0.2908\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.8149 - accuracy: 0.2935 - val_loss: 2.0110 - val_accuracy: 0.2246\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.5565 - accuracy: 0.3795 - val_loss: 2.6966 - val_accuracy: 0.3429\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.3552 - accuracy: 0.4735 - val_loss: 1.7121 - val_accuracy: 0.3242\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.1568 - accuracy: 0.5650 - val_loss: 3.1770 - val_accuracy: 0.4571\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.9572 - accuracy: 0.6285 - val_loss: 2.8984 - val_accuracy: 0.3783\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.8270 - accuracy: 0.6990 - val_loss: 2.9248 - val_accuracy: 0.3083\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.6769 - accuracy: 0.7465 - val_loss: 2.8543 - val_accuracy: 0.4875\n",
      "CV iteration 26 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.7183 - accuracy: 0.1135 - val_loss: 2.4633 - val_accuracy: 0.1704\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 2.3030 - accuracy: 0.1450 - val_loss: 2.1795 - val_accuracy: 0.1787\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 2.0895 - accuracy: 0.2235 - val_loss: 2.0507 - val_accuracy: 0.2067\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.8210 - accuracy: 0.3240 - val_loss: 1.8730 - val_accuracy: 0.2763c - ETA: 2s - loss: 1.8612 - accuracy: \n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.5921 - accuracy: 0.3920 - val_loss: 2.2910 - val_accuracy: 0.3496\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 1.3464 - accuracy: 0.4870 - val_loss: 4.1837 - val_accuracy: 0.3596\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.2266 - accuracy: 0.5280 - val_loss: 2.4128 - val_accuracy: 0.5467\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.0213 - accuracy: 0.6090 - val_loss: 4.2448 - val_accuracy: 0.4512\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.8448 - accuracy: 0.6760 - val_loss: 3.7185 - val_accuracy: 0.3900\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.7347 - accuracy: 0.7265 - val_loss: 3.4575 - val_accuracy: 0.3967\n",
      "CV iteration 27 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 4.2741 - accuracy: 0.1135 - val_loss: 2.2058 - val_accuracy: 0.2304\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 2.2756 - accuracy: 0.1455 - val_loss: 2.1064 - val_accuracy: 0.2288\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 1.9611 - accuracy: 0.2740 - val_loss: 1.8500 - val_accuracy: 0.3821\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 1.7162 - accuracy: 0.3470 - val_loss: 1.8643 - val_accuracy: 0.2883\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 204ms/step - loss: 1.4574 - accuracy: 0.4295 - val_loss: 2.5939 - val_accuracy: 0.3762\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 1.2780 - accuracy: 0.4905 - val_loss: 2.7107 - val_accuracy: 0.4192\n",
      "CV iteration 28 of 30\n",
      "Validation subjects are ['p041' 'p016' 'p026']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 4.3362 - accuracy: 0.1145 - val_loss: 2.2355 - val_accuracy: 0.1904\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.1770 - accuracy: 0.2125 - val_loss: 2.0635 - val_accuracy: 0.2575\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.9538 - accuracy: 0.2665 - val_loss: 1.6863 - val_accuracy: 0.3925\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.7058 - accuracy: 0.3565 - val_loss: 1.7670 - val_accuracy: 0.3496\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.4974 - accuracy: 0.4395 - val_loss: 1.2606 - val_accuracy: 0.5496\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.2190 - accuracy: 0.5415 - val_loss: 1.4951 - val_accuracy: 0.3938\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 1.1456 - accuracy: 0.5585 - val_loss: 1.0627 - val_accuracy: 0.6112\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.9649 - accuracy: 0.6395 - val_loss: 0.9998 - val_accuracy: 0.6175\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.7971 - accuracy: 0.7125 - val_loss: 1.2383 - val_accuracy: 0.5271 - accuracy: 0.\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.6976 - accuracy: 0.7485 - val_loss: 0.9140 - val_accuracy: 0.6308\n",
      "CV iteration 29 of 30\n",
      "Validation subjects are ['p045' 'p012' 'p042']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 4.4144 - accuracy: 0.1270 - val_loss: 2.4397 - val_accuracy: 0.0929\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 2.2941 - accuracy: 0.1460 - val_loss: 2.1355 - val_accuracy: 0.2429\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 2.0320 - accuracy: 0.2515 - val_loss: 1.8505 - val_accuracy: 0.3133\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 25s 198ms/step - loss: 1.6816 - accuracy: 0.3740 - val_loss: 2.1039 - val_accuracy: 0.4167\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.4841 - accuracy: 0.4235 - val_loss: 2.3869 - val_accuracy: 0.4350\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 1.2265 - accuracy: 0.5300 - val_loss: 2.6689 - val_accuracy: 0.3850\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 1.0808 - accuracy: 0.5910 - val_loss: 2.1067 - val_accuracy: 0.4254\n",
      "CV iteration 30 of 30\n",
      "Validation subjects are ['p064' 'p021' 'p022']\n",
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 4.3568 - accuracy: 0.1135 - val_loss: 2.3339 - val_accuracy: 0.1462\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 2.1410 - accuracy: 0.2310 - val_loss: 2.0246 - val_accuracy: 0.2579\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 1.8695 - accuracy: 0.2975 - val_loss: 1.8188 - val_accuracy: 0.2612\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 1.6370 - accuracy: 0.3805 - val_loss: 1.5840 - val_accuracy: 0.3479\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 1.3832 - accuracy: 0.4730 - val_loss: 1.5026 - val_accuracy: 0.4354\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 1.1847 - accuracy: 0.5570 - val_loss: 1.3484 - val_accuracy: 0.4317\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.9935 - accuracy: 0.6220 - val_loss: 1.3687 - val_accuracy: 0.4429\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.8047 - accuracy: 0.6995 - val_loss: 1.3456 - val_accuracy: 0.5279\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.6637 - accuracy: 0.7590 - val_loss: 1.4094 - val_accuracy: 0.5600\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.5444 - accuracy: 0.7990 - val_loss: 1.2089 - val_accuracy: 0.5871\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4632 - accuracy: 0.8440 - val_loss: 1.1517 - val_accuracy: 0.5792\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.3785 - accuracy: 0.8695 - val_loss: 1.1665 - val_accuracy: 0.6504\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.3068 - accuracy: 0.9000 - val_loss: 1.1789 - val_accuracy: 0.5904\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.2944 - accuracy: 0.8965 - val_loss: 1.3851 - val_accuracy: 0.6146\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.2410 - accuracy: 0.9190 - val_loss: 0.9870 - val_accuracy: 0.6850\n"
     ]
    }
   ],
   "source": [
    "model4data = cvrand(model4, \n",
    "                    df,\n",
    "                    n_iterations=30,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=125,\n",
    "                    target_size=(227,227),\n",
    "                    random_state=42,\n",
    "                    min_delta=0.05,\n",
    "                    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>sampledvalues</th>\n",
       "      <th>validation_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[p026, p050, p002]</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[p049, p039, p035]</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[p066, p050, p075]</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[p041, p016, p026]</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[p045, p035, p049]</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[p064, p021, p022]</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[p045, p035, p049]</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[p041, p016, p026]</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[p045, p056, p022]</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[p042, p075, p041]</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[p041, p016, p026]</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[p066, p050, p075]</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[p049, p039, p035]</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[p012, p035, p002]</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[p064, p021, p022]</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[p041, p016, p026]</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[p045, p035, p049]</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>[p066, p050, p075]</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>[p045, p035, p049]</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>[p064, p021, p022]</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>[p049, p039, p035]</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>[p041, p016, p026]</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>[p045, p012, p042]</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>[p064, p021, p022]</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration       sampledvalues  validation_accuracy\n",
       "0           1  [p026, p050, p002]                0.462\n",
       "1           2  [p049, p039, p035]                0.587\n",
       "2           3  [p066, p050, p075]                0.371\n",
       "3           4  [p045, p012, p042]                0.389\n",
       "4           5  [p041, p016, p026]                0.581\n",
       "5           6  [p045, p035, p049]                0.496\n",
       "6           7  [p064, p021, p022]                0.542\n",
       "7           8  [p045, p035, p049]                0.485\n",
       "8           9  [p041, p016, p026]                0.472\n",
       "9          10  [p045, p056, p022]                0.657\n",
       "10         11  [p042, p075, p041]                0.435\n",
       "11         12  [p041, p016, p026]                0.697\n",
       "12         13  [p066, p050, p075]                0.406\n",
       "13         14  [p049, p039, p035]                0.458\n",
       "14         15  [p012, p035, p002]                0.283\n",
       "15         16  [p064, p021, p022]                0.587\n",
       "16         17  [p045, p012, p042]                0.512\n",
       "17         18  [p045, p012, p042]                0.358\n",
       "18         19  [p041, p016, p026]                0.579\n",
       "19         20  [p045, p035, p049]                0.676\n",
       "20         21  [p066, p050, p075]                0.326\n",
       "21         22  [p045, p035, p049]                0.470\n",
       "22         23  [p064, p021, p022]                0.663\n",
       "23         24  [p049, p039, p035]                0.502\n",
       "24         25  [p045, p012, p042]                0.488\n",
       "25         26  [p045, p012, p042]                0.547\n",
       "26         27  [p045, p012, p042]                0.419\n",
       "27         28  [p041, p016, p026]                0.631\n",
       "28         29  [p045, p012, p042]                0.435\n",
       "29         30  [p064, p021, p022]                0.685"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4data.to_csv('../metrics/model4metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notify.send('all fitting complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = trainsampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024',\n",
       "       'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049',\n",
       "       'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072',\n",
       "       'p075', 'p081'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval = df1[df1['subject'].isin(['p002', 'p042', 'p081'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = df1[~df1['subject'].isin(['p002', 'p042', 'p081'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18400 validated image filenames belonging to 10 classes.\n",
      "Found 2400 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 125 steps, validate for 75 steps\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 43s 344ms/step - loss: 3.4503 - accuracy: 0.1410 - val_loss: 2.2149 - val_accuracy: 0.1792\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 37s 296ms/step - loss: 2.0914 - accuracy: 0.2750 - val_loss: 1.9203 - val_accuracy: 0.3508\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 40s 319ms/step - loss: 1.7208 - accuracy: 0.3970 - val_loss: 1.7303 - val_accuracy: 0.4367\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 30s 236ms/step - loss: 1.4540 - accuracy: 0.4795 - val_loss: 1.8058 - val_accuracy: 0.3558\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 1.2069 - accuracy: 0.5645 - val_loss: 1.9305 - val_accuracy: 0.4133\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 34s 273ms/step - loss: 0.9449 - accuracy: 0.6660 - val_loss: 1.3472 - val_accuracy: 0.5158\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.7190 - accuracy: 0.7485 - val_loss: 1.8264 - val_accuracy: 0.4892\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 27s 218ms/step - loss: 0.5779 - accuracy: 0.8020 - val_loss: 1.6603 - val_accuracy: 0.4946\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 32s 257ms/step - loss: 0.5013 - accuracy: 0.8310 - val_loss: 1.3821 - val_accuracy: 0.5550\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 28s 220ms/step - loss: 0.3721 - accuracy: 0.8820 - val_loss: 1.6833 - val_accuracy: 0.5083\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.3401 - accuracy: 0.8945 - val_loss: 2.0258 - val_accuracy: 0.4542\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 32s 259ms/step - loss: 0.2982 - accuracy: 0.9000 - val_loss: 1.4179 - val_accuracy: 0.5813\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 35s 276ms/step - loss: 0.2908 - accuracy: 0.9015 - val_loss: 1.1972 - val_accuracy: 0.6492\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 28s 220ms/step - loss: 0.2269 - accuracy: 0.9280 - val_loss: 2.3215 - val_accuracy: 0.5296\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 27s 218ms/step - loss: 0.2122 - accuracy: 0.9280 - val_loss: 2.9791 - val_accuracy: 0.4508\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 0.1824 - accuracy: 0.9415 - val_loss: 1.9324 - val_accuracy: 0.5846\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.1671 - accuracy: 0.9525 - val_loss: 1.7895 - val_accuracy: 0.5583\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.1728 - accuracy: 0.9480 - val_loss: 1.7349 - val_accuracy: 0.5546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2e9ea06c088>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Designate model checkpoint and callbacks_list\n",
    "checkpoint = ModelCheckpoint('weights.hdf5',\n",
    "                                mode='max',\n",
    "                            monitor='val_accuracy',\n",
    "                                 save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop]\n",
    "train = datagen.flow_from_dataframe(dtrain, x_col='imgpath',\n",
    "                                            y_col='classname',\n",
    "                                            batch_size=16,\n",
    "                                            target_size=(227, 227),\n",
    "                                            seed=42)\n",
    "val = datagen.flow_from_dataframe(dval, x_col='imgpath',\n",
    "                                            y_col='classname',\n",
    "                                            target_size=(227, 227),\n",
    "                                            seed=42)\n",
    "\n",
    "model4.fit(train, epochs=50, steps_per_epoch=125, callbacks=callbacks_list, validation_data=val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test = datagen.flow_from_directory('imgs/testlabeled',\n",
    "                                   seed=42,\n",
    "                                   target_size=(227,227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 168ms/step - loss: 1.8354 - accuracy: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8353876556668962, 0.54]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.load_weights('weights.hdf5')\n",
    "model4.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It seems that I ened to revamp my CV functions. It should randomly pick 3 - 5 subjects to isolate for the validation test, rather than cycling through each one individually. This way we can set the number of cross-validations to perform and we get a better sense on how well it's generalizing to all people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DenseNet121' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d248b21231e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DenseNet121' is not defined"
     ]
    }
   ],
   "source": [
    "model5 = DenseNet121(include_top=True, weights=None, classes=10)\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model5.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 10)           10250       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,047,754\n",
      "Trainable params: 6,964,106\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resample iteration 1\n",
      "CV iteration 1\n",
      "Substep 1 of 26\n",
      "Found 20000 validated image filenames belonging to 10 classes.\n",
      "Found 800 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 50 steps, validate for 25 steps\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 2.8602 - accuracy: 0.1000 - val_loss: 21135146844.1600 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 2.3780 - accuracy: 0.1000 - val_loss: 3190.2396 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 2.3868 - accuracy: 0.0988 - val_loss: 286.0759 - val_accuracy: 0.1088\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 2.3199 - accuracy: 0.1013 - val_loss: 2.3200 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 2.3099 - accuracy: 0.0938 - val_loss: 2.3050 - val_accuracy: 0.0925\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 2.2996 - accuracy: 0.1100 - val_loss: 2.3121 - val_accuracy: 0.0787\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 2.2881 - accuracy: 0.1213 - val_loss: 2.3256 - val_accuracy: 0.1000\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 2.2267 - accuracy: 0.1675 - val_loss: 3.5559 - val_accuracy: 0.1013\n",
      "Epoch 9/50\n",
      "22/50 [============>.................] - ETA: 11s - loss: 2.2515 - accuracy: 0.1369WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-347d2cd1b0d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                       \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                       random_state=42)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Dylan\\Desktop\\Data Science\\Projects\\DistractedDrivers\\functions\\ddfuncs.py\u001b[0m in \u001b[0;36msamplecv\u001b[1;34m(model, data, isampled, samples, col1, col2, itercol, n_iterations, epochs, batch_size, steps_per_epoch, validation_steps, target_size, random_state, patience)\u001b[0m\n\u001b[0;32m    141\u001b[0m         stats = cvmodeleval(model=modelsave, data=ts, itercol=itercol, n_iterations=n_iterations, epochs=epochs,\n\u001b[0;32m    142\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                             target_size=target_size, random_state=random_state, patience=patience)\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\Desktop\\Data Science\\Projects\\DistractedDrivers\\functions\\ddfuncs.py\u001b[0m in \u001b[0;36mcvmodeleval\u001b[1;34m(model, data, itercol, n_iterations, epochs, batch_size, steps_per_epoch, validation_steps, target_size, random_state, patience)\u001b[0m\n\u001b[0;32m     93\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                       callbacks=callbacks_list)\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;31m# Append lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dylan\\anaconda3\\envs\\DistractedDrivers\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model5data = samplecv(model5, \n",
    "                      df,\n",
    "                      samples=80, \n",
    "                      batch_size=16,\n",
    "                      epochs=50, \n",
    "                      steps_per_epoch=50, \n",
    "                      validation_steps=None, \n",
    "                      target_size=(299,299),\n",
    "                      patience=25,\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
